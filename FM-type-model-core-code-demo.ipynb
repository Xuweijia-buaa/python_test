{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5dd31b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from importlib import reload\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import argparse\n",
    "import random\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e2da3",
   "metadata": {},
   "source": [
    "数据处理\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee50b9",
   "metadata": {},
   "source": [
    "1 得到原始数据和离散，连续列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c58c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/media/xuweijia/DATA/代码/python_test/data/Criteo/demo_data/'\n",
    "file_name='train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f64db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>e88ffc9d</td>\n",
       "      <td>c393dc22</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>57c90cd9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>4d19a3eb</td>\n",
       "      <td>cb079c2d</td>\n",
       "      <td>456c12a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>92555263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242bb710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>72c78f11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>25c88e42</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>a0136dd2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>f37f3967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>c3abeb21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>642f2610</td>\n",
       "      <td>1d1eb838</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>1640d50b</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>45ab94c8</td>\n",
       "      <td>2bf691b1</td>\n",
       "      <td>c84c4aec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>fc35e8fe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a02708ad</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c3dc6cef</td>\n",
       "      <td>502f2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>eea796be</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>2b0a9d11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7453e535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dbb486d7</td>\n",
       "      <td>906e72ec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>817481a8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e4244d7f</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c7dc6720</td>\n",
       "      <td>60efe6e6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2005abd1</td>\n",
       "      <td>1cdbd1c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288eaded</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label   I1   I2    I3    I4      I5     I6     I7    I8     I9  ...  \\\n",
       "0         1  1.0    0   1.0   NaN   227.0    1.0  173.0  18.0   50.0  ...   \n",
       "1         1  4.0    1   1.0   2.0    27.0    2.0    4.0   2.0    2.0  ...   \n",
       "2         1  0.0  806   NaN   NaN  1752.0  142.0    2.0   0.0   50.0  ...   \n",
       "3         0  2.0   -1  42.0  14.0   302.0   38.0   25.0  38.0   90.0  ...   \n",
       "4         1  0.0   57   2.0   1.0  2891.0    2.0   35.0   1.0  137.0  ...   \n",
       "...     ...  ...  ...   ...   ...     ...    ...    ...   ...    ...  ...   \n",
       "1594      0  NaN    8   1.0   1.0    43.0    NaN    0.0   1.0    1.0  ...   \n",
       "1595      0  8.0    2  20.0   8.0    36.0    9.0    8.0  10.0    8.0  ...   \n",
       "1596      0  0.0    1   2.0  12.0  4877.0  140.0   13.0  34.0  136.0  ...   \n",
       "1597      0  NaN    2   NaN   1.0  1972.0    NaN    0.0   1.0   14.0  ...   \n",
       "1598      1  NaN   34   3.0   4.0     NaN    NaN    0.0   4.0   14.0  ...   \n",
       "\n",
       "           C17       C18       C19       C20       C21       C22       C23  \\\n",
       "0     3486227d  e88ffc9d  c393dc22  b1252a9d  57c90cd9       NaN  bcdee96c   \n",
       "1     07c540c4  92555263       NaN       NaN  242bb710       NaN  3a171ecb   \n",
       "2     07c540c4  25c88e42  21ddcdc9  b1252a9d  a0136dd2       NaN  32c7478e   \n",
       "3     e5ba7672  5aed7436  21ddcdc9  b1252a9d  c3abeb21       NaN  423fab69   \n",
       "4     e5ba7672  642f2610  1d1eb838  b1252a9d  1640d50b  ad3062eb  423fab69   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1594  1e88c74f  fc35e8fe       NaN       NaN  a02708ad  c9d4222a  c3dc6cef   \n",
       "1595  e5ba7672  5aed7436  21ddcdc9  b1252a9d  eea796be       NaN  3a171ecb   \n",
       "1596  e5ba7672  2b0a9d11       NaN       NaN  7453e535       NaN  dbb486d7   \n",
       "1597  e5ba7672  817481a8       NaN       NaN  e4244d7f  c9d4222a  c7dc6720   \n",
       "1598  2005abd1  1cdbd1c5       NaN       NaN  288eaded  c9d4222a  bcdee96c   \n",
       "\n",
       "           C24       C25       C26  \n",
       "0     4d19a3eb  cb079c2d  456c12a0  \n",
       "1     72c78f11       NaN       NaN  \n",
       "2     8fc66e78  001f3601  f37f3967  \n",
       "3     1793a828  e8b83407  5cef228f  \n",
       "4     45ab94c8  2bf691b1  c84c4aec  \n",
       "...        ...       ...       ...  \n",
       "1594  502f2493       NaN       NaN  \n",
       "1595  1793a828  e8b83407  5cef228f  \n",
       "1596  906e72ec       NaN       NaN  \n",
       "1597  60efe6e6       NaN       NaN  \n",
       "1598  8fc66e78       NaN       NaN  \n",
       "\n",
       "[1599 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get raw data\n",
    "raw_df=pd.read_csv(os.path.join(data_path+file_name))\n",
    "raw_df=raw_df.drop([\"Id\"],axis=1)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b5d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别找出连续列/离散列\n",
    "def col_type(df):\n",
    "    dis_col=[]\n",
    "    con_col=[]\n",
    "    columns=df.columns.tolist()\n",
    "    for c in columns:\n",
    "        if df[c].dtype=='int64' or df[c].dtype=='float':\n",
    "            con_col.append(c)\n",
    "        else:\n",
    "            dis_col.append(c)\n",
    "    return dis_col,con_col\n",
    "dis_col,con_col=col_type(raw_df)\n",
    "con_col.remove(\"Label\")\n",
    "label=\"Label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b59912c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[con_col].values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68807a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认是float64(double). 降低到float32. 与torch默认的兼容\n",
    "raw_df[con_col]=raw_df[con_col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f207e533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[con_col].values.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d7b1e",
   "metadata": {},
   "source": [
    "2 填充缺失值：数值型填0； 类别填空字符串，到时候也编码进去 （测试数据的缺失值用同样字符填充。相同编码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "737e366a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>e88ffc9d</td>\n",
       "      <td>c393dc22</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>57c90cd9</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>4d19a3eb</td>\n",
       "      <td>cb079c2d</td>\n",
       "      <td>456c12a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>92555263</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>242bb710</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>72c78f11</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>25c88e42</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>a0136dd2</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>f37f3967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>c3abeb21</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>642f2610</td>\n",
       "      <td>1d1eb838</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>1640d50b</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>45ab94c8</td>\n",
       "      <td>2bf691b1</td>\n",
       "      <td>c84c4aec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>fc35e8fe</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>a02708ad</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c3dc6cef</td>\n",
       "      <td>502f2493</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>eea796be</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>2b0a9d11</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>7453e535</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>dbb486d7</td>\n",
       "      <td>906e72ec</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>817481a8</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>e4244d7f</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c7dc6720</td>\n",
       "      <td>60efe6e6</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2005abd1</td>\n",
       "      <td>1cdbd1c5</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>288eaded</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label   I1     I2    I3    I4      I5     I6     I7    I8     I9  ...  \\\n",
       "0         1  1.0    0.0   1.0   0.0   227.0    1.0  173.0  18.0   50.0  ...   \n",
       "1         1  4.0    1.0   1.0   2.0    27.0    2.0    4.0   2.0    2.0  ...   \n",
       "2         1  0.0  806.0   0.0   0.0  1752.0  142.0    2.0   0.0   50.0  ...   \n",
       "3         0  2.0   -1.0  42.0  14.0   302.0   38.0   25.0  38.0   90.0  ...   \n",
       "4         1  0.0   57.0   2.0   1.0  2891.0    2.0   35.0   1.0  137.0  ...   \n",
       "...     ...  ...    ...   ...   ...     ...    ...    ...   ...    ...  ...   \n",
       "1594      0  0.0    8.0   1.0   1.0    43.0    0.0    0.0   1.0    1.0  ...   \n",
       "1595      0  8.0    2.0  20.0   8.0    36.0    9.0    8.0  10.0    8.0  ...   \n",
       "1596      0  0.0    1.0   2.0  12.0  4877.0  140.0   13.0  34.0  136.0  ...   \n",
       "1597      0  0.0    2.0   0.0   1.0  1972.0    0.0    0.0   1.0   14.0  ...   \n",
       "1598      1  0.0   34.0   3.0   4.0     0.0    0.0    0.0   4.0   14.0  ...   \n",
       "\n",
       "           C17       C18       C19       C20       C21       C22       C23  \\\n",
       "0     3486227d  e88ffc9d  c393dc22  b1252a9d  57c90cd9    <NULL>  bcdee96c   \n",
       "1     07c540c4  92555263    <NULL>    <NULL>  242bb710    <NULL>  3a171ecb   \n",
       "2     07c540c4  25c88e42  21ddcdc9  b1252a9d  a0136dd2    <NULL>  32c7478e   \n",
       "3     e5ba7672  5aed7436  21ddcdc9  b1252a9d  c3abeb21    <NULL>  423fab69   \n",
       "4     e5ba7672  642f2610  1d1eb838  b1252a9d  1640d50b  ad3062eb  423fab69   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1594  1e88c74f  fc35e8fe    <NULL>    <NULL>  a02708ad  c9d4222a  c3dc6cef   \n",
       "1595  e5ba7672  5aed7436  21ddcdc9  b1252a9d  eea796be    <NULL>  3a171ecb   \n",
       "1596  e5ba7672  2b0a9d11    <NULL>    <NULL>  7453e535    <NULL>  dbb486d7   \n",
       "1597  e5ba7672  817481a8    <NULL>    <NULL>  e4244d7f  c9d4222a  c7dc6720   \n",
       "1598  2005abd1  1cdbd1c5    <NULL>    <NULL>  288eaded  c9d4222a  bcdee96c   \n",
       "\n",
       "           C24       C25       C26  \n",
       "0     4d19a3eb  cb079c2d  456c12a0  \n",
       "1     72c78f11    <NULL>    <NULL>  \n",
       "2     8fc66e78  001f3601  f37f3967  \n",
       "3     1793a828  e8b83407  5cef228f  \n",
       "4     45ab94c8  2bf691b1  c84c4aec  \n",
       "...        ...       ...       ...  \n",
       "1594  502f2493    <NULL>    <NULL>  \n",
       "1595  1793a828  e8b83407  5cef228f  \n",
       "1596  906e72ec    <NULL>    <NULL>  \n",
       "1597  60efe6e6    <NULL>    <NULL>  \n",
       "1598  8fc66e78    <NULL>    <NULL>  \n",
       "\n",
       "[1599 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_token = '<NULL>'\n",
    "raw_df[dis_col]=raw_df[dis_col].fillna(null_token)\n",
    "raw_df[con_col]=raw_df[con_col].fillna(0)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1131d",
   "metadata": {},
   "source": [
    "3 可以做一些特征处理上的优化。比如数值型归一化。离散特征出现次数小于某阈值的，值都编码成\\<UNK\\>。这里忽略，假设已经做过了.也做过了特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f1832",
   "metadata": {},
   "source": [
    "4 离散特征label-encode. 保存原始值到label的映射。之后根据映射后的id找对应embedding （取值10个以内的one-hot,作为新特征）\n",
    "  如果想同一列加工出不同特征。可以用FeatureUnion和自定义transformer来选择列。 （如对文本列同时加工长度和tfidf两个特征）\n",
    "  ColumnTransformer对同一列只能做一个操作。如果不对同一列做不同操作，就用这个就可以。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b53bf00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load FM_helper/LabelEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b2430f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>...</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>...</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>30.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        C1     C2      C3     C4    C5   C6     C7    C8   C9    C10  ...  \\\n",
       "0     33.0   27.0   486.0  572.0   1.0  1.0  459.0   1.0  1.0  465.0  ...   \n",
       "1      0.0   98.0   170.0  287.0   1.0  3.0  550.0  21.0  1.0  683.0  ...   \n",
       "2      0.0   28.0   114.0  696.0  11.0  3.0  704.0   1.0  1.0  133.0  ...   \n",
       "3      0.0   12.0   650.0  243.0   1.0  3.0  329.0   1.0  1.0   27.0  ...   \n",
       "4      0.0   36.0   517.0   70.0   1.0  3.0   20.0   2.0  1.0  166.0  ...   \n",
       "...    ...    ...     ...    ...   ...  ...    ...   ...  ...    ...  ...   \n",
       "1594   0.0   93.0   617.0  801.0   1.0  1.0   25.0  12.0  1.0   28.0  ...   \n",
       "1595  30.0   12.0  1034.0  243.0   1.0  6.0  935.0   1.0  1.0  454.0  ...   \n",
       "1596  30.0  113.0   676.0    7.0   1.0  6.0  185.0  14.0  1.0  485.0  ...   \n",
       "1597   0.0   48.0   565.0  727.0   1.0  6.0  377.0   0.0  1.0  202.0  ...   \n",
       "1598   0.0  155.0   286.0  768.0   1.0  6.0  590.0   1.0  0.0  166.0  ...   \n",
       "\n",
       "          I5     I6     I7    I8     I9  I10   I11  I12   I13  Label  \n",
       "0      227.0    1.0  173.0  18.0   50.0  1.0   7.0  1.0   0.0    1.0  \n",
       "1       27.0    2.0    4.0   2.0    2.0  1.0   1.0  0.0   2.0    1.0  \n",
       "2     1752.0  142.0    2.0   0.0   50.0  0.0   1.0  0.0   0.0    1.0  \n",
       "3      302.0   38.0   25.0  38.0   90.0  1.0   3.0  0.0  38.0    0.0  \n",
       "4     2891.0    2.0   35.0   1.0  137.0  0.0  17.0  0.0   1.0    1.0  \n",
       "...      ...    ...    ...   ...    ...  ...   ...  ...   ...    ...  \n",
       "1594    43.0    0.0    0.0   1.0    1.0  0.0   0.0  0.0   1.0    0.0  \n",
       "1595    36.0    9.0    8.0  10.0    8.0  1.0   1.0  0.0   8.0    0.0  \n",
       "1596  4877.0  140.0   13.0  34.0  136.0  0.0   2.0  0.0  12.0    0.0  \n",
       "1597  1972.0    0.0    0.0   1.0   14.0  0.0   0.0  0.0   1.0    0.0  \n",
       "1598     0.0    0.0    0.0   4.0   14.0  0.0   0.0  0.0   4.0    1.0  \n",
       "\n",
       "[1599 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接当做包，引用py中函数\n",
    "# labelencoding。\n",
    "from FM_helper import LabelEncoder\n",
    "reload(LabelEncoder)\n",
    "trans,new_con_col,new_dis_col,df,raw_df2,cate_counts,cate_feature_map=LabelEncoder.labelencode_trans(raw_df,dis_col,con_col,label)\n",
    "# 测试.只需要保存大transformer和最终的dis_col,con_col。 用来做转化，以及识别转换后的两类特征。 \n",
    "LabelEncoder.test(raw_df,trans,new_con_col,new_dis_col,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a1e46",
   "metadata": {},
   "source": [
    "标准FM\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd23e3",
   "metadata": {},
   "source": [
    "公式："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395db68",
   "metadata": {},
   "source": [
    "$$y= b+ \\sum_{i}w_ix_i  + \\sum_{i}^{n}\\sum_{j!=i}^{n}x_ix_j<\\vec{v_i},\\vec{v_j}>$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899f7a5",
   "metadata": {},
   "source": [
    "一阶同LR. 每个连续特征对应一个$w_i$,每个离散特征one-hot之后的特征作为新特征，对应一个$w_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0fd6b1",
   "metadata": {},
   "source": [
    "二阶交互，每个连续特征对应一个embedding。每个离散特征的每个每个特征的每个取值对应一个embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997451f0",
   "metadata": {},
   "source": [
    "因此每个连续特征$x_i$,对应一个$w_i$,一个embedding，用来和其他特征交互。\n",
    "   每个离散特征域，对应one-hot之后的C个特征$x_i$，对应C个$w_i$,C个embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818520f1",
   "metadata": {},
   "source": [
    "但对每个样本来说，该离散特征one-hot之后，只会根据取值取到一个embedding，一个$w_i$<br/>(该离散特征对一阶的贡献，只有根据样本该离散特征取值映射到的$w_i$，对应取值$x_i$是1,其他C-1位置由于one-hot,该样本下取值$x_i$都是0,贡献是0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a62e344",
   "metadata": {},
   "source": [
    "因此总共需要维护（所有连续特征+所有离散特征的所有取值)个特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82c11d",
   "metadata": {},
   "source": [
    "假设所有连续特征和one-hot后的所有离散特征共F个,总共需要维护F个特征。可以根据特征名称，把每个特征映射到一个固定id上（位置）:<br/>\n",
    "每个连续特征对应一个id                            <br/>\n",
    "每个离散特征的每个取值对应一个id                    <br/>\n",
    "每个id都维护一个$w_i$,一个embedding，对应该特征在W（F,1）,embedding(F,d)中的位置。<br/>\n",
    "之后每个样本，都可以根据特征位置去找对应的$w_i$,embedding：       <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca8dd50",
   "metadata": {},
   "source": [
    "因此在对每个样本进行映射时，需要分别得到样本每个特征的位置（id）和取值$x_i$："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d5c8dd",
   "metadata": {},
   "source": [
    "位置映射：样本的所有特征都被映射到对应位置,用来找对应的$w_i$,embedding。每个连续特征对应的就是位置id。每个离散域，根据样本在该域的取值映射到对应id。n个离散域，对应n个embedding,n个$w_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012662c",
   "metadata": {},
   "source": [
    "样本取值：连续特征的取值不变（或者归一化），离散特征取值1，作为样本的$x_i$输入。n个离散域，对应的n个取值，$x_i$都是1。在one-hot后的对应位置上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2400cb9",
   "metadata": {},
   "source": [
    "### 对原始特征进行映射。得到one-hot之后的所有特征（含连续特征）到位置id的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bde59bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "class FeaturePosTrans(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, dis_col=None, con_col= None, limit_freq = 0):\n",
    "        self.dis_col=dis_col\n",
    "        self.con_col=con_col\n",
    "        self.limit_freq=limit_freq\n",
    "        \n",
    "        self.NULL = '<NULL>'\n",
    "        self.UNK = '<UNK>'                                                # nlp里。低频是1，NAN是0. NAN作为padding,不参与训练且是0\n",
    "                                                                          # NAN对应embedding： padding_index=0.只占位，不训练）\n",
    "                                                                          # nn.Embedding(V,d,padding_idx=0\n",
    "    \n",
    "        self.dis_col_map=dict()                                            # 按特征，记录取值到位置id的映射  只用来存着\n",
    "        self.feature_id_map=dict()                                         # 特征名到位置id的映射大表 {特征名_取值：位置id}\n",
    "        self.pos=0                                                         # 位置id\n",
    "        self.dis_col_count=dict()                                          # 每个离散特征的取值数目\n",
    "        \n",
    "        \n",
    "        # 所有离散的缺失值，统一用NAN编码，之后在w，E中padding成0\n",
    "        self.feature_id_map[self.NULL]=0\n",
    "        self.pos+=1\n",
    "        \n",
    "        if (con_col!=None):\n",
    "            self.feature_id_map.update(dict(zip(con_col,range(self.pos,self.pos+len(con_col))))) # 连续特征到对应位置的映射\n",
    "            self.pos+=len(self.con_col)\n",
    "\n",
    "    def fit(self, X , y = None):\n",
    "        \n",
    "        if (self.dis_col!=None):\n",
    "            # 每个离散特征取值,映射到对应id\n",
    "            for col in self.dis_col:\n",
    "                valueCount=dict(X[col].value_counts())                       # 该离散特征。每个取值的出现数目\n",
    "                # 是否特殊处理低频取值\n",
    "                if self.limit_freq>0:\n",
    "                    values=[k for k,v in valueCount.items() if k!=self.NULL and v>self.limit_freq]  # 该特征留下的取值\n",
    "                    self.dis_col_map[col]=dict(zip(values,range(self.pos+1,self.pos+1+len(values))))\n",
    "                    self.dis_col_map[col][self.UNK]=self.pos\n",
    "                    # 组织大表。类似\n",
    "                    new_values=[col+\"_\"+v for v in values]                    # { C1_v1：id}  \n",
    "                    self.feature_id_map.update(dict(zip(new_values,range(self.pos+1,self.pos+1+len(new_values)))))\n",
    "                    self.feature_id_map[col+\"_\"+self.UNK]=self.pos\n",
    "                    self.pos+=len(new_values)+1                              # 每个特征留下：所有高频取值+UNK                                   \n",
    "                else:\n",
    "                    # 每个特征。分别记录映射\n",
    "                    values=[k for k in valueCount.keys() if k!=self.NULL]    # 该离散特征所有取值（除缺失值） \n",
    "                    self.dis_col_map[col]=dict(zip(values,range(self.pos,self.pos+len(values))))\n",
    "                    # 类似，但根据取值记在大map里\n",
    "                    new_values=[col+\"_\"+v for v in values]                   # { C1_v1：id}  \n",
    "                    self.feature_id_map.update(dict(zip(new_values,range(self.pos,self.pos+len(new_values)))))\n",
    "                    self.pos+=len(new_values)\n",
    "                    \n",
    "                 # 每个离散特征的有效取值数目(不含NAN，含每个特征的unk)\n",
    "                self.dis_col_count[col]=len(self.dis_col_map[col])                            \n",
    "                                                                               \n",
    "    def transform(self, X, y=None):\n",
    "        # 映射：\n",
    "        feature_pos=X.copy()                        # 样本每个特征对应的位置\n",
    "        feature_values=X.copy()                     # 样本每个特征的取值。离散特征取值是1.\n",
    "        cols=self.dis_col+self.con_col\n",
    "        for col in cols:\n",
    "            if col in self.dis_col:\n",
    "                #values=X[col].apply(self.gen,args=(col,)).values\n",
    "                values=X[col].apply(self.gen2,args=(col,)).values    # 组织形式不同。映射效果相同。用这个好些\n",
    "                feature_pos[col]=values\n",
    "                feature_values[col]=1.0\n",
    "            else:\n",
    "                feature_pos[col]=self.feature_id_map[col]            # 连续特征取值不变  。 位置是映射后的id \n",
    "        \n",
    "        # 映射完的取值（包括离散特征取值1.0），也都变成float32\n",
    "        feature_values=feature_values.astype(np.float32)\n",
    "        \n",
    "        return feature_pos,feature_values\n",
    "        \n",
    "    # 如果是多列。传入的x是该列对应的series. 输出的是这些列拼起来的df\n",
    "    # 如果是单列，传入的x是该列的每个元素    输出的是该列对应的Series\n",
    "    # 根据离散特征取值，返回对应的位置id\n",
    "    def gen(self,x,col):\n",
    "        if x==self.NULL:                                        # NAN统一映射到0\n",
    "            return 0\n",
    "        else:\n",
    "            if x in self.dis_col_map[col]:\n",
    "                return self.dis_col_map[col][x]                 # 按取值，映射到对应位置id\n",
    "            else:\n",
    "                if self.limit_freq>0:\n",
    "                    return self.dis_col_map[col][self.UNK]       # 低频取值/没见过的值。映射到unqkey对应的编码 \n",
    "                else:\n",
    "                    return 0                                     # 没见过的值。映射到NAN==0。没有贡献\n",
    "\n",
    "    # 用大表做映射。类似\n",
    "    def gen2(self,x,col):    \n",
    "        if x==self.NULL:                                         # NAN统一映射到0\n",
    "            return 0\n",
    "        else:\n",
    "            x=col+\"_\"+x\n",
    "            if x in self.feature_id_map:                         # 其他按取值，映射到对应位置id\n",
    "                return self.feature_id_map[x]                 \n",
    "            else:\n",
    "                if self.limit_freq>0:                \n",
    "                    return self.feature_id_map[col+\"_\"+self.UNK] # 低频取值/没见过的值。映射到该特征unqkey对应的编码 \n",
    "                else:\n",
    "                    return 0                                     # 没见过的值。映射到NAN。没有贡献\n",
    "                \n",
    "    def id2name(self):\n",
    "        return dict(zip(self.feature_id_map.values(),self.feature_id_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80f89ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from FM_helper import Fmdata\n",
    "#reload(Fmdata)\n",
    "#f_trans=Fmdata.FeaturePosTrans(dis_col,con_col,10)\n",
    "f_trans=FeaturePosTrans(dis_col,con_col,10)             # 出现10次以下的作为UNK\n",
    "f_trans.fit(raw_df)\n",
    "feature_pos,feature_values=f_trans.transform(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4622628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_trans.feature_id_map)  # 离散特征one-hot后，总的特征数目. NAN+con_col+all_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9310c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<NULL>': 0,\n",
       " 'I1': 1,\n",
       " 'I2': 2,\n",
       " 'I3': 3,\n",
       " 'I4': 4,\n",
       " 'I5': 5,\n",
       " 'I6': 6,\n",
       " 'I7': 7,\n",
       " 'I8': 8,\n",
       " 'I9': 9,\n",
       " 'I10': 10,\n",
       " 'I11': 11,\n",
       " 'I12': 12,\n",
       " 'I13': 13,\n",
       " 'C1_05db9164': 15,\n",
       " 'C1_68fd1e64': 16,\n",
       " 'C1_5a9ed9b0': 17,\n",
       " 'C1_8cf07265': 18,\n",
       " 'C1_be589b51': 19,\n",
       " 'C1_5bfa8ab5': 20,\n",
       " 'C1_f473b8dc': 21,\n",
       " 'C1_87552397': 22,\n",
       " 'C1_ae82ea21': 23,\n",
       " 'C1_39af2607': 24,\n",
       " 'C1_9a89b36c': 25,\n",
       " 'C1_<UNK>': 14,\n",
       " 'C2_38a947a1': 27,\n",
       " 'C2_09e68b86': 28,\n",
       " 'C2_80e26c9b': 29,\n",
       " 'C2_d833535f': 30,\n",
       " 'C2_4f25e98b': 31,\n",
       " 'C2_287130e0': 32,\n",
       " 'C2_0a519c5c': 33,\n",
       " 'C2_08d6d899': 34,\n",
       " 'C2_4c2bc594': 35,\n",
       " 'C2_38d50e09': 36,\n",
       " 'C2_207b2d81': 37,\n",
       " 'C2_58e67aaf': 38,\n",
       " 'C2_2c16a946': 39,\n",
       " 'C2_942f9a8d': 40,\n",
       " 'C2_8947f767': 41,\n",
       " 'C2_421b43cd': 42,\n",
       " 'C2_0468d672': 43,\n",
       " 'C2_8084ee93': 44,\n",
       " 'C2_78ccd99e': 45,\n",
       " 'C2_1cfdf714': 46,\n",
       " 'C2_68b3edbf': 47,\n",
       " 'C2_e112a9de': 48,\n",
       " 'C2_95e2d337': 49,\n",
       " 'C2_e5fb1af3': 50,\n",
       " 'C2_39dfaa0d': 51,\n",
       " 'C2_e77e5e6e': 52,\n",
       " 'C2_9819deea': 53,\n",
       " 'C2_8cc9c66e': 54,\n",
       " 'C2_f0cf0024': 55,\n",
       " 'C2_3df44d94': 56,\n",
       " 'C2_ae46a29d': 57,\n",
       " 'C2_26a88120': 58,\n",
       " 'C2_<UNK>': 26,\n",
       " 'C3_d032c263': 60,\n",
       " 'C3_b00d1501': 61,\n",
       " 'C3_77f2f2e5': 62,\n",
       " 'C3_aa8c1539': 63,\n",
       " 'C3_02cf9876': 64,\n",
       " 'C3_ad4b77ff': 65,\n",
       " 'C3_9143c832': 66,\n",
       " 'C3_e346a5fd': 67,\n",
       " 'C3_<UNK>': 59,\n",
       " 'C4_d16679b9': 69,\n",
       " 'C4_c18be181': 70,\n",
       " 'C4_85dd697c': 71,\n",
       " 'C4_f922efad': 72,\n",
       " 'C4_13508380': 73,\n",
       " 'C4_29998ed1': 74,\n",
       " 'C4_f56b7dd5': 75,\n",
       " 'C4_<UNK>': 68,\n",
       " 'C5_25c83c98': 77,\n",
       " 'C5_4cf72387': 78,\n",
       " 'C5_43b19349': 79,\n",
       " 'C5_384874ce': 80,\n",
       " 'C5_30903e74': 81,\n",
       " 'C5_0942e0a7': 82,\n",
       " 'C5_f281d2a7': 83,\n",
       " 'C5_b0530c50': 84,\n",
       " 'C5_<UNK>': 76,\n",
       " 'C6_7e0ccccf': 86,\n",
       " 'C6_fbad5c96': 87,\n",
       " 'C6_fe6b92e5': 88,\n",
       " 'C6_13718bbd': 89,\n",
       " 'C6_6f6d9be8': 90,\n",
       " 'C6_3bf701e7': 91,\n",
       " 'C6_<UNK>': 85,\n",
       " 'C7_38eb9cf4': 93,\n",
       " 'C7_3f4ec687': 94,\n",
       " 'C7_970f01b2': 95,\n",
       " 'C7_9b98e9fc': 96,\n",
       " 'C7_49b74ebc': 97,\n",
       " 'C7_d0bdaa98': 98,\n",
       " 'C7_468a0854': 99,\n",
       " 'C7_dc7659bd': 100,\n",
       " 'C7_26a81064': 101,\n",
       " 'C7_88002ee1': 102,\n",
       " 'C7_<UNK>': 92,\n",
       " 'C8_0b153874': 104,\n",
       " 'C8_5b392875': 105,\n",
       " 'C8_1f89b562': 106,\n",
       " 'C8_37e4aa92': 107,\n",
       " 'C8_062b5529': 108,\n",
       " 'C8_51d76abe': 109,\n",
       " 'C8_c8ddd494': 110,\n",
       " 'C8_64523cfa': 111,\n",
       " 'C8_6c41e35e': 112,\n",
       " 'C8_66f29b89': 113,\n",
       " 'C8_<UNK>': 103,\n",
       " 'C9_a73ee510': 115,\n",
       " 'C9_7cc72ec2': 116,\n",
       " 'C9_<UNK>': 114,\n",
       " 'C10_3b08e48b': 118,\n",
       " 'C10_fbbf2c95': 119,\n",
       " 'C10_fa7d0797': 120,\n",
       " 'C10_0e9ead52': 121,\n",
       " 'C10_efea433b': 122,\n",
       " 'C10_6c47047a': 123,\n",
       " 'C10_5ba575e7': 124,\n",
       " 'C10_dcbc7c2b': 125,\n",
       " 'C10_451bd4e4': 126,\n",
       " 'C10_<UNK>': 117,\n",
       " 'C11_7f8ffe57': 128,\n",
       " 'C11_c4adf918': 129,\n",
       " 'C11_e51ddf94': 130,\n",
       " 'C11_5874c9c9': 131,\n",
       " 'C11_9e511730': 132,\n",
       " 'C11_a7b606c4': 133,\n",
       " 'C11_f25fe7e9': 134,\n",
       " 'C11_4ba74619': 135,\n",
       " 'C11_36bccca0': 136,\n",
       " 'C11_dd6fc8cb': 137,\n",
       " 'C11_b7094596': 138,\n",
       " 'C11_<UNK>': 127,\n",
       " 'C12_dfbb09fb': 140,\n",
       " 'C12_e0d76380': 141,\n",
       " 'C12_9f32b866': 142,\n",
       " 'C12_d8c29807': 143,\n",
       " 'C12_8fe001f4': 144,\n",
       " 'C12_a2f4e8b5': 145,\n",
       " 'C12_6aaba33c': 146,\n",
       " 'C12_ae1bb660': 147,\n",
       " 'C12_b99ddbc8': 148,\n",
       " 'C12_539c5644': 149,\n",
       " 'C12_<UNK>': 139,\n",
       " 'C13_46f42a63': 151,\n",
       " 'C13_85dbe138': 152,\n",
       " 'C13_80467802': 153,\n",
       " 'C13_ebd756bd': 154,\n",
       " 'C13_3516f6e6': 155,\n",
       " 'C13_740c210d': 156,\n",
       " 'C13_6e5da64f': 157,\n",
       " 'C13_04e4a7e0': 158,\n",
       " 'C13_eae197fd': 159,\n",
       " 'C13_dd183b4c': 160,\n",
       " 'C13_879fa878': 161,\n",
       " 'C13_1f9d2c38': 162,\n",
       " 'C13_605bbc24': 163,\n",
       " 'C13_949ea585': 164,\n",
       " 'C13_b55434a9': 165,\n",
       " 'C13_<UNK>': 150,\n",
       " 'C14_07d13a8f': 167,\n",
       " 'C14_b28479f6': 168,\n",
       " 'C14_1adce6ef': 169,\n",
       " 'C14_8ceecbc8': 170,\n",
       " 'C14_64c94865': 171,\n",
       " 'C14_cfef1c29': 172,\n",
       " 'C14_051219e6': 173,\n",
       " 'C14_f862f261': 174,\n",
       " 'C14_<UNK>': 166,\n",
       " 'C15_36721ddc': 176,\n",
       " 'C15_7ac43a46': 177,\n",
       " 'C15_52baadf5': 178,\n",
       " 'C15_a733d362': 179,\n",
       " 'C15_0f942372': 180,\n",
       " 'C15_10040656': 181,\n",
       " 'C15_d2f03b75': 182,\n",
       " 'C15_dfab705f': 183,\n",
       " 'C15_dbc5e126': 184,\n",
       " 'C15_8ab5b746': 185,\n",
       " 'C15_41f10449': 186,\n",
       " 'C15_1150f5ed': 187,\n",
       " 'C15_2ee9f086': 188,\n",
       " 'C15_2d0bb053': 189,\n",
       " 'C15_9efd8b77': 190,\n",
       " 'C15_4c1df281': 191,\n",
       " 'C15_3628a186': 192,\n",
       " 'C15_f3635baf': 193,\n",
       " 'C15_bfef54b3': 194,\n",
       " 'C15_ac182643': 195,\n",
       " 'C15_b760dcb7': 196,\n",
       " 'C15_<UNK>': 175,\n",
       " 'C16_84898b2a': 198,\n",
       " 'C16_1203a270': 199,\n",
       " 'C16_31ca40b6': 200,\n",
       " 'C16_c64d548f': 201,\n",
       " 'C16_36103458': 202,\n",
       " 'C16_89052618': 203,\n",
       " 'C16_b041b04a': 204,\n",
       " 'C16_bad5ee18': 205,\n",
       " 'C16_87acb535': 206,\n",
       " 'C16_aafa191e': 207,\n",
       " 'C16_da441c7e': 208,\n",
       " 'C16_<UNK>': 197,\n",
       " 'C17_e5ba7672': 210,\n",
       " 'C17_d4bb7bd8': 211,\n",
       " 'C17_07c540c4': 212,\n",
       " 'C17_3486227d': 213,\n",
       " 'C17_776ce399': 214,\n",
       " 'C17_1e88c74f': 215,\n",
       " 'C17_2005abd1': 216,\n",
       " 'C17_27c07bd6': 217,\n",
       " 'C17_8efede7f': 218,\n",
       " 'C17_<UNK>': 209,\n",
       " 'C18_5aed7436': 220,\n",
       " 'C18_891589e7': 221,\n",
       " 'C18_7ef5affa': 222,\n",
       " 'C18_281769c2': 223,\n",
       " 'C18_bc48b783': 224,\n",
       " 'C18_005c6740': 225,\n",
       " 'C18_f54016b9': 226,\n",
       " 'C18_c21c3e4c': 227,\n",
       " 'C18_7b49e3d2': 228,\n",
       " 'C18_1f868fdd': 229,\n",
       " 'C18_2efa89c6': 230,\n",
       " 'C18_63cdbb21': 231,\n",
       " 'C18_2804effd': 232,\n",
       " 'C18_bd17c3da': 233,\n",
       " 'C18_e7e991cb': 234,\n",
       " 'C18_698d1c68': 235,\n",
       " 'C18_eea3ab97': 236,\n",
       " 'C18_13145934': 237,\n",
       " 'C18_582152eb': 238,\n",
       " 'C18_7e32f7a4': 239,\n",
       " 'C18_e88ffc9d': 240,\n",
       " 'C18_a6f5dd38': 241,\n",
       " 'C18_9880032b': 242,\n",
       " 'C18_e4ca448c': 243,\n",
       " 'C18_87c6f83c': 244,\n",
       " 'C18_7b06fafe': 245,\n",
       " 'C18_df4fffb7': 246,\n",
       " 'C18_752d8b8a': 247,\n",
       " 'C18_52e44668': 248,\n",
       " 'C18_<UNK>': 219,\n",
       " 'C19_21ddcdc9': 250,\n",
       " 'C19_55dd3565': 251,\n",
       " 'C19_cf99e5de': 252,\n",
       " 'C19_9437f62f': 253,\n",
       " 'C19_<UNK>': 249,\n",
       " 'C20_5840adea': 255,\n",
       " 'C20_a458ea53': 256,\n",
       " 'C20_b1252a9d': 257,\n",
       " 'C20_<UNK>': 254,\n",
       " 'C21_0014c32a': 259,\n",
       " 'C21_73d06dde': 260,\n",
       " 'C21_dfcfc3fa': 261,\n",
       " 'C21_5f957280': 262,\n",
       " 'C21_e587c466': 263,\n",
       " 'C21_d4703ebd': 264,\n",
       " 'C21_723b4dfd': 265,\n",
       " 'C21_0429f84b': 266,\n",
       " 'C21_a4b7004c': 267,\n",
       " 'C21_7e5b7cc4': 268,\n",
       " 'C21_<UNK>': 258,\n",
       " 'C22_ad3062eb': 270,\n",
       " 'C22_c9d4222a': 271,\n",
       " 'C22_78e2e389': 272,\n",
       " 'C22_8ec974f4': 273,\n",
       " 'C22_<UNK>': 269,\n",
       " 'C23_32c7478e': 275,\n",
       " 'C23_3a171ecb': 276,\n",
       " 'C23_423fab69': 277,\n",
       " 'C23_be7c41b4': 278,\n",
       " 'C23_bcdee96c': 279,\n",
       " 'C23_c7dc6720': 280,\n",
       " 'C23_55dd3565': 281,\n",
       " 'C23_dbb486d7': 282,\n",
       " 'C23_93bad2c0': 283,\n",
       " 'C23_<UNK>': 274,\n",
       " 'C24_aee52b6f': 285,\n",
       " 'C24_3b183c5c': 286,\n",
       " 'C24_1793a828': 287,\n",
       " 'C24_3fdb382b': 288,\n",
       " 'C24_b34f3128': 289,\n",
       " 'C24_45ab94c8': 290,\n",
       " 'C24_9117a34a': 291,\n",
       " 'C24_c0d61a5c': 292,\n",
       " 'C24_b258af68': 293,\n",
       " 'C24_df487a73': 294,\n",
       " 'C24_f96a556f': 295,\n",
       " 'C24_08b0ce98': 296,\n",
       " 'C24_<UNK>': 284,\n",
       " 'C25_e8b83407': 298,\n",
       " 'C25_001f3601': 299,\n",
       " 'C25_ea9a246c': 300,\n",
       " 'C25_2bf691b1': 301,\n",
       " 'C25_010f6491': 302,\n",
       " 'C25_9b3e8820': 303,\n",
       " 'C25_445bbe3b': 304,\n",
       " 'C25_cb079c2d': 305,\n",
       " 'C25_f0f449dd': 306,\n",
       " 'C25_9d93af03': 307,\n",
       " 'C25_724b04da': 308,\n",
       " 'C25_<UNK>': 297,\n",
       " 'C26_49d68486': 310,\n",
       " 'C26_c84c4aec': 311,\n",
       " 'C26_b7d9c3bc': 312,\n",
       " 'C26_9904c656': 313,\n",
       " 'C26_c27f155b': 314,\n",
       " 'C26_2fede552': 315,\n",
       " 'C26_984e0db0': 316,\n",
       " 'C26_aa5f0a15': 317,\n",
       " 'C26_b9809574': 318,\n",
       " 'C26_<UNK>': 309}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_trans.feature_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "883319d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>240</td>\n",
       "      <td>249</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>284</td>\n",
       "      <td>305</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>212</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>212</td>\n",
       "      <td>219</td>\n",
       "      <td>250</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>284</td>\n",
       "      <td>299</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>220</td>\n",
       "      <td>250</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>287</td>\n",
       "      <td>298</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>219</td>\n",
       "      <td>249</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>270</td>\n",
       "      <td>277</td>\n",
       "      <td>290</td>\n",
       "      <td>301</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>271</td>\n",
       "      <td>274</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>220</td>\n",
       "      <td>250</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>287</td>\n",
       "      <td>298</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>271</td>\n",
       "      <td>280</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>271</td>\n",
       "      <td>279</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  I1  I2  I3  I4  I5  I6  I7  I8  I9  ...  C17  C18  C19  C20  C21  \\\n",
       "0         1   1   2   3   4   5   6   7   8   9  ...  213  240  249  257  258   \n",
       "1         1   1   2   3   4   5   6   7   8   9  ...  212  219    0    0  258   \n",
       "2         1   1   2   3   4   5   6   7   8   9  ...  212  219  250  257  258   \n",
       "3         0   1   2   3   4   5   6   7   8   9  ...  210  220  250  257  258   \n",
       "4         1   1   2   3   4   5   6   7   8   9  ...  210  219  249  257  258   \n",
       "...     ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...   \n",
       "1594      0   1   2   3   4   5   6   7   8   9  ...  215  219    0    0  258   \n",
       "1595      0   1   2   3   4   5   6   7   8   9  ...  210  220  250  257  258   \n",
       "1596      0   1   2   3   4   5   6   7   8   9  ...  210  219    0    0  258   \n",
       "1597      0   1   2   3   4   5   6   7   8   9  ...  210  219    0    0  258   \n",
       "1598      1   1   2   3   4   5   6   7   8   9  ...  216  219    0    0  258   \n",
       "\n",
       "      C22  C23  C24  C25  C26  \n",
       "0       0  279  284  305  309  \n",
       "1       0  276  284    0    0  \n",
       "2       0  275  284  299  309  \n",
       "3       0  277  287  298  309  \n",
       "4     270  277  290  301  311  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "1594  271  274  284    0    0  \n",
       "1595    0  276  287  298  309  \n",
       "1596    0  282  284    0    0  \n",
       "1597  271  280  284    0    0  \n",
       "1598  271  279  284    0    0  \n",
       "\n",
       "[1599 rows x 40 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7235edeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label   I1     I2    I3    I4      I5     I6     I7    I8     I9  ...  \\\n",
       "0       1.0  1.0    0.0   1.0   0.0   227.0    1.0  173.0  18.0   50.0  ...   \n",
       "1       1.0  4.0    1.0   1.0   2.0    27.0    2.0    4.0   2.0    2.0  ...   \n",
       "2       1.0  0.0  806.0   0.0   0.0  1752.0  142.0    2.0   0.0   50.0  ...   \n",
       "3       0.0  2.0   -1.0  42.0  14.0   302.0   38.0   25.0  38.0   90.0  ...   \n",
       "4       1.0  0.0   57.0   2.0   1.0  2891.0    2.0   35.0   1.0  137.0  ...   \n",
       "...     ...  ...    ...   ...   ...     ...    ...    ...   ...    ...  ...   \n",
       "1594    0.0  0.0    8.0   1.0   1.0    43.0    0.0    0.0   1.0    1.0  ...   \n",
       "1595    0.0  8.0    2.0  20.0   8.0    36.0    9.0    8.0  10.0    8.0  ...   \n",
       "1596    0.0  0.0    1.0   2.0  12.0  4877.0  140.0   13.0  34.0  136.0  ...   \n",
       "1597    0.0  0.0    2.0   0.0   1.0  1972.0    0.0    0.0   1.0   14.0  ...   \n",
       "1598    1.0  0.0   34.0   3.0   4.0     0.0    0.0    0.0   4.0   14.0  ...   \n",
       "\n",
       "      C17  C18  C19  C20  C21  C22  C23  C24  C25  C26  \n",
       "0     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "3     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "1594  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1595  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1596  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1597  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1598  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[1599 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a0f5b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_values.values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb76dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pos=feature_pos.drop([label], axis=1)\n",
    "feature_values=feature_values.drop([label], axis=1)    # 特征列去掉label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cbb3267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcols=dis_col+con_col\n",
    "feature_values[allcols].values.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920cd3e",
   "metadata": {},
   "source": [
    "### 建立自己的dataset和对应的dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33d9c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)           # torch模型参数的默认数据类型是flaot32.  np/pd是默认是flaot64(double).转成一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ed2ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建dataset: 都放np,防止loader开多进程内存泄露:https://github.com/pytorch/pytorch/issues/13246#issuecomment-893198671）\n",
    "class Mydata(Dataset):\n",
    "    def __init__(self,fv,fp,target,mode='train'):\n",
    "        super(Mydata, self).__init__()\n",
    "        self.fv=fv           # np: m,n.  每个样本的特征取值 \n",
    "        self.fp=fp           #           每个样本的特征位置.如果太大以后可以放np文件名.或切成多个文件,每次只打开一个(类似drml)\n",
    "        self.target=target   #           如果mode==train/valid.对应y. mode==test,没有y，对应id \n",
    "    def __len__(self):\n",
    "        return len(self.fv)\n",
    "    def __getitem__(self, index):\n",
    "        return self.fp[index,:],self.fv[index],self.target[index]  # 提前做好了映射。当然映射也可以在这里做。\n",
    "\n",
    "allcols=dis_col+con_col\n",
    "trainDataset=Mydata(feature_values[allcols].values,feature_pos[allcols].values, raw_df[label].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3e73d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader:   valid同\n",
    "trainloader = DataLoader(trainDataset,        \n",
    "                    shuffle=True,             # 每个epoch全部shuffle\n",
    "                    batch_size=32,\n",
    "                    collate_fn=None,          # 自定义如何拼batch。默认有，一般不需要。可以用来对batch padding（根据每个batch最长的text）\n",
    "                                              # 传入的是一个batch，B个tuple. 每个tuple对应Dataset传出来的n个元素。\n",
    "                                              # 自己重新拼成n个元素，每个元素B行，作为loader每次迭代的返回\n",
    "                    pin_memory=False,         # 页锁定内存：不可分页，占用物理内存。 可分页内存：占用虚拟内存，用时候从磁盘读入物理内存\n",
    "                                                # gpu需要通过页锁定内存中，把数据复制到gpu上\n",
    "                                                #  数据从cpu的可分页内存内存传到gpu时，需要先把数据复制到临时的页锁定内存，再赋值到gpu.速度更慢\n",
    "                                                #  如果指定pin_memory=True, batch的数据会直接被放在cpu的页锁定内存中，传到gpu时更快。少了一步复制\n",
    "                                                #  但页锁定内存会占用真实物理内存，分配过多会挤占别的程序的内存，把内存耗尽。因此内存小时不建议用\n",
    "                    sampler=None,             # 定义/自定义怎么从dataset里抽取每个batch的样本.还有一个batch_sampler参数\n",
    "                                              # 需要实现__iter__方法。返回针对所有样本id的迭代器，顺序按自定义的样本顺序排好\n",
    "                                              # 需要实现 __len__ ， 表示loader的一次抽取完成。一般同dataset样本数。\n",
    "                                              # 就不能定义shuffle了，因为策略自己实现了。shuffle只能在iter里自己做。加入随机性\n",
    "                                              # 每次loader会根据__iter__(和batch_size），迭代产生该epoch的每个batch。 \n",
    "                                              # 比如nlp会根据样本文本长度，将长度相近样本排一起：iter([25,3,60,0,...1])。使得每个batch长度接近\n",
    "                                              # 通过在__iter_里先切好batch,再shuffle,再整合。打乱每个epoch,batch间的执行顺序\n",
    "                                              # 可以设置RandomSampler每次随机采样。（可参考该实现等）                       \n",
    "                    num_workers=10            # 开多进程，每个进程计算一个batch。初始化时用之前提前处理好对应的n个batch。后续batch加入新的线程\n",
    "                   )                          # 初始化时会一次性建好n个进程。每个进程提前处理好要用的batch数据。（底层是 multiprocessing）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32d5890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num=3\n",
    "for epoch in range(epoch_num):\n",
    "    for batch_id,x in enumerate(trainloader):   # 把数据完整轮询一遍。对应一个epoch\n",
    "        # 输入模型\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5a26398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[17, 26, 59,  ..., 11, 12, 13],\n",
       "         [15, 27, 59,  ..., 11, 12, 13],\n",
       "         [15, 33, 62,  ..., 11, 12, 13],\n",
       "         ...,\n",
       "         [15, 32, 59,  ..., 11, 12, 13],\n",
       "         [15, 26, 59,  ..., 11, 12, 13],\n",
       "         [16, 26, 59,  ..., 11, 12, 13]]),\n",
       " tensor([[ 1.,  1.,  1.,  ...,  0.,  0.,  2.],\n",
       "         [ 1.,  1.,  1.,  ...,  2.,  0.,  3.],\n",
       "         [ 1.,  1.,  1.,  ...,  0.,  0.,  2.],\n",
       "         ...,\n",
       "         [ 1.,  1.,  1.,  ...,  2.,  0.,  0.],\n",
       "         [ 1.,  1.,  1.,  ...,  8.,  0., 68.],\n",
       "         [ 1.,  1.,  1.,  ...,  7.,  0., 22.]]),\n",
       " tensor([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "         1, 0, 0, 1, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "732b7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_p,f_v,y=x[0],x[1],x[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649aa906",
   "metadata": {},
   "source": [
    "### 原始FM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d13e0d",
   "metadata": {},
   "source": [
    "模型维持n个w,n个embedding，对应one-hot后的所有特征（这里还算上了缺失值对应的0参数）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e0034",
   "metadata": {},
   "source": [
    "二阶分数是$$\\sum_{i}^{n}\\sum_{j!=i}^{n}x_ix_j<\\vec{v_i},\\vec{v_j}>$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3827b2f",
   "metadata": {},
   "source": [
    "直接计算是$O(n^2*k)$。每对向量内积是$k$,共$O(n^2)$个pair。最后求和"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d74b52",
   "metadata": {},
   "source": [
    "等价于embedding们对应位置22相乘后，再求和。可以先求所有embedding每个维度元素22相乘的和，最后再对所有维度求和"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968764fe",
   "metadata": {},
   "source": [
    "$$\\sum_{i}^{n}\\sum_{j!=i}^{n}<\\vec{e_i},\\vec{e_j}>= \\sum_{f} \\sum_{i}^{n}\\sum_{j!=i}^{n}e_{if}*e_{jf} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d22070",
   "metadata": {},
   "source": [
    "embedding的每个维度元素22相乘的和： $ab+ac+bc= \\frac{1}{2}((a+b+c)^2-(a^2+b^2+c^2))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e537011",
   "metadata": {},
   "source": [
    "因此对固定维度，embedding的每个维度元素22相乘的和$\\sum_{i}^{n}\\sum_{j!=i}^{n}e_{if}*e_{jf}$ ，是$\\frac{1}{2}((e_{if}+e_{jf}...)^2-(e_{if}^2+e_{if}^2+...))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7a78d",
   "metadata": {},
   "source": [
    "可以通过每个embedding相加（对应位置相加）的平方，减去每个embedding平方的相加，得到（1，k）的向量，作为embedding的每个维度元素22交互的结果。最终的二阶分数是这k个维度的结果相加。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8ea15",
   "metadata": {},
   "source": [
    "也可以把这k维向量作为新的隐特征，输入后续网络。作为FM/deepFM的一个小变体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6985922",
   "metadata": {},
   "source": [
    "转化后，$\\frac{1}{2}((e_{if}+e_{jf}...)^2-(e_{if}^2+e_{if}^2+...))$的复杂度只有$O(n)$(n个元素相加或平方后相加)。加上维度F，总的复杂度可以降低到$O(nk)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4527e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self,n_field,n_features,embed_size,dropout=0):\n",
    "        \"\"\"\n",
    "        标准FM\n",
    "        n_field: 原始离散特征数目\n",
    "        n_features: 离散特征one-hot之后,和dense的总特征个数. 这里包含了一个缺失值特征向量，paddding成0\n",
    "        \"\"\"\n",
    "        super(FM, self).__init__()\n",
    "        self.n_field=n_field             # 原始特征数目\n",
    "        self.n_features=n_features       # 连续+离散特征的总数目 (离散特征one-hot+unique化后的。且算上最终的一个padding)\n",
    "        self.k=embed_size\n",
    "        \n",
    "        self.W=nn.Embedding(n_features,1,padding_idx=0)                       # 每个特征对应的wi。位置0是0对梯度无贡献。embedding默认是N(0,1)\n",
    "        self.w0=nn.Parameter(torch.zeros([1,]))                               # b初始化为0\n",
    "        self.feature_embed=nn.Embedding(n_features,embed_size,padding_idx=0)  # 每个特征对应的embedding\n",
    "        self.droplayer=nn.Dropout(dropout)\n",
    "        \n",
    "        self.scoreweight=nn.Parameter(0.5*torch.ones([2,]))                   # 一阶，二阶score的权重 \n",
    "                                                                              \n",
    "        self.__init_weight__()                                                # 初始化权重(可以不调用，用默认的)\n",
    "            \n",
    "    def __init_weight__(self):              # 初始化权重.默认是N(0,1)\n",
    "        inn=n_features-1\n",
    "        # kaiming_normal_\n",
    "        nn.init.kaiming_uniform_(self.feature_embed.weight[1:], mode='fan_in', nonlinearity='relu')  # sqrt(6/inn)\n",
    "        nn.init.normal_(self.W.weight[1:],0, np.sqrt(2.0 /inn))\n",
    "        \n",
    "    def forward(self,f_p,f_x): # B,n.  n是每个样本的原始特征数目\n",
    "        \"\"\"\n",
    "        f_p: (B,N)  每个样本的原始特征，根据特征名（连续特征）/特征取值（离散特征）被映射到embedding上的位置。 N:原始特征数目\n",
    "        f_x: (B,N)  每个样本的原始特征，对应的取值。 离散特征对应的是one-hot后的，所以在对应的f_p上取值为1\n",
    "        \"\"\"\n",
    "        batch_size=f_p.shape[0]\n",
    "        \n",
    "        # 一阶score\n",
    "        w=self.W(f_p).reshape(batch_size,-1)              # B,n   每个样本根据原始特征，找到对应位置处的w\n",
    "        y_score1=self.w0 + torch.sum(torch.mul(w,f_x),1)  # B,1   wixi+b  B,n -->   B,1.  要是不sum，也可以作为n个特征。之后作为deepFM的改造\n",
    "        \n",
    "        # 二阶score\n",
    "        embed=self.feature_embed(f_p)                     # B,n,d 每个样本根据原始特征，找到对应位置处的embedding\n",
    "        \n",
    "        embed=torch.mul(embed,f_x.unsqueeze(2))           # B,n,d 样本的每个向量乘上对应的xi： xi* embedding\n",
    "                                                          #       tf.mul:按位置乘.广播 (B,n,d) * (B,n,1) ->(B,n,d) \n",
    "                                                          #       离散特征对应的xi是1.假设数值型已经归一化\n",
    "        \n",
    "        #embed=self.droplayer(embed)\n",
    "        \n",
    "        # 每个filed 向量22交互\n",
    "        e_sum= torch.sum(embed,1)                         # B,d   每个样本。所有embedding对应维度元素相加，得到e_sum\n",
    "        e_sum_square=torch.square(e_sum)                  # B,d   (e_sum)^2\n",
    "        \n",
    "        e_square=torch.square(embed)                      # B,n,d  平方后的\n",
    "        e_square_sum=torch.sum(e_square,1)                # B,d    每个维度相加\n",
    "        \n",
    "        f =0.5*(e_sum_square-e_square_sum)                # B,d    n个embedding，每个维度元素22交互的结果（可作为新特征，拼接到后边）\n",
    "    \n",
    "        y_score2= torch.sum(f,1)                          # (B,)\n",
    "        \n",
    "        logits=y_score1+y_score2                          # (B,)   最终分数  y_score1*self.scoreweight[0] +..\n",
    "        \n",
    "        # TODO:loss加正则项（最后加）/ grad-clip等. 看下train-loop\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24089f",
   "metadata": {},
   "source": [
    "### 原始deepFM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ebe038",
   "metadata": {},
   "source": [
    "FM部分相同，但共享底层的embedding部分。把样本原始离散特征和连续特征映射得到的所有embedding，concat,作为后续mlp的输入。输出结果作为deep部分的score,和linear(FM)部分相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ddae6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepFM： 标准的。 或者上述k个元素作为特征统一拼到deep的\n",
    "class deepFM(nn.Module):\n",
    "    def __init__(self,n_field,n_features,embed_size,hiddens,dropout=0,batchnorm=True):\n",
    "        \"\"\"\n",
    "        标准DeepFM\n",
    "        n_field: 原始特征数目\n",
    "        n_features: 离散特征one-hot之后,和dense的总特征个数. 这里包含了一个缺失值特征向量，paddding成0\n",
    "        deep每层：linear + (bn) + relu + (dropout).  输出hidden层。  最后按需单独linear到1\n",
    "        \"\"\"\n",
    "        super(deepFM, self).__init__() \n",
    "        self.n_field=n_field             # 原始特征数目\n",
    "        self.n_features=n_features       # 连续+离散特征的总数目 (离散特征one-hot+unique化后的。且算上最终的一个padding)\n",
    "        self.k=embed_size\n",
    "        self.dropout=dropout\n",
    "        self.batchnorm=batchnorm\n",
    "        self.hiddens=hiddens             # hiddens:[256,64,32]\n",
    "    \n",
    "        # FM-part\n",
    "        self.W=nn.Embedding(n_features,1,padding_idx=0)                       # 每个特征对应的wi。位置0是0对梯度无贡献。embedding默认是N(0,1)\n",
    "        self.w0=nn.Parameter(torch.zeros([1,]))                               # b初始化为0\n",
    "        self.feature_embed=nn.Embedding(n_features,embed_size,padding_idx=0)  # 每个特征对应的embedding\n",
    "        self.droplayer=nn.Dropout(dropout)            \n",
    "        \n",
    "        #self.__init_wide_weight__()                                           # 初始化权重(可以不调用，用默认的)\n",
    "        \n",
    "        # deep-part.\n",
    "        input_size=n_field*embed_size                                         #输入是所有原始特征的embedding拼接   \n",
    "        self.mlp=self.build_mlp(input_size,hiddens)                           #多层mlp.输出hidden  是一个ModuleList\n",
    "        self.finallinear=nn.Linear(hiddens[-1],1,bias=True)                   #最后一层linear\n",
    "        \n",
    "        #self.__init_deep_weight__()                                           # 初始化权重。(可以按情况调用。现在用kaiming)\n",
    "            \n",
    "    def __init_wide_weight__(self):              # 初始化权重.默认是N(0,1)\n",
    "        inn=n_features-1\n",
    "        # kaiming_normal_\n",
    "        nn.init.kaiming_uniform_(self.feature_embed.weight[1:], mode='fan_in', nonlinearity='relu')  # sqrt(6/inn)\n",
    "        nn.init.normal_(self.W.weight[1:],0, np.sqrt(2.0 /inn))\n",
    "\n",
    "    def __init_deep_weight__(self):              # 初始化权重\n",
    "        for layer in self.mlp:\n",
    "            if (layer.__class__.__name__=='Linear'):  # 每层初始化\n",
    "                self.init_linear(layer)\n",
    "        self.init_linear(self.finallinear)\n",
    "        \n",
    "    def init_linear(self,layer):\n",
    "        nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')  #sqrt(2/inn) 或者 sqrt(2/out)\n",
    "        nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "    def build_mlp(self,input_size,hiddens):\n",
    "        \"\"\"\n",
    "        hiddens:[256,56,32]\n",
    "        输出最后一层的hidden节点 （dropout+激活后的），可直接linear+sigmoid到deepscore. 也可以拼其他特征后再linear\n",
    "        \"\"\"        \n",
    "        layers=nn.ModuleList()\n",
    "        \n",
    "        hiddens.insert(0,input_size)     #  [inputsize,256,56,32]\n",
    "        num_layer=len(hiddens)-1         #  3层\n",
    "        \n",
    "        for i in range(0,len(hiddens)-1):\n",
    "            \n",
    "            # 线性层\n",
    "            in_dim=hiddens[i]\n",
    "            out_dim=hiddens[i+1]\n",
    "            layer=nn.Linear(in_dim,out_dim,bias=True)\n",
    "            layers.append(layer)\n",
    "            \n",
    "            # BN\n",
    "            if self.batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(out_dim)) \n",
    "            \n",
    "            # active + dropout\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(self.dropout))\n",
    "                \n",
    "        return layers  # 拼成一个前后连接的网络。可以在forward里作为一个模块被整体调用\n",
    "    \n",
    "    \n",
    "    def forward(self,f_p,f_x): # B,n.  n是每个样本的原始特征数目\n",
    "        \"\"\"\n",
    "        f_p: (B,N)  每个样本的原始特征，根据特征名（连续特征）/特征取值（离散特征）被映射到embedding上的位置。 N:原始特征数目\n",
    "        f_x: (B,N)  每个样本的原始特征，对应的取值。 离散特征对应的是one-hot后的，所以在对应的f_p上取值为1\n",
    "        output:  FM和deep部分 score相加\n",
    "        \"\"\"\n",
    "        batch_size=f_p.shape[0]\n",
    "        \n",
    "        # FM-part    每个filed 向量22交互\n",
    "        w=self.W(f_p).reshape(batch_size,-1)              # B,n   每个样本根据原始特征，找到对应位置处的w\n",
    "        y_score1=self.w0 + torch.sum(torch.mul(w,f_x),1)  # B,1   wixi+b  B,n -->   B,1.  要是不sum，也可以作为n个特征。\n",
    "        \n",
    "        embed=self.feature_embed(f_p)                     # B,n,d 每个样本根据原始特征，找到对应位置处的embedding \n",
    "        embed=torch.mul(embed,f_x.unsqueeze(2))           # B,n,d 样本的每个向量乘上对应的xi： xi* embedding\n",
    "        e_sum= torch.sum(embed,1)                         # B,d   每个样本。所有embedding对应维度元素相加，得到e_sum\n",
    "        e_sum_square=torch.square(e_sum)                  # B,d   (e_sum)^2\n",
    "        e_square=torch.square(embed)                      # B,n,d  平方后的\n",
    "        e_square_sum=torch.sum(e_square,1)                # B,d    每个维度相加\n",
    "        f =0.5*(e_sum_square-e_square_sum)                # B,d    n个embedding，每个维度元素22交互的结果（可作为新特征，拼接到后边）\n",
    "        y_score2= torch.sum(f,1)                          # (B,)\n",
    "        \n",
    "        # deep-part\n",
    "        x=torch.reshape(embed,[-1,self.n_field*self.k])           # 输入是所有原始特征对应embedding的拼接\n",
    "        for layer in self.mlp:\n",
    "            if(layer.__class__.__name__=='Linear'):\n",
    "                print(x.shape,x.mean(),x.std())        # 可以画一下数据分布\n",
    "            x=layer(x)\n",
    "        \n",
    "        y_deep=self.finallinear(x).squeeze(-1)         # (B，)\n",
    "        \n",
    "        logits=y_score1+y_score2 +y_deep\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96836f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_field=len(dis_col+con_col)           # 原始特征数目\n",
    "n_features=len(f_trans.feature_id_map) # 连续+离散特征的总数目 (离散特征one-hot+unique化后的。且算上最终的一个padding)\n",
    "embed_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fb2ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "hiddens=[256,56,32]\n",
    "model=deepFM(n_field,n_features,embed_size,hiddens,dropout=0.5)\n",
    "#model=FM(n_field,n_features,embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d2f24ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepFM(\n",
       "  (W): Embedding(319, 1, padding_idx=0)\n",
       "  (feature_embed): Embedding(319, 8, padding_idx=0)\n",
       "  (droplayer): Dropout(p=0.5, inplace=False)\n",
       "  (mlp): ModuleList(\n",
       "    (0): Linear(in_features=312, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=56, bias=True)\n",
       "    (5): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=56, out_features=32, bias=True)\n",
       "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (finallinear): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba7855c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 312]) tensor(-267.7921, grad_fn=<MeanBackward0>) tensor(7412.6074, grad_fn=<StdBackward>)\n",
      "torch.Size([32, 256]) tensor(0.2178, grad_fn=<MeanBackward0>) tensor(1.0186, grad_fn=<StdBackward>)\n",
      "torch.Size([32, 56]) tensor(0.2547, grad_fn=<MeanBackward0>) tensor(1.1246, grad_fn=<StdBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 模拟一次forward\n",
    "logits=model(f_p,f_v)\n",
    "target=y\n",
    "loss_func= nn.BCEWithLogitsLoss()    #  mean [yn⋅logσ(xn)+(1−yn)⋅log(1−σ(xn))]\n",
    "loss=loss_func(logits,target.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dacb0652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e653abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6856e+07,  2.0494e+03,  2.8631e+02,  2.6076e+05, -4.1025e+03,\n",
       "         1.8989e+04, -9.5286e+03,  3.1135e+05,  8.2947e+06, -2.4730e+04,\n",
       "         1.9531e+05, -1.6658e+04, -1.4949e+04,  1.1009e+06, -1.0445e+05,\n",
       "         1.8215e+05,  1.0894e+05,  1.1513e+06,  6.1241e+06,  3.8426e+06,\n",
       "         2.7371e+05,  4.0723e+04, -2.5086e+03,  3.6061e+05,  6.7333e+05,\n",
       "         6.5259e+06,  8.9568e+04, -3.4668e+04,  3.0059e+05, -1.4897e+04,\n",
       "         6.6340e+05,  3.8886e+05], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4980064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1329974.2500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29b27111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.3655,  0.1447,  1.7108,  ..., -0.3539, -1.5231,  0.5709],\n",
       "        [ 1.0026, -2.1243,  1.0951,  ..., -1.6591,  1.1211,  1.6638],\n",
       "        ...,\n",
       "        [ 0.4362, -0.5719, -2.1344,  ..., -1.0841,  1.4919, -0.4240],\n",
       "        [-1.0858, -1.7406,  0.0946,  ...,  1.4830, -3.7626,  1.5078],\n",
       "        [ 0.7019, -0.2428,  0.1968,  ..., -1.1473,  0.2409, -0.6082]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_embed.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff6cb0",
   "metadata": {},
   "source": [
    "### train_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e3141",
   "metadata": {},
   "source": [
    "正常trainloop + reg + grad_clip  + CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf6000a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StandardScaler()\n",
    "ss.fit(raw_df[con_col])                           #归一化\n",
    "raw_df[con_col]=ss.transform(raw_df[con_col])     # 测试做相同处理\n",
    "\n",
    "f_trans=FeaturePosTrans(dis_col,con_col,10)           # 映射到对应id. 出现10次以下的作为UNK\n",
    "f_trans.fit(raw_df)\n",
    "feature_pos,feature_values=f_trans.transform(raw_df)  # 测试集做相同处理。用相同的原始con_col,dis_col。 总的\n",
    "\n",
    "cols=dis_col+con_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff5727",
   "metadata": {},
   "source": [
    "处理过的数据，划分cv。 训练5个模型，用5个模型的平均作为最终结果（同时也保存这5个模型。作为衡量该模型最终表现的量度）\n",
    "也可以有放回的每次随机采样一份：df.sample(frac=0.7,random_state =i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "192a3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf=StratifiedKFold(n_splits=5,random_state=2020,shuffle=True)    # 分割器。按y值对给定的样本划分。返回分好的样本id 每轮4:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85cafbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(train_index,dev_index) in enumerate(skf.split(raw_df,raw_df[label])): # 可用于df. 根据y，输出分割后的train/dev样本位置\n",
    "    logger.info(\"训练第%s折对应的模型\",i)                                    # 每个fold训一个模型\n",
    "    \n",
    "    train_fv=feature_values[cols].iloc[train_index].values                # 按样本位置，从转换好的df里取训练样本\n",
    "    train_fp=feature_pos[cols].iloc[train_index].values\n",
    "    train_label=raw_df[label].iloc[train_index].values\n",
    "    trainDataset=Mydata(train_fv,train_fp, train_label)                   # 对应的dataset\n",
    "    \n",
    "    dev_fv=feature_values[cols].iloc[dev_index].values                    # dev场景下，主要是计算指标。model不输出loss\n",
    "    dev_fp=feature_pos[cols].iloc[dev_index].values\n",
    "    dev_label=raw_df[label].iloc[dev_index].values\n",
    "    dev_dataset=Mydata(dev_fv,dev_fp, dev_label)\n",
    "    \n",
    "    #train(train_dataset,dev_dataset)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65834824",
   "metadata": {},
   "source": [
    "建立一个class,用来封装基本模型。预测，保存，重新加载等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cb915d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置随机种子。每次训练固定  \n",
    "def set_seed(args):\n",
    "    random.seed(args.random_seed)\n",
    "    np.random.seed(args.random_seed)\n",
    "    torch.manual_seed(args.random_seed)\n",
    "    \n",
    "class WrapModel(object):\n",
    "    def __init__(self,args=None,state_dict=None):\n",
    "        # 初始化模型\n",
    "        n_field=len(args.dis_col+args.con_col)                # 原始特征数目\n",
    "        n_features=len(args.f_trans.feature_id_map)           # 连续+离散特征one-hot后的特征总数目 (算上一个NAN padding)\n",
    "        model=FM(n_field,n_features,args.embed_size,args.dropout)\n",
    "        #self.model=deepFM(n_field,n_features,args.embed_size,args.hiddens,args.dropout,args.batchnorm)\n",
    "        \n",
    "        if state_dict:                                        # 加载保存过的模型参数（如果有）\n",
    "            model.load_state_dict(state_dict)\n",
    "        \n",
    "        device = torch.device(\"cuda\" if args.cuda else \"cpu\") # 放gpu上\n",
    "        model.to(device)   \n",
    "        self.model=model\n",
    "        self.args=args\n",
    "        set_seed(args)\n",
    "        \n",
    "    def train(self,train_dataset,dev_dataset=None):        # 参考jupyter的loss画图\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        \n",
    "    def infer(self,test_dataset):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def eval_metric(self,labels,preds):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def save(self,filename):\n",
    "        '保存超参数和内部模型的模型参数'\n",
    "        params = {\n",
    "            'state_dict': self.model.state_dict(),   # 只按参数名称保存模型所有参数。是一个dict.不保存模型结构\n",
    "            'args': self.args,\n",
    "        }\n",
    "        torch.save(params, filename)           # 保存static等到指定文件中。 这里可以保存字典，之后通过load加载进来（底层pickle）\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filename):   \n",
    "        '直接根据文件名，返回加载好内部模型参数的WraPModel（init时通过state_dict）.可以在外边直接调用：WrapModel.load(f)'\n",
    "        saved_params = torch.load(\n",
    "            filename, map_location=lambda storage, loc: storage  # load默认直接加载到GPU.  这样指定，先加载到cpu上。再load_state\n",
    "        )\n",
    "        state_dict = saved_params['state_dict']\n",
    "        args = saved_params['args']\n",
    "        \n",
    "        return WrapModel(args,state_dict)     \n",
    "    \n",
    "    def export_onnx(self,onnx_filename):\n",
    "        '需要用到nn.Module等'\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "209d57e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()                             # 超参数\n",
    "parser.add_argument('--embed_size', type=int, default=8)\n",
    "parser.add_argument('--hiddens', type=str, default='256,56,32',help='deepfm的mlp层数')\n",
    "parser.add_argument('--dropout', type=float, default=0,help='默认没有dropout')\n",
    "parser.add_argument('--batchnorm', type=bool, default=False,help='默认没有batchnorm')\n",
    "parser.add_argument('--epoch', type=int, default=5)\n",
    "parser.add_argument('--lr', type=float, default=8e-5)\n",
    "parser.add_argument('--max_grad_norm', type=float, default=1.0)\n",
    "parser.add_argument('--no-cuda', type=bool, default=False,help='是否用GPU')\n",
    "parser.add_argument('--gpu', type=int, default=0,help='GPU设备id')\n",
    "parser.add_argument('--random_seed', type=int, default=2020)\n",
    "parser.add_argument('--eval_steps', type=int, default=500)\n",
    "parser.add_argument('--display_steps', type=int, default=100)\n",
    "parser.add_argument('--eval_batch_size', type=int, default=4096)\n",
    "args = parser.parse_args(args=[])                              # jupyter里需要加args=[]\n",
    "args.dis_col=dis_col\n",
    "args.con_col=con_col\n",
    "args.f_trans=f_trans\n",
    "args.hiddens=args.hiddens.split(',')\n",
    "# 设置设备为某固定gpu\n",
    "args.cuda = (not args.no_cuda)  and  (torch.cuda.is_available())\n",
    "if args.cuda:\n",
    "    torch.cuda.set_device(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8bcbbf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(embed_size=8, hiddens=['256', '56', '32'], dropout=0, batchnorm=False, epoch=5, lr=8e-05, max_grad_norm=1.0, no_cuda=False, gpu=0, random_seed=2020, eval_steps=500, display_steps=100, eval_batch_size=4096, dis_col=['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26'], con_col=['I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13'], f_trans=FeaturePosTrans(con_col=['I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9',\n",
       "                         'I10', 'I11', 'I12', 'I13'],\n",
       "                dis_col=['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9',\n",
       "                         'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17',\n",
       "                         'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25',\n",
       "                         'C26'],\n",
       "                limit_freq=10), cuda=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e5486bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTRmodel=WrapModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "374b49cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1766, -0.2691, -0.1574,  ...,  0.3566,  0.5657,  0.2922],\n",
       "        [-0.3409,  0.5294,  0.4841,  ..., -0.5336,  0.6542, -0.6717],\n",
       "        ...,\n",
       "        [-0.6886,  0.8462,  0.0508,  ..., -0.4379,  0.2559, -0.7336],\n",
       "        [-0.7355,  0.2774,  0.3422,  ...,  0.2255,  0.4101,  0.2945],\n",
       "        [ 0.5182, -0.1089, -0.3929,  ...,  0.1849,  0.1977,  0.4575]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTRmodel.model.feature_embed.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6532d971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('w0', tensor([0.], device='cuda:0')),\n",
       "             ('scoreweight', tensor([0.5000, 0.5000], device='cuda:0')),\n",
       "             ('W.weight',\n",
       "              tensor([[ 0.0000],\n",
       "                      [-0.1039],\n",
       "                      [ 0.0776],\n",
       "                      [-0.0221],\n",
       "                      [ 0.0267],\n",
       "                      [ 0.0459],\n",
       "                      [ 0.2359],\n",
       "                      [ 0.0497],\n",
       "                      [-0.1051],\n",
       "                      [-0.1409],\n",
       "                      [ 0.0386],\n",
       "                      [-0.1200],\n",
       "                      [-0.0636],\n",
       "                      [ 0.0275],\n",
       "                      [-0.0110],\n",
       "                      [-0.0185],\n",
       "                      [-0.1234],\n",
       "                      [ 0.1108],\n",
       "                      [ 0.0785],\n",
       "                      [ 0.0503],\n",
       "                      [ 0.1735],\n",
       "                      [-0.0716],\n",
       "                      [-0.0673],\n",
       "                      [-0.0094],\n",
       "                      [ 0.0527],\n",
       "                      [ 0.0322],\n",
       "                      [ 0.0400],\n",
       "                      [ 0.0657],\n",
       "                      [ 0.0198],\n",
       "                      [ 0.0373],\n",
       "                      [ 0.0488],\n",
       "                      [ 0.1180],\n",
       "                      [-0.0098],\n",
       "                      [-0.0645],\n",
       "                      [-0.0515],\n",
       "                      [-0.0021],\n",
       "                      [ 0.0697],\n",
       "                      [ 0.1584],\n",
       "                      [ 0.1129],\n",
       "                      [-0.0297],\n",
       "                      [ 0.0192],\n",
       "                      [ 0.2403],\n",
       "                      [ 0.0038],\n",
       "                      [ 0.0919],\n",
       "                      [ 0.0174],\n",
       "                      [-0.1707],\n",
       "                      [ 0.0729],\n",
       "                      [-0.1205],\n",
       "                      [-0.0589],\n",
       "                      [ 0.0334],\n",
       "                      [ 0.0653],\n",
       "                      [-0.0358],\n",
       "                      [ 0.0274],\n",
       "                      [-0.0285],\n",
       "                      [ 0.0917],\n",
       "                      [ 0.0920],\n",
       "                      [-0.0271],\n",
       "                      [ 0.0289],\n",
       "                      [ 0.0218],\n",
       "                      [ 0.0052],\n",
       "                      [ 0.0273],\n",
       "                      [ 0.1292],\n",
       "                      [-0.0698],\n",
       "                      [ 0.0239],\n",
       "                      [-0.0768],\n",
       "                      [ 0.0594],\n",
       "                      [ 0.0475],\n",
       "                      [ 0.1532],\n",
       "                      [ 0.0046],\n",
       "                      [-0.0508],\n",
       "                      [-0.0024],\n",
       "                      [-0.0894],\n",
       "                      [ 0.0049],\n",
       "                      [-0.0858],\n",
       "                      [ 0.1301],\n",
       "                      [-0.0564],\n",
       "                      [ 0.0991],\n",
       "                      [ 0.0202],\n",
       "                      [ 0.0544],\n",
       "                      [-0.0162],\n",
       "                      [ 0.0024],\n",
       "                      [-0.0814],\n",
       "                      [ 0.0937],\n",
       "                      [ 0.0142],\n",
       "                      [-0.0725],\n",
       "                      [ 0.0445],\n",
       "                      [ 0.1032],\n",
       "                      [ 0.1201],\n",
       "                      [-0.0816],\n",
       "                      [-0.1586],\n",
       "                      [ 0.0238],\n",
       "                      [-0.0438],\n",
       "                      [-0.0193],\n",
       "                      [ 0.0851],\n",
       "                      [ 0.0663],\n",
       "                      [-0.1082],\n",
       "                      [-0.1375],\n",
       "                      [ 0.1096],\n",
       "                      [ 0.0883],\n",
       "                      [ 0.0370],\n",
       "                      [-0.0063],\n",
       "                      [-0.0370],\n",
       "                      [ 0.0864],\n",
       "                      [ 0.0547],\n",
       "                      [ 0.0235],\n",
       "                      [-0.0126],\n",
       "                      [-0.1032],\n",
       "                      [ 0.0418],\n",
       "                      [ 0.0172],\n",
       "                      [-0.1514],\n",
       "                      [-0.0667],\n",
       "                      [ 0.0179],\n",
       "                      [ 0.1299],\n",
       "                      [ 0.0281],\n",
       "                      [ 0.0261],\n",
       "                      [ 0.0176],\n",
       "                      [ 0.0693],\n",
       "                      [-0.0379],\n",
       "                      [-0.0841],\n",
       "                      [-0.0409],\n",
       "                      [ 0.0276],\n",
       "                      [-0.1237],\n",
       "                      [-0.0942],\n",
       "                      [ 0.0942],\n",
       "                      [-0.0671],\n",
       "                      [-0.0666],\n",
       "                      [-0.0152],\n",
       "                      [ 0.0048],\n",
       "                      [-0.0902],\n",
       "                      [-0.0257],\n",
       "                      [-0.0822],\n",
       "                      [-0.0141],\n",
       "                      [-0.0605],\n",
       "                      [-0.1069],\n",
       "                      [ 0.1189],\n",
       "                      [ 0.0145],\n",
       "                      [ 0.0265],\n",
       "                      [-0.0157],\n",
       "                      [-0.0785],\n",
       "                      [ 0.0878],\n",
       "                      [-0.0606],\n",
       "                      [-0.0418],\n",
       "                      [ 0.0388],\n",
       "                      [-0.0356],\n",
       "                      [-0.0385],\n",
       "                      [-0.0309],\n",
       "                      [ 0.0251],\n",
       "                      [ 0.1127],\n",
       "                      [ 0.0878],\n",
       "                      [-0.0507],\n",
       "                      [ 0.0710],\n",
       "                      [ 0.0279],\n",
       "                      [ 0.0281],\n",
       "                      [-0.1153],\n",
       "                      [-0.1337],\n",
       "                      [-0.1197],\n",
       "                      [-0.1602],\n",
       "                      [-0.0873],\n",
       "                      [ 0.0376],\n",
       "                      [-0.0363],\n",
       "                      [ 0.0753],\n",
       "                      [ 0.0110],\n",
       "                      [ 0.0114],\n",
       "                      [-0.0228],\n",
       "                      [ 0.1223],\n",
       "                      [ 0.1364],\n",
       "                      [ 0.0442],\n",
       "                      [ 0.1772],\n",
       "                      [ 0.1389],\n",
       "                      [ 0.0082],\n",
       "                      [ 0.0315],\n",
       "                      [ 0.0748],\n",
       "                      [ 0.1243],\n",
       "                      [-0.0537],\n",
       "                      [ 0.0234],\n",
       "                      [-0.1526],\n",
       "                      [ 0.0447],\n",
       "                      [-0.0458],\n",
       "                      [-0.0899],\n",
       "                      [ 0.1091],\n",
       "                      [-0.0526],\n",
       "                      [-0.0505],\n",
       "                      [-0.1039],\n",
       "                      [ 0.0808],\n",
       "                      [-0.0206],\n",
       "                      [ 0.1241],\n",
       "                      [ 0.0985],\n",
       "                      [ 0.0621],\n",
       "                      [ 0.0053],\n",
       "                      [-0.0146],\n",
       "                      [-0.0208],\n",
       "                      [ 0.1168],\n",
       "                      [-0.1083],\n",
       "                      [-0.0754],\n",
       "                      [ 0.0258],\n",
       "                      [ 0.1187],\n",
       "                      [ 0.0440],\n",
       "                      [-0.2344],\n",
       "                      [ 0.0106],\n",
       "                      [-0.0472],\n",
       "                      [-0.0605],\n",
       "                      [-0.0929],\n",
       "                      [ 0.0857],\n",
       "                      [-0.0450],\n",
       "                      [-0.0218],\n",
       "                      [-0.1069],\n",
       "                      [-0.0256],\n",
       "                      [ 0.0852],\n",
       "                      [ 0.0064],\n",
       "                      [ 0.0238],\n",
       "                      [ 0.0812],\n",
       "                      [-0.0316],\n",
       "                      [-0.0393],\n",
       "                      [-0.0856],\n",
       "                      [ 0.0065],\n",
       "                      [ 0.0657],\n",
       "                      [-0.1094],\n",
       "                      [ 0.0380],\n",
       "                      [-0.1823],\n",
       "                      [-0.0826],\n",
       "                      [ 0.0374],\n",
       "                      [ 0.0155],\n",
       "                      [-0.0569],\n",
       "                      [ 0.0671],\n",
       "                      [ 0.0459],\n",
       "                      [-0.0492],\n",
       "                      [ 0.0150],\n",
       "                      [-0.1352],\n",
       "                      [-0.0740],\n",
       "                      [-0.0490],\n",
       "                      [ 0.0590],\n",
       "                      [ 0.0428],\n",
       "                      [ 0.0332],\n",
       "                      [-0.0464],\n",
       "                      [-0.0125],\n",
       "                      [-0.0636],\n",
       "                      [-0.0836],\n",
       "                      [ 0.0268],\n",
       "                      [ 0.0685],\n",
       "                      [-0.1277],\n",
       "                      [ 0.0221],\n",
       "                      [-0.0108],\n",
       "                      [-0.0258],\n",
       "                      [-0.1894],\n",
       "                      [-0.0423],\n",
       "                      [-0.2007],\n",
       "                      [-0.0154],\n",
       "                      [ 0.0205],\n",
       "                      [ 0.1866],\n",
       "                      [-0.0311],\n",
       "                      [-0.0539],\n",
       "                      [ 0.0396],\n",
       "                      [ 0.0057],\n",
       "                      [ 0.1404],\n",
       "                      [ 0.0005],\n",
       "                      [-0.0543],\n",
       "                      [-0.0145],\n",
       "                      [-0.1151],\n",
       "                      [ 0.1509],\n",
       "                      [-0.0220],\n",
       "                      [ 0.1188],\n",
       "                      [-0.0335],\n",
       "                      [-0.1259],\n",
       "                      [-0.0254],\n",
       "                      [ 0.0261],\n",
       "                      [ 0.0744],\n",
       "                      [-0.0459],\n",
       "                      [-0.0738],\n",
       "                      [ 0.0540],\n",
       "                      [-0.0396],\n",
       "                      [-0.0395],\n",
       "                      [-0.1056],\n",
       "                      [-0.0373],\n",
       "                      [ 0.0949],\n",
       "                      [-0.1473],\n",
       "                      [ 0.0353],\n",
       "                      [-0.1727],\n",
       "                      [ 0.0110],\n",
       "                      [-0.0364],\n",
       "                      [ 0.0041],\n",
       "                      [-0.1076],\n",
       "                      [ 0.0244],\n",
       "                      [ 0.0235],\n",
       "                      [-0.0935],\n",
       "                      [ 0.0403],\n",
       "                      [-0.0785],\n",
       "                      [-0.0016],\n",
       "                      [ 0.0151],\n",
       "                      [-0.1224],\n",
       "                      [ 0.0315],\n",
       "                      [ 0.0866],\n",
       "                      [-0.0389],\n",
       "                      [ 0.1940],\n",
       "                      [ 0.0041],\n",
       "                      [ 0.1437],\n",
       "                      [ 0.0067],\n",
       "                      [-0.0642],\n",
       "                      [ 0.0216],\n",
       "                      [ 0.0087],\n",
       "                      [-0.0280],\n",
       "                      [-0.0884],\n",
       "                      [ 0.1065],\n",
       "                      [ 0.1458],\n",
       "                      [ 0.0538],\n",
       "                      [-0.0406],\n",
       "                      [ 0.0593],\n",
       "                      [ 0.0091],\n",
       "                      [ 0.0202],\n",
       "                      [-0.0569],\n",
       "                      [ 0.0123],\n",
       "                      [-0.0718],\n",
       "                      [ 0.0394],\n",
       "                      [ 0.0637],\n",
       "                      [ 0.0809],\n",
       "                      [-0.0137],\n",
       "                      [-0.0122],\n",
       "                      [ 0.1680],\n",
       "                      [-0.0798],\n",
       "                      [-0.1258]], device='cuda:0')),\n",
       "             ('feature_embed.weight',\n",
       "              tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                      [ 0.1766, -0.2691, -0.1574,  ...,  0.3566,  0.5657,  0.2922],\n",
       "                      [-0.3409,  0.5294,  0.4841,  ..., -0.5336,  0.6542, -0.6717],\n",
       "                      ...,\n",
       "                      [-0.6886,  0.8462,  0.0508,  ..., -0.4379,  0.2559, -0.7336],\n",
       "                      [-0.7355,  0.2774,  0.3422,  ...,  0.2255,  0.4101,  0.2945],\n",
       "                      [ 0.5182, -0.1089, -0.3929,  ...,  0.1849,  0.1977,  0.4575]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTRmodel.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2811af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTRmodel.save(\"pytorch_state.bt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0f8badc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTRmodelload=WrapModel.load(\"pytorch_state.bt\")  # 静态方法。不需要事先new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9763f2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('w0', tensor([0.], device='cuda:0')),\n",
       "             ('scoreweight', tensor([0.5000, 0.5000], device='cuda:0')),\n",
       "             ('W.weight',\n",
       "              tensor([[ 0.0000],\n",
       "                      [-0.1039],\n",
       "                      [ 0.0776],\n",
       "                      [-0.0221],\n",
       "                      [ 0.0267],\n",
       "                      [ 0.0459],\n",
       "                      [ 0.2359],\n",
       "                      [ 0.0497],\n",
       "                      [-0.1051],\n",
       "                      [-0.1409],\n",
       "                      [ 0.0386],\n",
       "                      [-0.1200],\n",
       "                      [-0.0636],\n",
       "                      [ 0.0275],\n",
       "                      [-0.0110],\n",
       "                      [-0.0185],\n",
       "                      [-0.1234],\n",
       "                      [ 0.1108],\n",
       "                      [ 0.0785],\n",
       "                      [ 0.0503],\n",
       "                      [ 0.1735],\n",
       "                      [-0.0716],\n",
       "                      [-0.0673],\n",
       "                      [-0.0094],\n",
       "                      [ 0.0527],\n",
       "                      [ 0.0322],\n",
       "                      [ 0.0400],\n",
       "                      [ 0.0657],\n",
       "                      [ 0.0198],\n",
       "                      [ 0.0373],\n",
       "                      [ 0.0488],\n",
       "                      [ 0.1180],\n",
       "                      [-0.0098],\n",
       "                      [-0.0645],\n",
       "                      [-0.0515],\n",
       "                      [-0.0021],\n",
       "                      [ 0.0697],\n",
       "                      [ 0.1584],\n",
       "                      [ 0.1129],\n",
       "                      [-0.0297],\n",
       "                      [ 0.0192],\n",
       "                      [ 0.2403],\n",
       "                      [ 0.0038],\n",
       "                      [ 0.0919],\n",
       "                      [ 0.0174],\n",
       "                      [-0.1707],\n",
       "                      [ 0.0729],\n",
       "                      [-0.1205],\n",
       "                      [-0.0589],\n",
       "                      [ 0.0334],\n",
       "                      [ 0.0653],\n",
       "                      [-0.0358],\n",
       "                      [ 0.0274],\n",
       "                      [-0.0285],\n",
       "                      [ 0.0917],\n",
       "                      [ 0.0920],\n",
       "                      [-0.0271],\n",
       "                      [ 0.0289],\n",
       "                      [ 0.0218],\n",
       "                      [ 0.0052],\n",
       "                      [ 0.0273],\n",
       "                      [ 0.1292],\n",
       "                      [-0.0698],\n",
       "                      [ 0.0239],\n",
       "                      [-0.0768],\n",
       "                      [ 0.0594],\n",
       "                      [ 0.0475],\n",
       "                      [ 0.1532],\n",
       "                      [ 0.0046],\n",
       "                      [-0.0508],\n",
       "                      [-0.0024],\n",
       "                      [-0.0894],\n",
       "                      [ 0.0049],\n",
       "                      [-0.0858],\n",
       "                      [ 0.1301],\n",
       "                      [-0.0564],\n",
       "                      [ 0.0991],\n",
       "                      [ 0.0202],\n",
       "                      [ 0.0544],\n",
       "                      [-0.0162],\n",
       "                      [ 0.0024],\n",
       "                      [-0.0814],\n",
       "                      [ 0.0937],\n",
       "                      [ 0.0142],\n",
       "                      [-0.0725],\n",
       "                      [ 0.0445],\n",
       "                      [ 0.1032],\n",
       "                      [ 0.1201],\n",
       "                      [-0.0816],\n",
       "                      [-0.1586],\n",
       "                      [ 0.0238],\n",
       "                      [-0.0438],\n",
       "                      [-0.0193],\n",
       "                      [ 0.0851],\n",
       "                      [ 0.0663],\n",
       "                      [-0.1082],\n",
       "                      [-0.1375],\n",
       "                      [ 0.1096],\n",
       "                      [ 0.0883],\n",
       "                      [ 0.0370],\n",
       "                      [-0.0063],\n",
       "                      [-0.0370],\n",
       "                      [ 0.0864],\n",
       "                      [ 0.0547],\n",
       "                      [ 0.0235],\n",
       "                      [-0.0126],\n",
       "                      [-0.1032],\n",
       "                      [ 0.0418],\n",
       "                      [ 0.0172],\n",
       "                      [-0.1514],\n",
       "                      [-0.0667],\n",
       "                      [ 0.0179],\n",
       "                      [ 0.1299],\n",
       "                      [ 0.0281],\n",
       "                      [ 0.0261],\n",
       "                      [ 0.0176],\n",
       "                      [ 0.0693],\n",
       "                      [-0.0379],\n",
       "                      [-0.0841],\n",
       "                      [-0.0409],\n",
       "                      [ 0.0276],\n",
       "                      [-0.1237],\n",
       "                      [-0.0942],\n",
       "                      [ 0.0942],\n",
       "                      [-0.0671],\n",
       "                      [-0.0666],\n",
       "                      [-0.0152],\n",
       "                      [ 0.0048],\n",
       "                      [-0.0902],\n",
       "                      [-0.0257],\n",
       "                      [-0.0822],\n",
       "                      [-0.0141],\n",
       "                      [-0.0605],\n",
       "                      [-0.1069],\n",
       "                      [ 0.1189],\n",
       "                      [ 0.0145],\n",
       "                      [ 0.0265],\n",
       "                      [-0.0157],\n",
       "                      [-0.0785],\n",
       "                      [ 0.0878],\n",
       "                      [-0.0606],\n",
       "                      [-0.0418],\n",
       "                      [ 0.0388],\n",
       "                      [-0.0356],\n",
       "                      [-0.0385],\n",
       "                      [-0.0309],\n",
       "                      [ 0.0251],\n",
       "                      [ 0.1127],\n",
       "                      [ 0.0878],\n",
       "                      [-0.0507],\n",
       "                      [ 0.0710],\n",
       "                      [ 0.0279],\n",
       "                      [ 0.0281],\n",
       "                      [-0.1153],\n",
       "                      [-0.1337],\n",
       "                      [-0.1197],\n",
       "                      [-0.1602],\n",
       "                      [-0.0873],\n",
       "                      [ 0.0376],\n",
       "                      [-0.0363],\n",
       "                      [ 0.0753],\n",
       "                      [ 0.0110],\n",
       "                      [ 0.0114],\n",
       "                      [-0.0228],\n",
       "                      [ 0.1223],\n",
       "                      [ 0.1364],\n",
       "                      [ 0.0442],\n",
       "                      [ 0.1772],\n",
       "                      [ 0.1389],\n",
       "                      [ 0.0082],\n",
       "                      [ 0.0315],\n",
       "                      [ 0.0748],\n",
       "                      [ 0.1243],\n",
       "                      [-0.0537],\n",
       "                      [ 0.0234],\n",
       "                      [-0.1526],\n",
       "                      [ 0.0447],\n",
       "                      [-0.0458],\n",
       "                      [-0.0899],\n",
       "                      [ 0.1091],\n",
       "                      [-0.0526],\n",
       "                      [-0.0505],\n",
       "                      [-0.1039],\n",
       "                      [ 0.0808],\n",
       "                      [-0.0206],\n",
       "                      [ 0.1241],\n",
       "                      [ 0.0985],\n",
       "                      [ 0.0621],\n",
       "                      [ 0.0053],\n",
       "                      [-0.0146],\n",
       "                      [-0.0208],\n",
       "                      [ 0.1168],\n",
       "                      [-0.1083],\n",
       "                      [-0.0754],\n",
       "                      [ 0.0258],\n",
       "                      [ 0.1187],\n",
       "                      [ 0.0440],\n",
       "                      [-0.2344],\n",
       "                      [ 0.0106],\n",
       "                      [-0.0472],\n",
       "                      [-0.0605],\n",
       "                      [-0.0929],\n",
       "                      [ 0.0857],\n",
       "                      [-0.0450],\n",
       "                      [-0.0218],\n",
       "                      [-0.1069],\n",
       "                      [-0.0256],\n",
       "                      [ 0.0852],\n",
       "                      [ 0.0064],\n",
       "                      [ 0.0238],\n",
       "                      [ 0.0812],\n",
       "                      [-0.0316],\n",
       "                      [-0.0393],\n",
       "                      [-0.0856],\n",
       "                      [ 0.0065],\n",
       "                      [ 0.0657],\n",
       "                      [-0.1094],\n",
       "                      [ 0.0380],\n",
       "                      [-0.1823],\n",
       "                      [-0.0826],\n",
       "                      [ 0.0374],\n",
       "                      [ 0.0155],\n",
       "                      [-0.0569],\n",
       "                      [ 0.0671],\n",
       "                      [ 0.0459],\n",
       "                      [-0.0492],\n",
       "                      [ 0.0150],\n",
       "                      [-0.1352],\n",
       "                      [-0.0740],\n",
       "                      [-0.0490],\n",
       "                      [ 0.0590],\n",
       "                      [ 0.0428],\n",
       "                      [ 0.0332],\n",
       "                      [-0.0464],\n",
       "                      [-0.0125],\n",
       "                      [-0.0636],\n",
       "                      [-0.0836],\n",
       "                      [ 0.0268],\n",
       "                      [ 0.0685],\n",
       "                      [-0.1277],\n",
       "                      [ 0.0221],\n",
       "                      [-0.0108],\n",
       "                      [-0.0258],\n",
       "                      [-0.1894],\n",
       "                      [-0.0423],\n",
       "                      [-0.2007],\n",
       "                      [-0.0154],\n",
       "                      [ 0.0205],\n",
       "                      [ 0.1866],\n",
       "                      [-0.0311],\n",
       "                      [-0.0539],\n",
       "                      [ 0.0396],\n",
       "                      [ 0.0057],\n",
       "                      [ 0.1404],\n",
       "                      [ 0.0005],\n",
       "                      [-0.0543],\n",
       "                      [-0.0145],\n",
       "                      [-0.1151],\n",
       "                      [ 0.1509],\n",
       "                      [-0.0220],\n",
       "                      [ 0.1188],\n",
       "                      [-0.0335],\n",
       "                      [-0.1259],\n",
       "                      [-0.0254],\n",
       "                      [ 0.0261],\n",
       "                      [ 0.0744],\n",
       "                      [-0.0459],\n",
       "                      [-0.0738],\n",
       "                      [ 0.0540],\n",
       "                      [-0.0396],\n",
       "                      [-0.0395],\n",
       "                      [-0.1056],\n",
       "                      [-0.0373],\n",
       "                      [ 0.0949],\n",
       "                      [-0.1473],\n",
       "                      [ 0.0353],\n",
       "                      [-0.1727],\n",
       "                      [ 0.0110],\n",
       "                      [-0.0364],\n",
       "                      [ 0.0041],\n",
       "                      [-0.1076],\n",
       "                      [ 0.0244],\n",
       "                      [ 0.0235],\n",
       "                      [-0.0935],\n",
       "                      [ 0.0403],\n",
       "                      [-0.0785],\n",
       "                      [-0.0016],\n",
       "                      [ 0.0151],\n",
       "                      [-0.1224],\n",
       "                      [ 0.0315],\n",
       "                      [ 0.0866],\n",
       "                      [-0.0389],\n",
       "                      [ 0.1940],\n",
       "                      [ 0.0041],\n",
       "                      [ 0.1437],\n",
       "                      [ 0.0067],\n",
       "                      [-0.0642],\n",
       "                      [ 0.0216],\n",
       "                      [ 0.0087],\n",
       "                      [-0.0280],\n",
       "                      [-0.0884],\n",
       "                      [ 0.1065],\n",
       "                      [ 0.1458],\n",
       "                      [ 0.0538],\n",
       "                      [-0.0406],\n",
       "                      [ 0.0593],\n",
       "                      [ 0.0091],\n",
       "                      [ 0.0202],\n",
       "                      [-0.0569],\n",
       "                      [ 0.0123],\n",
       "                      [-0.0718],\n",
       "                      [ 0.0394],\n",
       "                      [ 0.0637],\n",
       "                      [ 0.0809],\n",
       "                      [-0.0137],\n",
       "                      [-0.0122],\n",
       "                      [ 0.1680],\n",
       "                      [-0.0798],\n",
       "                      [-0.1258]], device='cuda:0')),\n",
       "             ('feature_embed.weight',\n",
       "              tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                      [ 0.1766, -0.2691, -0.1574,  ...,  0.3566,  0.5657,  0.2922],\n",
       "                      [-0.3409,  0.5294,  0.4841,  ..., -0.5336,  0.6542, -0.6717],\n",
       "                      ...,\n",
       "                      [-0.6886,  0.8462,  0.0508,  ..., -0.4379,  0.2559, -0.7336],\n",
       "                      [-0.7355,  0.2774,  0.3422,  ...,  0.2255,  0.4101,  0.2945],\n",
       "                      [ 0.5182, -0.1089, -0.3929,  ...,  0.1849,  0.1977,  0.4575]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTRmodelload.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04f6711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
