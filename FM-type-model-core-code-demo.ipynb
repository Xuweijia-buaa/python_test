{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5dd31b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from importlib import reload\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import argparse\n",
    "import random\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "from transformers import (AdamW, get_linear_schedule_with_warmup)\n",
    "from torchkeras import summary\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a13175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup file handler\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "           #logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler  = logging.FileHandler('my.log')\n",
    "fhandler.setLevel(logging.DEBUG)\n",
    "fhandler.setFormatter(formatter)\n",
    " \n",
    "# Configure stream handler for the cells\n",
    "chandler = logging.StreamHandler()\n",
    "chandler.setLevel(logging.DEBUG)\n",
    "chandler.setFormatter(formatter)\n",
    " \n",
    "# Add both handlers\n",
    "logger.addHandler(fhandler)\n",
    "logger.addHandler(chandler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e2da3",
   "metadata": {},
   "source": [
    "数据处理\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee50b9",
   "metadata": {},
   "source": [
    "1 得到原始数据和离散，连续列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c58c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/media/xuweijia/DATA/代码/python_test/data/Criteo/demo_data/'\n",
    "file_name='train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f64db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>e88ffc9d</td>\n",
       "      <td>c393dc22</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>57c90cd9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>4d19a3eb</td>\n",
       "      <td>cb079c2d</td>\n",
       "      <td>456c12a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>92555263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242bb710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>72c78f11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>25c88e42</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>a0136dd2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>f37f3967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>c3abeb21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>642f2610</td>\n",
       "      <td>1d1eb838</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>1640d50b</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>45ab94c8</td>\n",
       "      <td>2bf691b1</td>\n",
       "      <td>c84c4aec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>fc35e8fe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a02708ad</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c3dc6cef</td>\n",
       "      <td>502f2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>eea796be</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>2b0a9d11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7453e535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dbb486d7</td>\n",
       "      <td>906e72ec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>817481a8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e4244d7f</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c7dc6720</td>\n",
       "      <td>60efe6e6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2005abd1</td>\n",
       "      <td>1cdbd1c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288eaded</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label   I1   I2    I3    I4      I5     I6     I7    I8     I9  ...  \\\n",
       "0         1  1.0    0   1.0   NaN   227.0    1.0  173.0  18.0   50.0  ...   \n",
       "1         1  4.0    1   1.0   2.0    27.0    2.0    4.0   2.0    2.0  ...   \n",
       "2         1  0.0  806   NaN   NaN  1752.0  142.0    2.0   0.0   50.0  ...   \n",
       "3         0  2.0   -1  42.0  14.0   302.0   38.0   25.0  38.0   90.0  ...   \n",
       "4         1  0.0   57   2.0   1.0  2891.0    2.0   35.0   1.0  137.0  ...   \n",
       "...     ...  ...  ...   ...   ...     ...    ...    ...   ...    ...  ...   \n",
       "1594      0  NaN    8   1.0   1.0    43.0    NaN    0.0   1.0    1.0  ...   \n",
       "1595      0  8.0    2  20.0   8.0    36.0    9.0    8.0  10.0    8.0  ...   \n",
       "1596      0  0.0    1   2.0  12.0  4877.0  140.0   13.0  34.0  136.0  ...   \n",
       "1597      0  NaN    2   NaN   1.0  1972.0    NaN    0.0   1.0   14.0  ...   \n",
       "1598      1  NaN   34   3.0   4.0     NaN    NaN    0.0   4.0   14.0  ...   \n",
       "\n",
       "           C17       C18       C19       C20       C21       C22       C23  \\\n",
       "0     3486227d  e88ffc9d  c393dc22  b1252a9d  57c90cd9       NaN  bcdee96c   \n",
       "1     07c540c4  92555263       NaN       NaN  242bb710       NaN  3a171ecb   \n",
       "2     07c540c4  25c88e42  21ddcdc9  b1252a9d  a0136dd2       NaN  32c7478e   \n",
       "3     e5ba7672  5aed7436  21ddcdc9  b1252a9d  c3abeb21       NaN  423fab69   \n",
       "4     e5ba7672  642f2610  1d1eb838  b1252a9d  1640d50b  ad3062eb  423fab69   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1594  1e88c74f  fc35e8fe       NaN       NaN  a02708ad  c9d4222a  c3dc6cef   \n",
       "1595  e5ba7672  5aed7436  21ddcdc9  b1252a9d  eea796be       NaN  3a171ecb   \n",
       "1596  e5ba7672  2b0a9d11       NaN       NaN  7453e535       NaN  dbb486d7   \n",
       "1597  e5ba7672  817481a8       NaN       NaN  e4244d7f  c9d4222a  c7dc6720   \n",
       "1598  2005abd1  1cdbd1c5       NaN       NaN  288eaded  c9d4222a  bcdee96c   \n",
       "\n",
       "           C24       C25       C26  \n",
       "0     4d19a3eb  cb079c2d  456c12a0  \n",
       "1     72c78f11       NaN       NaN  \n",
       "2     8fc66e78  001f3601  f37f3967  \n",
       "3     1793a828  e8b83407  5cef228f  \n",
       "4     45ab94c8  2bf691b1  c84c4aec  \n",
       "...        ...       ...       ...  \n",
       "1594  502f2493       NaN       NaN  \n",
       "1595  1793a828  e8b83407  5cef228f  \n",
       "1596  906e72ec       NaN       NaN  \n",
       "1597  60efe6e6       NaN       NaN  \n",
       "1598  8fc66e78       NaN       NaN  \n",
       "\n",
       "[1599 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get raw data\n",
    "raw_df=pd.read_csv(os.path.join(data_path+file_name))\n",
    "raw_df=raw_df.drop([\"Id\"],axis=1)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b5d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别找出连续列/离散列\n",
    "def col_type(df):\n",
    "    dis_col=[]\n",
    "    con_col=[]\n",
    "    columns=df.columns.tolist()\n",
    "    for c in columns:\n",
    "        if df[c].dtype=='int64' or df[c].dtype=='float':\n",
    "            con_col.append(c)\n",
    "        else:\n",
    "            dis_col.append(c)\n",
    "    return dis_col,con_col\n",
    "dis_col,con_col=col_type(raw_df)\n",
    "con_col.remove(\"Label\")\n",
    "label=\"Label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59912c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[con_col].values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68807a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认是float64(double). 降低到float32. 与torch默认的兼容\n",
    "raw_df[con_col]=raw_df[con_col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f207e533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[con_col].values.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d7b1e",
   "metadata": {},
   "source": [
    "2 填充缺失值：数值型填0； 类别填空字符串，到时候也编码进去 （测试数据的缺失值用同样字符填充。相同编码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737e366a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>e88ffc9d</td>\n",
       "      <td>c393dc22</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>57c90cd9</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>4d19a3eb</td>\n",
       "      <td>cb079c2d</td>\n",
       "      <td>456c12a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>92555263</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>242bb710</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>72c78f11</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>25c88e42</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>a0136dd2</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>f37f3967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>c3abeb21</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>642f2610</td>\n",
       "      <td>1d1eb838</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>1640d50b</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>45ab94c8</td>\n",
       "      <td>2bf691b1</td>\n",
       "      <td>c84c4aec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>fc35e8fe</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>a02708ad</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c3dc6cef</td>\n",
       "      <td>502f2493</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>eea796be</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>2b0a9d11</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>7453e535</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>dbb486d7</td>\n",
       "      <td>906e72ec</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>817481a8</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>e4244d7f</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c7dc6720</td>\n",
       "      <td>60efe6e6</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2005abd1</td>\n",
       "      <td>1cdbd1c5</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>288eaded</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label   I1     I2    I3    I4      I5     I6     I7    I8     I9  ...  \\\n",
       "0         1  1.0    0.0   1.0   0.0   227.0    1.0  173.0  18.0   50.0  ...   \n",
       "1         1  4.0    1.0   1.0   2.0    27.0    2.0    4.0   2.0    2.0  ...   \n",
       "2         1  0.0  806.0   0.0   0.0  1752.0  142.0    2.0   0.0   50.0  ...   \n",
       "3         0  2.0   -1.0  42.0  14.0   302.0   38.0   25.0  38.0   90.0  ...   \n",
       "4         1  0.0   57.0   2.0   1.0  2891.0    2.0   35.0   1.0  137.0  ...   \n",
       "...     ...  ...    ...   ...   ...     ...    ...    ...   ...    ...  ...   \n",
       "1594      0  0.0    8.0   1.0   1.0    43.0    0.0    0.0   1.0    1.0  ...   \n",
       "1595      0  8.0    2.0  20.0   8.0    36.0    9.0    8.0  10.0    8.0  ...   \n",
       "1596      0  0.0    1.0   2.0  12.0  4877.0  140.0   13.0  34.0  136.0  ...   \n",
       "1597      0  0.0    2.0   0.0   1.0  1972.0    0.0    0.0   1.0   14.0  ...   \n",
       "1598      1  0.0   34.0   3.0   4.0     0.0    0.0    0.0   4.0   14.0  ...   \n",
       "\n",
       "           C17       C18       C19       C20       C21       C22       C23  \\\n",
       "0     3486227d  e88ffc9d  c393dc22  b1252a9d  57c90cd9    <NULL>  bcdee96c   \n",
       "1     07c540c4  92555263    <NULL>    <NULL>  242bb710    <NULL>  3a171ecb   \n",
       "2     07c540c4  25c88e42  21ddcdc9  b1252a9d  a0136dd2    <NULL>  32c7478e   \n",
       "3     e5ba7672  5aed7436  21ddcdc9  b1252a9d  c3abeb21    <NULL>  423fab69   \n",
       "4     e5ba7672  642f2610  1d1eb838  b1252a9d  1640d50b  ad3062eb  423fab69   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1594  1e88c74f  fc35e8fe    <NULL>    <NULL>  a02708ad  c9d4222a  c3dc6cef   \n",
       "1595  e5ba7672  5aed7436  21ddcdc9  b1252a9d  eea796be    <NULL>  3a171ecb   \n",
       "1596  e5ba7672  2b0a9d11    <NULL>    <NULL>  7453e535    <NULL>  dbb486d7   \n",
       "1597  e5ba7672  817481a8    <NULL>    <NULL>  e4244d7f  c9d4222a  c7dc6720   \n",
       "1598  2005abd1  1cdbd1c5    <NULL>    <NULL>  288eaded  c9d4222a  bcdee96c   \n",
       "\n",
       "           C24       C25       C26  \n",
       "0     4d19a3eb  cb079c2d  456c12a0  \n",
       "1     72c78f11    <NULL>    <NULL>  \n",
       "2     8fc66e78  001f3601  f37f3967  \n",
       "3     1793a828  e8b83407  5cef228f  \n",
       "4     45ab94c8  2bf691b1  c84c4aec  \n",
       "...        ...       ...       ...  \n",
       "1594  502f2493    <NULL>    <NULL>  \n",
       "1595  1793a828  e8b83407  5cef228f  \n",
       "1596  906e72ec    <NULL>    <NULL>  \n",
       "1597  60efe6e6    <NULL>    <NULL>  \n",
       "1598  8fc66e78    <NULL>    <NULL>  \n",
       "\n",
       "[1599 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_token = '<NULL>'\n",
    "raw_df[dis_col]=raw_df[dis_col].fillna(null_token)\n",
    "raw_df[con_col]=raw_df[con_col].fillna(0)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1131d",
   "metadata": {},
   "source": [
    "3 可以做一些特征处理上的优化。比如数值型归一化。离散特征出现次数小于某阈值的，值都编码成\\<UNK\\>。这里忽略，假设已经做过了.也做过了特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f1832",
   "metadata": {},
   "source": [
    "4 离散特征label-encode. 保存原始值到label的映射。之后根据映射后的id找对应embedding （取值10个以内的one-hot,作为新特征）\n",
    "  如果想同一列加工出不同特征。可以用FeatureUnion和自定义transformer来选择列。 （如对文本列同时加工长度和tfidf两个特征）\n",
    "  ColumnTransformer对同一列只能做一个操作。如果不对同一列做不同操作，就用这个就可以。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b53bf00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load FM_helper/LabelEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b2430f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>...</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>...</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>30.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        C1     C2      C3     C4    C5   C6     C7    C8   C9    C10  ...  \\\n",
       "0     33.0   27.0   486.0  572.0   1.0  1.0  459.0   1.0  1.0  465.0  ...   \n",
       "1      0.0   98.0   170.0  287.0   1.0  3.0  550.0  21.0  1.0  683.0  ...   \n",
       "2      0.0   28.0   114.0  696.0  11.0  3.0  704.0   1.0  1.0  133.0  ...   \n",
       "3      0.0   12.0   650.0  243.0   1.0  3.0  329.0   1.0  1.0   27.0  ...   \n",
       "4      0.0   36.0   517.0   70.0   1.0  3.0   20.0   2.0  1.0  166.0  ...   \n",
       "...    ...    ...     ...    ...   ...  ...    ...   ...  ...    ...  ...   \n",
       "1594   0.0   93.0   617.0  801.0   1.0  1.0   25.0  12.0  1.0   28.0  ...   \n",
       "1595  30.0   12.0  1034.0  243.0   1.0  6.0  935.0   1.0  1.0  454.0  ...   \n",
       "1596  30.0  113.0   676.0    7.0   1.0  6.0  185.0  14.0  1.0  485.0  ...   \n",
       "1597   0.0   48.0   565.0  727.0   1.0  6.0  377.0   0.0  1.0  202.0  ...   \n",
       "1598   0.0  155.0   286.0  768.0   1.0  6.0  590.0   1.0  0.0  166.0  ...   \n",
       "\n",
       "          I5     I6     I7    I8     I9  I10   I11  I12   I13  Label  \n",
       "0      227.0    1.0  173.0  18.0   50.0  1.0   7.0  1.0   0.0    1.0  \n",
       "1       27.0    2.0    4.0   2.0    2.0  1.0   1.0  0.0   2.0    1.0  \n",
       "2     1752.0  142.0    2.0   0.0   50.0  0.0   1.0  0.0   0.0    1.0  \n",
       "3      302.0   38.0   25.0  38.0   90.0  1.0   3.0  0.0  38.0    0.0  \n",
       "4     2891.0    2.0   35.0   1.0  137.0  0.0  17.0  0.0   1.0    1.0  \n",
       "...      ...    ...    ...   ...    ...  ...   ...  ...   ...    ...  \n",
       "1594    43.0    0.0    0.0   1.0    1.0  0.0   0.0  0.0   1.0    0.0  \n",
       "1595    36.0    9.0    8.0  10.0    8.0  1.0   1.0  0.0   8.0    0.0  \n",
       "1596  4877.0  140.0   13.0  34.0  136.0  0.0   2.0  0.0  12.0    0.0  \n",
       "1597  1972.0    0.0    0.0   1.0   14.0  0.0   0.0  0.0   1.0    0.0  \n",
       "1598     0.0    0.0    0.0   4.0   14.0  0.0   0.0  0.0   4.0    1.0  \n",
       "\n",
       "[1599 rows x 40 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接当做包，引用py中函数\n",
    "# labelencoding。\n",
    "from FM_helper import LabelEncoder\n",
    "reload(LabelEncoder)\n",
    "trans,new_con_col,new_dis_col,df,raw_df2,cate_counts,cate_feature_map=LabelEncoder.labelencode_trans(raw_df,dis_col,con_col,label)\n",
    "# 测试.只需要保存大transformer和最终的dis_col,con_col。 用来做转化，以及识别转换后的两类特征。 \n",
    "LabelEncoder.test(raw_df,trans,new_con_col,new_dis_col,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a1e46",
   "metadata": {},
   "source": [
    "标准FM\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd23e3",
   "metadata": {},
   "source": [
    "公式："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395db68",
   "metadata": {},
   "source": [
    "$$y= b+ \\sum_{i}w_ix_i  + \\sum_{i}^{n}\\sum_{j!=i}^{n}x_ix_j<\\vec{v_i},\\vec{v_j}>$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899f7a5",
   "metadata": {},
   "source": [
    "一阶同LR. 每个连续特征对应一个$w_i$,每个离散特征one-hot之后的特征作为新特征，对应一个$w_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0fd6b1",
   "metadata": {},
   "source": [
    "二阶交互，每个连续特征对应一个embedding。每个离散特征的每个每个特征的每个取值对应一个embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997451f0",
   "metadata": {},
   "source": [
    "因此每个连续特征$x_i$,对应一个$w_i$,一个embedding，用来和其他特征交互。\n",
    "   每个离散特征域，对应one-hot之后的C个特征$x_i$，对应C个$w_i$,C个embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818520f1",
   "metadata": {},
   "source": [
    "但对每个样本来说，该离散特征one-hot之后，只会根据取值取到一个embedding，一个$w_i$<br/>(该离散特征对一阶的贡献，只有根据样本该离散特征取值映射到的$w_i$，对应取值$x_i$是1,其他C-1位置由于one-hot,该样本下取值$x_i$都是0,贡献是0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a62e344",
   "metadata": {},
   "source": [
    "因此总共需要维护（所有连续特征+所有离散特征的所有取值)个特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82c11d",
   "metadata": {},
   "source": [
    "假设所有连续特征和one-hot后的所有离散特征共F个,总共需要维护F个特征。可以根据特征名称，把每个特征映射到一个固定id上（位置）:<br/>\n",
    "每个连续特征对应一个id                            <br/>\n",
    "每个离散特征的每个取值对应一个id                    <br/>\n",
    "每个id都维护一个$w_i$,一个embedding，对应该特征在W（F,1）,embedding(F,d)中的位置。<br/>\n",
    "之后每个样本，都可以根据特征位置去找对应的$w_i$,embedding：       <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca8dd50",
   "metadata": {},
   "source": [
    "因此在对每个样本进行映射时，需要分别得到样本每个特征的位置（id）和取值$x_i$："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d5c8dd",
   "metadata": {},
   "source": [
    "位置映射：样本的所有特征都被映射到对应位置,用来找对应的$w_i$,embedding。每个连续特征对应的就是位置id。每个离散域，根据样本在该域的取值映射到对应id。n个离散域，对应n个embedding,n个$w_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012662c",
   "metadata": {},
   "source": [
    "样本取值：连续特征的取值不变（或者归一化），离散特征取值1，作为样本的$x_i$输入。n个离散域，对应的n个取值，$x_i$都是1。在one-hot后的对应位置上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2400cb9",
   "metadata": {},
   "source": [
    "### 对原始特征进行映射。得到one-hot之后的所有特征（含连续特征）到位置id的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde59bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "class FeaturePosTrans(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, dis_col=None, con_col= None, limit_freq = 0):\n",
    "        self.dis_col=dis_col\n",
    "        self.con_col=con_col\n",
    "        self.limit_freq=limit_freq\n",
    "        \n",
    "        self.NULL = '<NULL>'\n",
    "        self.UNK = '<UNK>'                                                # nlp里。低频是1，NAN是0. NAN作为padding,不参与训练且是0\n",
    "                                                                          # NAN对应embedding： padding_index=0.只占位，不训练）\n",
    "                                                                          # nn.Embedding(V,d,padding_idx=0\n",
    "    \n",
    "        self.dis_col_map=dict()                                            # 按特征，记录取值到位置id的映射  只用来存着\n",
    "        self.feature_id_map=dict()                                         # 特征名到位置id的映射大表 {特征名_取值：位置id}\n",
    "        self.pos=0                                                         # 位置id\n",
    "        self.dis_col_count=dict()                                          # 每个离散特征的取值数目\n",
    "        \n",
    "        \n",
    "        # 所有离散的缺失值，统一用NAN编码，之后在w，E中padding成0\n",
    "        self.feature_id_map[self.NULL]=0\n",
    "        self.pos+=1\n",
    "        \n",
    "        if (con_col!=None):\n",
    "            self.feature_id_map.update(dict(zip(con_col,range(self.pos,self.pos+len(con_col))))) # 连续特征到对应位置的映射\n",
    "            self.pos+=len(self.con_col)\n",
    "\n",
    "    def fit(self, X , y = None):\n",
    "        \n",
    "        if (self.dis_col!=None):\n",
    "            # 每个离散特征取值,映射到对应id\n",
    "            for col in self.dis_col:\n",
    "                valueCount=dict(X[col].value_counts())                       # 该离散特征。每个取值的出现数目\n",
    "                # 是否特殊处理低频取值\n",
    "                if self.limit_freq>0:\n",
    "                    values=[k for k,v in valueCount.items() if k!=self.NULL and v>self.limit_freq]  # 该特征留下的取值\n",
    "                    self.dis_col_map[col]=dict(zip(values,range(self.pos+1,self.pos+1+len(values))))\n",
    "                    self.dis_col_map[col][self.UNK]=self.pos\n",
    "                    # 组织大表。类似\n",
    "                    new_values=[col+\"_\"+v for v in values]                    # { C1_v1：id}  \n",
    "                    self.feature_id_map.update(dict(zip(new_values,range(self.pos+1,self.pos+1+len(new_values)))))\n",
    "                    self.feature_id_map[col+\"_\"+self.UNK]=self.pos\n",
    "                    self.pos+=len(new_values)+1                              # 每个特征留下：所有高频取值+UNK                                   \n",
    "                else:\n",
    "                    # 每个特征。分别记录映射\n",
    "                    values=[k for k in valueCount.keys() if k!=self.NULL]    # 该离散特征所有取值（除缺失值） \n",
    "                    self.dis_col_map[col]=dict(zip(values,range(self.pos,self.pos+len(values))))\n",
    "                    # 类似，但根据取值记在大map里\n",
    "                    new_values=[col+\"_\"+v for v in values]                   # { C1_v1：id}  \n",
    "                    self.feature_id_map.update(dict(zip(new_values,range(self.pos,self.pos+len(new_values)))))\n",
    "                    self.pos+=len(new_values)\n",
    "                    \n",
    "                 # 每个离散特征的有效取值数目(不含NAN，含每个特征的unk)\n",
    "                self.dis_col_count[col]=len(self.dis_col_map[col])                            \n",
    "                                                                               \n",
    "    def transform(self, X, label=None):        \n",
    "        # 映射：\n",
    "        feature_pos=X.copy()                        # 样本每个特征对应的位置\n",
    "        feature_values=X.copy()                     # 样本每个特征的取值。离散特征取值是1.  \n",
    "        cols=self.dis_col+self.con_col    \n",
    "        \n",
    "        # 如果有target列，删掉target列\n",
    "        if label in feature_pos.columns:\n",
    "            feature_pos=feature_pos.drop([label], axis=1)\n",
    "            feature_values=feature_values.drop([label], axis=1)    # 特征列去掉label\n",
    "        \n",
    "        for col in cols:\n",
    "            if col in self.dis_col:\n",
    "                #values=X[col].apply(self.gen,args=(col,)).values\n",
    "                values=X[col].apply(self.gen2,args=(col,)).values    # 组织形式不同。映射效果相同。用这个好些\n",
    "                feature_pos[col]=values\n",
    "                feature_values[col]=1.0\n",
    "            else:\n",
    "                feature_pos[col]=self.feature_id_map[col]            # 连续特征取值不变  。 位置是映射后的id \n",
    "        \n",
    "        # 映射完的取值（包括离散特征取值1.0），也都变成float32\n",
    "        feature_values=feature_values.astype(np.float32)\n",
    "        \n",
    "        return feature_pos,feature_values\n",
    "        \n",
    "    # 如果是多列。传入的x是该列对应的series. 输出的是这些列拼起来的df\n",
    "    # 如果是单列，传入的x是该列的每个元素    输出的是该列对应的Series\n",
    "    # 根据离散特征取值，返回对应的位置id\n",
    "    def gen(self,x,col):\n",
    "        if x==self.NULL:                                        # NAN统一映射到0\n",
    "            return 0\n",
    "        else:\n",
    "            if x in self.dis_col_map[col]:\n",
    "                return self.dis_col_map[col][x]                 # 按取值，映射到对应位置id\n",
    "            else:\n",
    "                if self.limit_freq>0:\n",
    "                    return self.dis_col_map[col][self.UNK]       # 低频取值/没见过的值。映射到unqkey对应的编码 \n",
    "                else:\n",
    "                    return 0                                     # 没见过的值。映射到NAN==0。没有贡献\n",
    "\n",
    "    # 用大表做映射。类似\n",
    "    def gen2(self,x,col):    \n",
    "        if x==self.NULL:                                         # NAN统一映射到0\n",
    "            return 0\n",
    "        else:\n",
    "            x=col+\"_\"+x\n",
    "            if x in self.feature_id_map:                         # 其他按取值，映射到对应位置id\n",
    "                return self.feature_id_map[x]                 \n",
    "            else:\n",
    "                if self.limit_freq>0:                \n",
    "                    return self.feature_id_map[col+\"_\"+self.UNK] # 低频取值/没见过的值。映射到该特征unqkey对应的编码 \n",
    "                else:\n",
    "                    return 0                                     # 没见过的值。映射到NAN。没有贡献\n",
    "                \n",
    "    def id2name(self):\n",
    "        return dict(zip(self.feature_id_map.values(),self.feature_id_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b92fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10',\n",
       "       'I11', 'I12', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8',\n",
       "       'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18',\n",
       "       'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80f89ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from FM_helper import Fmdata\n",
    "#reload(Fmdata)\n",
    "#f_trans=Fmdata.FeaturePosTrans(dis_col,con_col,10)\n",
    "f_trans=FeaturePosTrans(dis_col,con_col,10)             # 出现10次以下的作为UNK\n",
    "f_trans.fit(raw_df)\n",
    "feature_pos,feature_values=f_trans.transform(raw_df,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4622628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_trans.feature_id_map)  # 离散特征one-hot后，总的特征数目. NAN+con_col+all_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9310c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<NULL>': 0,\n",
       " 'I1': 1,\n",
       " 'I2': 2,\n",
       " 'I3': 3,\n",
       " 'I4': 4,\n",
       " 'I5': 5,\n",
       " 'I6': 6,\n",
       " 'I7': 7,\n",
       " 'I8': 8,\n",
       " 'I9': 9,\n",
       " 'I10': 10,\n",
       " 'I11': 11,\n",
       " 'I12': 12,\n",
       " 'I13': 13,\n",
       " 'C1_05db9164': 15,\n",
       " 'C1_68fd1e64': 16,\n",
       " 'C1_5a9ed9b0': 17,\n",
       " 'C1_8cf07265': 18,\n",
       " 'C1_be589b51': 19,\n",
       " 'C1_5bfa8ab5': 20,\n",
       " 'C1_f473b8dc': 21,\n",
       " 'C1_87552397': 22,\n",
       " 'C1_ae82ea21': 23,\n",
       " 'C1_39af2607': 24,\n",
       " 'C1_9a89b36c': 25,\n",
       " 'C1_<UNK>': 14,\n",
       " 'C2_38a947a1': 27,\n",
       " 'C2_09e68b86': 28,\n",
       " 'C2_80e26c9b': 29,\n",
       " 'C2_d833535f': 30,\n",
       " 'C2_4f25e98b': 31,\n",
       " 'C2_287130e0': 32,\n",
       " 'C2_0a519c5c': 33,\n",
       " 'C2_08d6d899': 34,\n",
       " 'C2_4c2bc594': 35,\n",
       " 'C2_38d50e09': 36,\n",
       " 'C2_207b2d81': 37,\n",
       " 'C2_58e67aaf': 38,\n",
       " 'C2_2c16a946': 39,\n",
       " 'C2_942f9a8d': 40,\n",
       " 'C2_8947f767': 41,\n",
       " 'C2_421b43cd': 42,\n",
       " 'C2_0468d672': 43,\n",
       " 'C2_8084ee93': 44,\n",
       " 'C2_78ccd99e': 45,\n",
       " 'C2_1cfdf714': 46,\n",
       " 'C2_68b3edbf': 47,\n",
       " 'C2_e112a9de': 48,\n",
       " 'C2_95e2d337': 49,\n",
       " 'C2_e5fb1af3': 50,\n",
       " 'C2_39dfaa0d': 51,\n",
       " 'C2_e77e5e6e': 52,\n",
       " 'C2_9819deea': 53,\n",
       " 'C2_8cc9c66e': 54,\n",
       " 'C2_f0cf0024': 55,\n",
       " 'C2_3df44d94': 56,\n",
       " 'C2_ae46a29d': 57,\n",
       " 'C2_26a88120': 58,\n",
       " 'C2_<UNK>': 26,\n",
       " 'C3_d032c263': 60,\n",
       " 'C3_b00d1501': 61,\n",
       " 'C3_77f2f2e5': 62,\n",
       " 'C3_aa8c1539': 63,\n",
       " 'C3_02cf9876': 64,\n",
       " 'C3_ad4b77ff': 65,\n",
       " 'C3_9143c832': 66,\n",
       " 'C3_e346a5fd': 67,\n",
       " 'C3_<UNK>': 59,\n",
       " 'C4_d16679b9': 69,\n",
       " 'C4_c18be181': 70,\n",
       " 'C4_85dd697c': 71,\n",
       " 'C4_f922efad': 72,\n",
       " 'C4_13508380': 73,\n",
       " 'C4_29998ed1': 74,\n",
       " 'C4_f56b7dd5': 75,\n",
       " 'C4_<UNK>': 68,\n",
       " 'C5_25c83c98': 77,\n",
       " 'C5_4cf72387': 78,\n",
       " 'C5_43b19349': 79,\n",
       " 'C5_384874ce': 80,\n",
       " 'C5_30903e74': 81,\n",
       " 'C5_0942e0a7': 82,\n",
       " 'C5_f281d2a7': 83,\n",
       " 'C5_b0530c50': 84,\n",
       " 'C5_<UNK>': 76,\n",
       " 'C6_7e0ccccf': 86,\n",
       " 'C6_fbad5c96': 87,\n",
       " 'C6_fe6b92e5': 88,\n",
       " 'C6_13718bbd': 89,\n",
       " 'C6_6f6d9be8': 90,\n",
       " 'C6_3bf701e7': 91,\n",
       " 'C6_<UNK>': 85,\n",
       " 'C7_38eb9cf4': 93,\n",
       " 'C7_3f4ec687': 94,\n",
       " 'C7_970f01b2': 95,\n",
       " 'C7_9b98e9fc': 96,\n",
       " 'C7_49b74ebc': 97,\n",
       " 'C7_d0bdaa98': 98,\n",
       " 'C7_468a0854': 99,\n",
       " 'C7_dc7659bd': 100,\n",
       " 'C7_26a81064': 101,\n",
       " 'C7_88002ee1': 102,\n",
       " 'C7_<UNK>': 92,\n",
       " 'C8_0b153874': 104,\n",
       " 'C8_5b392875': 105,\n",
       " 'C8_1f89b562': 106,\n",
       " 'C8_37e4aa92': 107,\n",
       " 'C8_062b5529': 108,\n",
       " 'C8_51d76abe': 109,\n",
       " 'C8_c8ddd494': 110,\n",
       " 'C8_64523cfa': 111,\n",
       " 'C8_6c41e35e': 112,\n",
       " 'C8_66f29b89': 113,\n",
       " 'C8_<UNK>': 103,\n",
       " 'C9_a73ee510': 115,\n",
       " 'C9_7cc72ec2': 116,\n",
       " 'C9_<UNK>': 114,\n",
       " 'C10_3b08e48b': 118,\n",
       " 'C10_fbbf2c95': 119,\n",
       " 'C10_fa7d0797': 120,\n",
       " 'C10_0e9ead52': 121,\n",
       " 'C10_efea433b': 122,\n",
       " 'C10_6c47047a': 123,\n",
       " 'C10_5ba575e7': 124,\n",
       " 'C10_dcbc7c2b': 125,\n",
       " 'C10_451bd4e4': 126,\n",
       " 'C10_<UNK>': 117,\n",
       " 'C11_7f8ffe57': 128,\n",
       " 'C11_c4adf918': 129,\n",
       " 'C11_e51ddf94': 130,\n",
       " 'C11_5874c9c9': 131,\n",
       " 'C11_9e511730': 132,\n",
       " 'C11_a7b606c4': 133,\n",
       " 'C11_f25fe7e9': 134,\n",
       " 'C11_4ba74619': 135,\n",
       " 'C11_36bccca0': 136,\n",
       " 'C11_dd6fc8cb': 137,\n",
       " 'C11_b7094596': 138,\n",
       " 'C11_<UNK>': 127,\n",
       " 'C12_dfbb09fb': 140,\n",
       " 'C12_e0d76380': 141,\n",
       " 'C12_9f32b866': 142,\n",
       " 'C12_d8c29807': 143,\n",
       " 'C12_8fe001f4': 144,\n",
       " 'C12_a2f4e8b5': 145,\n",
       " 'C12_6aaba33c': 146,\n",
       " 'C12_ae1bb660': 147,\n",
       " 'C12_b99ddbc8': 148,\n",
       " 'C12_539c5644': 149,\n",
       " 'C12_<UNK>': 139,\n",
       " 'C13_46f42a63': 151,\n",
       " 'C13_85dbe138': 152,\n",
       " 'C13_80467802': 153,\n",
       " 'C13_ebd756bd': 154,\n",
       " 'C13_3516f6e6': 155,\n",
       " 'C13_740c210d': 156,\n",
       " 'C13_6e5da64f': 157,\n",
       " 'C13_04e4a7e0': 158,\n",
       " 'C13_eae197fd': 159,\n",
       " 'C13_dd183b4c': 160,\n",
       " 'C13_879fa878': 161,\n",
       " 'C13_1f9d2c38': 162,\n",
       " 'C13_605bbc24': 163,\n",
       " 'C13_949ea585': 164,\n",
       " 'C13_b55434a9': 165,\n",
       " 'C13_<UNK>': 150,\n",
       " 'C14_07d13a8f': 167,\n",
       " 'C14_b28479f6': 168,\n",
       " 'C14_1adce6ef': 169,\n",
       " 'C14_8ceecbc8': 170,\n",
       " 'C14_64c94865': 171,\n",
       " 'C14_cfef1c29': 172,\n",
       " 'C14_051219e6': 173,\n",
       " 'C14_f862f261': 174,\n",
       " 'C14_<UNK>': 166,\n",
       " 'C15_36721ddc': 176,\n",
       " 'C15_7ac43a46': 177,\n",
       " 'C15_52baadf5': 178,\n",
       " 'C15_a733d362': 179,\n",
       " 'C15_0f942372': 180,\n",
       " 'C15_10040656': 181,\n",
       " 'C15_d2f03b75': 182,\n",
       " 'C15_dfab705f': 183,\n",
       " 'C15_dbc5e126': 184,\n",
       " 'C15_8ab5b746': 185,\n",
       " 'C15_41f10449': 186,\n",
       " 'C15_1150f5ed': 187,\n",
       " 'C15_2ee9f086': 188,\n",
       " 'C15_2d0bb053': 189,\n",
       " 'C15_9efd8b77': 190,\n",
       " 'C15_4c1df281': 191,\n",
       " 'C15_3628a186': 192,\n",
       " 'C15_f3635baf': 193,\n",
       " 'C15_bfef54b3': 194,\n",
       " 'C15_ac182643': 195,\n",
       " 'C15_b760dcb7': 196,\n",
       " 'C15_<UNK>': 175,\n",
       " 'C16_84898b2a': 198,\n",
       " 'C16_1203a270': 199,\n",
       " 'C16_31ca40b6': 200,\n",
       " 'C16_c64d548f': 201,\n",
       " 'C16_36103458': 202,\n",
       " 'C16_89052618': 203,\n",
       " 'C16_b041b04a': 204,\n",
       " 'C16_bad5ee18': 205,\n",
       " 'C16_87acb535': 206,\n",
       " 'C16_aafa191e': 207,\n",
       " 'C16_da441c7e': 208,\n",
       " 'C16_<UNK>': 197,\n",
       " 'C17_e5ba7672': 210,\n",
       " 'C17_d4bb7bd8': 211,\n",
       " 'C17_07c540c4': 212,\n",
       " 'C17_3486227d': 213,\n",
       " 'C17_776ce399': 214,\n",
       " 'C17_1e88c74f': 215,\n",
       " 'C17_2005abd1': 216,\n",
       " 'C17_27c07bd6': 217,\n",
       " 'C17_8efede7f': 218,\n",
       " 'C17_<UNK>': 209,\n",
       " 'C18_5aed7436': 220,\n",
       " 'C18_891589e7': 221,\n",
       " 'C18_7ef5affa': 222,\n",
       " 'C18_281769c2': 223,\n",
       " 'C18_bc48b783': 224,\n",
       " 'C18_005c6740': 225,\n",
       " 'C18_f54016b9': 226,\n",
       " 'C18_c21c3e4c': 227,\n",
       " 'C18_7b49e3d2': 228,\n",
       " 'C18_1f868fdd': 229,\n",
       " 'C18_2efa89c6': 230,\n",
       " 'C18_63cdbb21': 231,\n",
       " 'C18_2804effd': 232,\n",
       " 'C18_bd17c3da': 233,\n",
       " 'C18_e7e991cb': 234,\n",
       " 'C18_698d1c68': 235,\n",
       " 'C18_eea3ab97': 236,\n",
       " 'C18_13145934': 237,\n",
       " 'C18_582152eb': 238,\n",
       " 'C18_7e32f7a4': 239,\n",
       " 'C18_e88ffc9d': 240,\n",
       " 'C18_a6f5dd38': 241,\n",
       " 'C18_9880032b': 242,\n",
       " 'C18_e4ca448c': 243,\n",
       " 'C18_87c6f83c': 244,\n",
       " 'C18_7b06fafe': 245,\n",
       " 'C18_df4fffb7': 246,\n",
       " 'C18_752d8b8a': 247,\n",
       " 'C18_52e44668': 248,\n",
       " 'C18_<UNK>': 219,\n",
       " 'C19_21ddcdc9': 250,\n",
       " 'C19_55dd3565': 251,\n",
       " 'C19_cf99e5de': 252,\n",
       " 'C19_9437f62f': 253,\n",
       " 'C19_<UNK>': 249,\n",
       " 'C20_5840adea': 255,\n",
       " 'C20_a458ea53': 256,\n",
       " 'C20_b1252a9d': 257,\n",
       " 'C20_<UNK>': 254,\n",
       " 'C21_0014c32a': 259,\n",
       " 'C21_73d06dde': 260,\n",
       " 'C21_dfcfc3fa': 261,\n",
       " 'C21_5f957280': 262,\n",
       " 'C21_e587c466': 263,\n",
       " 'C21_d4703ebd': 264,\n",
       " 'C21_723b4dfd': 265,\n",
       " 'C21_0429f84b': 266,\n",
       " 'C21_a4b7004c': 267,\n",
       " 'C21_7e5b7cc4': 268,\n",
       " 'C21_<UNK>': 258,\n",
       " 'C22_ad3062eb': 270,\n",
       " 'C22_c9d4222a': 271,\n",
       " 'C22_78e2e389': 272,\n",
       " 'C22_8ec974f4': 273,\n",
       " 'C22_<UNK>': 269,\n",
       " 'C23_32c7478e': 275,\n",
       " 'C23_3a171ecb': 276,\n",
       " 'C23_423fab69': 277,\n",
       " 'C23_be7c41b4': 278,\n",
       " 'C23_bcdee96c': 279,\n",
       " 'C23_c7dc6720': 280,\n",
       " 'C23_55dd3565': 281,\n",
       " 'C23_dbb486d7': 282,\n",
       " 'C23_93bad2c0': 283,\n",
       " 'C23_<UNK>': 274,\n",
       " 'C24_aee52b6f': 285,\n",
       " 'C24_3b183c5c': 286,\n",
       " 'C24_1793a828': 287,\n",
       " 'C24_3fdb382b': 288,\n",
       " 'C24_b34f3128': 289,\n",
       " 'C24_45ab94c8': 290,\n",
       " 'C24_9117a34a': 291,\n",
       " 'C24_c0d61a5c': 292,\n",
       " 'C24_b258af68': 293,\n",
       " 'C24_df487a73': 294,\n",
       " 'C24_f96a556f': 295,\n",
       " 'C24_08b0ce98': 296,\n",
       " 'C24_<UNK>': 284,\n",
       " 'C25_e8b83407': 298,\n",
       " 'C25_001f3601': 299,\n",
       " 'C25_ea9a246c': 300,\n",
       " 'C25_2bf691b1': 301,\n",
       " 'C25_010f6491': 302,\n",
       " 'C25_9b3e8820': 303,\n",
       " 'C25_445bbe3b': 304,\n",
       " 'C25_cb079c2d': 305,\n",
       " 'C25_f0f449dd': 306,\n",
       " 'C25_9d93af03': 307,\n",
       " 'C25_724b04da': 308,\n",
       " 'C25_<UNK>': 297,\n",
       " 'C26_49d68486': 310,\n",
       " 'C26_c84c4aec': 311,\n",
       " 'C26_b7d9c3bc': 312,\n",
       " 'C26_9904c656': 313,\n",
       " 'C26_c27f155b': 314,\n",
       " 'C26_2fede552': 315,\n",
       " 'C26_984e0db0': 316,\n",
       " 'C26_aa5f0a15': 317,\n",
       " 'C26_b9809574': 318,\n",
       " 'C26_<UNK>': 309}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_trans.feature_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "883319d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>240</td>\n",
       "      <td>249</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>284</td>\n",
       "      <td>305</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>212</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>212</td>\n",
       "      <td>219</td>\n",
       "      <td>250</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>284</td>\n",
       "      <td>299</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>220</td>\n",
       "      <td>250</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>287</td>\n",
       "      <td>298</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>219</td>\n",
       "      <td>249</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>270</td>\n",
       "      <td>277</td>\n",
       "      <td>290</td>\n",
       "      <td>301</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>271</td>\n",
       "      <td>274</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>220</td>\n",
       "      <td>250</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>287</td>\n",
       "      <td>298</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>271</td>\n",
       "      <td>280</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>271</td>\n",
       "      <td>279</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      I1  I2  I3  I4  I5  I6  I7  I8  I9  I10  ...  C17  C18  C19  C20  C21  \\\n",
       "0      1   2   3   4   5   6   7   8   9   10  ...  213  240  249  257  258   \n",
       "1      1   2   3   4   5   6   7   8   9   10  ...  212  219    0    0  258   \n",
       "2      1   2   3   4   5   6   7   8   9   10  ...  212  219  250  257  258   \n",
       "3      1   2   3   4   5   6   7   8   9   10  ...  210  220  250  257  258   \n",
       "4      1   2   3   4   5   6   7   8   9   10  ...  210  219  249  257  258   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "1594   1   2   3   4   5   6   7   8   9   10  ...  215  219    0    0  258   \n",
       "1595   1   2   3   4   5   6   7   8   9   10  ...  210  220  250  257  258   \n",
       "1596   1   2   3   4   5   6   7   8   9   10  ...  210  219    0    0  258   \n",
       "1597   1   2   3   4   5   6   7   8   9   10  ...  210  219    0    0  258   \n",
       "1598   1   2   3   4   5   6   7   8   9   10  ...  216  219    0    0  258   \n",
       "\n",
       "      C22  C23  C24  C25  C26  \n",
       "0       0  279  284  305  309  \n",
       "1       0  276  284    0    0  \n",
       "2       0  275  284  299  309  \n",
       "3       0  277  287  298  309  \n",
       "4     270  277  290  301  311  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "1594  271  274  284    0    0  \n",
       "1595    0  276  287  298  309  \n",
       "1596    0  282  284    0    0  \n",
       "1597  271  280  284    0    0  \n",
       "1598  271  279  284    0    0  \n",
       "\n",
       "[1599 rows x 39 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7235edeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       I1     I2    I3    I4      I5     I6     I7    I8     I9  I10  ...  \\\n",
       "0     1.0    0.0   1.0   0.0   227.0    1.0  173.0  18.0   50.0  1.0  ...   \n",
       "1     4.0    1.0   1.0   2.0    27.0    2.0    4.0   2.0    2.0  1.0  ...   \n",
       "2     0.0  806.0   0.0   0.0  1752.0  142.0    2.0   0.0   50.0  0.0  ...   \n",
       "3     2.0   -1.0  42.0  14.0   302.0   38.0   25.0  38.0   90.0  1.0  ...   \n",
       "4     0.0   57.0   2.0   1.0  2891.0    2.0   35.0   1.0  137.0  0.0  ...   \n",
       "...   ...    ...   ...   ...     ...    ...    ...   ...    ...  ...  ...   \n",
       "1594  0.0    8.0   1.0   1.0    43.0    0.0    0.0   1.0    1.0  0.0  ...   \n",
       "1595  8.0    2.0  20.0   8.0    36.0    9.0    8.0  10.0    8.0  1.0  ...   \n",
       "1596  0.0    1.0   2.0  12.0  4877.0  140.0   13.0  34.0  136.0  0.0  ...   \n",
       "1597  0.0    2.0   0.0   1.0  1972.0    0.0    0.0   1.0   14.0  0.0  ...   \n",
       "1598  0.0   34.0   3.0   4.0     0.0    0.0    0.0   4.0   14.0  0.0  ...   \n",
       "\n",
       "      C17  C18  C19  C20  C21  C22  C23  C24  C25  C26  \n",
       "0     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "3     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "1594  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1595  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1596  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1597  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1598  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[1599 rows x 39 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a0f5b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_values.values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cbb3267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcols=dis_col+con_col\n",
    "feature_values[allcols].values.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920cd3e",
   "metadata": {},
   "source": [
    "### 建立自己的dataset和对应的dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33d9c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)           # torch模型参数的默认数据类型是flaot32.  np/pd是默认是flaot64(double).转成一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ed2ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建dataset: 都放np,防止loader开多进程内存泄露:https://github.com/pytorch/pytorch/issues/13246#issuecomment-893198671）\n",
    "class Mydata(Dataset):\n",
    "    def __init__(self,fv,fp,target,mode='train'):\n",
    "        super(Mydata, self).__init__()\n",
    "        self.fv=fv           # np: m,n.  每个样本的特征取值 \n",
    "        self.fp=fp           #           每个样本的特征位置.如果太大以后可以放np文件名.或切成多个文件,每次只打开一个(类似drml)\n",
    "        self.target=target   #           如果mode==train/valid.对应y. mode==test。可以传入样本id。infer时不用\n",
    "    def __len__(self):\n",
    "        return len(self.fv)\n",
    "    def __getitem__(self, index):\n",
    "        return self.fp[index,:],self.fv[index],self.target[index]  # 提前做好了映射。当然映射也可以在这里做。\n",
    "\n",
    "allcols=dis_col+con_col\n",
    "trainDataset=Mydata(feature_values[allcols].values,feature_pos[allcols].values, raw_df[label].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b65b9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(trainDataset)\n",
    "train_dataloader = DataLoader(trainDataset, sampler=train_sampler, batch_size=32,num_workers=4)\n",
    "epoch_num=3\n",
    "for epoch in range(epoch_num):\n",
    "    for batch_id,x in enumerate(train_dataloader):   # 把数据完整轮询一遍。对应一个epoch. 每一轮都是随机的\n",
    "        # 输入模型\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "573eb561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[15, 29, 67,  ..., 11, 12, 13],\n",
       "         [15, 28, 59,  ..., 11, 12, 13],\n",
       "         [15, 26, 59,  ..., 11, 12, 13],\n",
       "         ...,\n",
       "         [15, 26,  0,  ..., 11, 12, 13],\n",
       "         [14, 27, 59,  ..., 11, 12, 13],\n",
       "         [15, 45, 59,  ..., 11, 12, 13]]),\n",
       " tensor([[ 1.,  1.,  1.,  ..., 19.,  0., 21.],\n",
       "         [ 1.,  1.,  1.,  ...,  4.,  2.,  2.],\n",
       "         [ 1.,  1.,  1.,  ...,  1.,  0.,  3.],\n",
       "         ...,\n",
       "         [ 1.,  1.,  1.,  ...,  3.,  0.,  9.],\n",
       "         [ 1.,  1.,  1.,  ...,  7.,  0.,  0.],\n",
       "         [ 1.,  1.,  1.,  ...,  0.,  0., 23.]]),\n",
       " tensor([0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3e73d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader:   valid同\n",
    "trainloader = DataLoader(trainDataset,        \n",
    "                    shuffle=True,             # 每个epoch全部shuffle\n",
    "                    batch_size=32,\n",
    "                    collate_fn=None,          # 自定义如何拼batch。默认有，一般不需要。可以用来对batch padding（根据每个batch最长的text）\n",
    "                                              # 传入的是一个batch，B个tuple. 每个tuple对应Dataset传出来的n个元素。\n",
    "                                              # 自己重新拼成n个元素，每个元素B行，作为loader每次迭代的返回\n",
    "                    pin_memory=False,         # 页锁定内存：不可分页，占用物理内存。 可分页内存：占用虚拟内存，用时候从磁盘读入物理内存\n",
    "                                                # gpu需要通过页锁定内存中，把数据复制到gpu上\n",
    "                                                #  数据从cpu的可分页内存内存传到gpu时，需要先把数据复制到临时的页锁定内存，再赋值到gpu.速度更慢\n",
    "                                                #  如果指定pin_memory=True, batch的数据会直接被放在cpu的页锁定内存中，传到gpu时更快。少了一步复制\n",
    "                                                #  但页锁定内存会占用真实物理内存，分配过多会挤占别的程序的内存，把内存耗尽。因此内存小时不建议用\n",
    "                    sampler=None,             # 定义/自定义怎么从dataset里抽取每个batch的样本.还有一个batch_sampler参数\n",
    "                                              # 需要实现__iter__方法。返回针对所有样本id的迭代器，顺序按自定义的样本顺序排好\n",
    "                                              # 需要实现 __len__ ， 表示loader的一次抽取完成。一般同dataset样本数。\n",
    "                                              # 就不能定义shuffle了，因为策略自己实现了。shuffle只能在iter里自己做。加入随机性\n",
    "                                              # 每次loader会根据__iter__(和batch_size），迭代产生该epoch的每个batch。 \n",
    "                                              # 比如nlp会根据样本文本长度，将长度相近样本排一起：iter([25,3,60,0,...1])。使得每个batch长度接近\n",
    "                                              # 通过在__iter_里先切好batch,再shuffle,再整合。打乱每个epoch,batch间的执行顺序\n",
    "                                              # 可以设置RandomSampler每次随机采样。（可参考该实现等）                       \n",
    "                    num_workers=10            # 开多进程，每个进程计算一个batch。初始化时用之前提前处理好对应的n个batch。后续batch加入新的线程\n",
    "                   )                          # 初始化时会一次性建好n个进程。每个进程提前处理好要用的batch数据。（底层是 multiprocessing）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32d5890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num=3\n",
    "for epoch in range(epoch_num):\n",
    "    for batch_id,x in enumerate(trainloader):   # 把数据完整轮询一遍。对应一个epoch\n",
    "        # 输入模型\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de96c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)                                # 每个epoch对应的batch的个数（step的数目）。一个epoch共50个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f870eab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_df)//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5a26398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[15, 38, 59,  ..., 11, 12, 13],\n",
       "         [16, 52, 59,  ..., 11, 12, 13],\n",
       "         [15, 26, 59,  ..., 11, 12, 13],\n",
       "         ...,\n",
       "         [15, 31, 59,  ..., 11, 12, 13],\n",
       "         [18, 26, 59,  ..., 11, 12, 13],\n",
       "         [16, 26, 59,  ..., 11, 12, 13]]),\n",
       " tensor([[ 1.,  1.,  1.,  ...,  6.,  0.,  1.],\n",
       "         [ 1.,  1.,  1.,  ...,  9.,  1.,  2.],\n",
       "         [ 1.,  1.,  1.,  ...,  1.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 1.,  1.,  1.,  ...,  2.,  0., 26.],\n",
       "         [ 1.,  1.,  1.,  ...,  1.,  0.,  0.],\n",
       "         [ 1.,  1.,  1.,  ...,  0.,  0.,  0.]]),\n",
       " tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "732b7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_p,f_v,y=x[0],x[1],x[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649aa906",
   "metadata": {},
   "source": [
    "### 原始FM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d13e0d",
   "metadata": {},
   "source": [
    "模型维持n个w,n个embedding，对应one-hot后的所有特征（这里还算上了缺失值对应的0参数）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e0034",
   "metadata": {},
   "source": [
    "二阶分数是$$\\sum_{i}^{n}\\sum_{j!=i}^{n}x_ix_j<\\vec{v_i},\\vec{v_j}>$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3827b2f",
   "metadata": {},
   "source": [
    "直接计算是$O(n^2*k)$。每对向量内积是$k$,共$O(n^2)$个pair。最后求和"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d74b52",
   "metadata": {},
   "source": [
    "等价于embedding们对应位置22相乘后，再求和。可以先求所有embedding每个维度元素22相乘的和，最后再对所有维度求和"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968764fe",
   "metadata": {},
   "source": [
    "$$\\sum_{i}^{n}\\sum_{j!=i}^{n}<\\vec{e_i},\\vec{e_j}>= \\sum_{f} \\sum_{i}^{n}\\sum_{j!=i}^{n}e_{if}*e_{jf} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d22070",
   "metadata": {},
   "source": [
    "embedding的每个维度元素22相乘的和： $ab+ac+bc= \\frac{1}{2}((a+b+c)^2-(a^2+b^2+c^2))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e537011",
   "metadata": {},
   "source": [
    "因此对固定维度，embedding的每个维度元素22相乘的和$\\sum_{i}^{n}\\sum_{j!=i}^{n}e_{if}*e_{jf}$ ，是$\\frac{1}{2}((e_{if}+e_{jf}...)^2-(e_{if}^2+e_{if}^2+...))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7a78d",
   "metadata": {},
   "source": [
    "可以通过每个embedding相加（对应位置相加）的平方，减去每个embedding平方的相加，得到（1，k）的向量，作为embedding的每个维度元素22交互的结果。最终的二阶分数是这k个维度的结果相加。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8ea15",
   "metadata": {},
   "source": [
    "也可以把这k维向量作为新的隐特征，输入后续网络。作为FM/deepFM的一个小变体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6985922",
   "metadata": {},
   "source": [
    "转化后，$\\frac{1}{2}((e_{if}+e_{jf}...)^2-(e_{if}^2+e_{if}^2+...))$的复杂度只有$O(n)$(n个元素相加或平方后相加)。加上维度F，总的复杂度可以降低到$O(nk)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4527e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self,n_field,n_features,embed_size,dropout=0,init_w=False):\n",
    "        \"\"\"\n",
    "        标准FM\n",
    "        n_field: 原始离散特征数目\n",
    "        n_features: 离散特征one-hot之后,和dense的总特征个数. 这里包含了一个缺失值特征向量，paddding成0\n",
    "        \"\"\"\n",
    "        super(FM, self).__init__()\n",
    "        self.n_field=n_field             # 原始特征数目\n",
    "        self.n_features=n_features       # 连续+离散特征的总数目 (离散特征one-hot+unique化后的。且算上最终的一个padding)\n",
    "        self.k=embed_size\n",
    "        \n",
    "        self.W=nn.Embedding(n_features,1,padding_idx=0)                       # 每个特征对应的wi。位置0是0对梯度无贡献。embedding默认是N(0,1)\n",
    "        self.w0=nn.Parameter(torch.zeros([1,]))                               # b初始化为0\n",
    "        self.feature_embed=nn.Embedding(n_features,embed_size,padding_idx=0)  # 每个特征对应的embedding\n",
    "        self.droplayer=nn.Dropout(dropout)\n",
    "        \n",
    "        self.scoreweight=nn.Parameter(0.5*torch.ones([2,]))                   # 一阶，二阶score的权重 \n",
    "                                                                              \n",
    "        if init_w:\n",
    "            self.__init_weight__()                                                # 初始化权重(可以不调用，用默认的)\n",
    "            \n",
    "    def __init_weight__(self):              # 初始化权重.默认是N(0,1)\n",
    "        inn=n_features-1\n",
    "        # kaiming_normal_\n",
    "        nn.init.kaiming_uniform_(self.feature_embed.weight[1:], mode='fan_in', nonlinearity='relu')  # sqrt(6/inn)\n",
    "        nn.init.normal_(self.W.weight[1:],0, np.sqrt(2.0 /inn))\n",
    "        \n",
    "    def forward(self,f_p,f_x): # B,n.  n是每个样本的原始特征数目\n",
    "        \"\"\"\n",
    "        f_p: (B,N)  每个样本的原始特征，根据特征名（连续特征）/特征取值（离散特征）被映射到embedding上的位置。 N:原始特征数目\n",
    "        f_x: (B,N)  每个样本的原始特征，对应的取值。 离散特征对应的是one-hot后的，所以在对应的f_p上取值为1\n",
    "        \"\"\"\n",
    "        batch_size=f_p.shape[0]\n",
    "        \n",
    "        # 一阶score\n",
    "        w=self.W(f_p.long()).reshape(batch_size,-1)              # B,n   每个样本根据原始特征，找到对应位置处的w\n",
    "        y_score1=self.w0 + torch.sum(torch.mul(w,f_x),1)  # B,1   wixi+b  B,n -->   B,1.  要是不sum，也可以作为n个特征。之后作为deepFM的改造\n",
    "        \n",
    "        # 二阶score\n",
    "        embed=self.feature_embed(f_p.long())             # B,n,d 每个样本根据原始特征，找到对应位置处的embedding\n",
    "        \n",
    "        embed=torch.mul(embed,f_x.unsqueeze(2))           # B,n,d 样本的每个向量乘上对应的xi： xi* embedding\n",
    "                                                          #       tf.mul:按位置乘.广播 (B,n,d) * (B,n,1) ->(B,n,d) \n",
    "                                                          #       离散特征对应的xi是1.假设数值型已经归一化\n",
    "        \n",
    "        #embed=self.droplayer(embed)\n",
    "        \n",
    "        # 每个filed 向量22交互\n",
    "        e_sum= torch.sum(embed,1)                         # B,d   每个样本。所有embedding对应维度元素相加，得到e_sum\n",
    "        e_sum_square=torch.square(e_sum)                  # B,d   (e_sum)^2\n",
    "        \n",
    "        e_square=torch.square(embed)                      # B,n,d  平方后的\n",
    "        e_square_sum=torch.sum(e_square,1)                # B,d    每个维度相加\n",
    "        \n",
    "        f =0.5*(e_sum_square-e_square_sum)                # B,d    n个embedding，每个维度元素22交互的结果（可作为新特征，拼接到后边）\n",
    "    \n",
    "        y_score2= torch.sum(f,1)                          # (B,)\n",
    "        \n",
    "        logits=y_score1+y_score2                          # (B,)   最终分数  y_score1*self.scoreweight[0] +..\n",
    "        \n",
    "        # TODO:loss加正则项（最后加）/ grad-clip等. 看下train-loop\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24089f",
   "metadata": {},
   "source": [
    "### 原始deepFM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ebe038",
   "metadata": {},
   "source": [
    "FM部分相同，但共享底层的embedding部分。把样本原始离散特征和连续特征映射得到的所有embedding，concat,作为后续mlp的输入。输出结果作为deep部分的score,和linear(FM)部分相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ddae6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepFM： 标准的。 或者上述k个元素作为特征统一拼到deep的\n",
    "class deepFM(nn.Module):\n",
    "    def __init__(self,n_field,n_features,embed_size,hiddens,dropout=0,batchnorm=True,init_w=False):\n",
    "        \"\"\"\n",
    "        标准DeepFM\n",
    "        n_field: 原始特征数目\n",
    "        n_features: 离散特征one-hot之后,和dense的总特征个数. 这里包含了一个缺失值特征向量，paddding成0\n",
    "        deep每层：linear + (bn) + relu + (dropout).  输出hidden层。  最后按需单独linear到1\n",
    "        \"\"\"\n",
    "        super(deepFM, self).__init__() \n",
    "        self.n_field=n_field             # 原始特征数目\n",
    "        self.n_features=n_features       # 连续+离散特征的总数目 (离散特征one-hot+unique化后的。且算上最终的一个padding)\n",
    "        self.k=embed_size\n",
    "        self.dropout=dropout\n",
    "        self.batchnorm=batchnorm\n",
    "        self.hiddens=hiddens             # hiddens:[256,64,32]\n",
    "    \n",
    "        # FM-part\n",
    "        self.W=nn.Embedding(n_features,1,padding_idx=0)                       # 每个特征对应的wi。位置0是0对梯度无贡献。embedding默认是N(0,1)\n",
    "        self.w0=nn.Parameter(torch.zeros([1,]))                               # b初始化为0\n",
    "        self.feature_embed=nn.Embedding(n_features,embed_size,padding_idx=0)  # 每个特征对应的embedding\n",
    "        self.droplayer=nn.Dropout(dropout)            \n",
    "        \n",
    "        #self.__init_wide_weight__()                                           # 初始化权重(可以不调用，用默认的)\n",
    "        \n",
    "        # deep-part.\n",
    "        input_size=n_field*embed_size                                         #输入是所有原始特征的embedding拼接   \n",
    "        self.mlp=self.build_mlp(input_size,hiddens)                           #多层mlp.输出hidden  是一个ModuleList\n",
    "        self.finallinear=nn.Linear(hiddens[-1],1,bias=True)                   #最后一层linear\n",
    "        \n",
    "        if init_w:\n",
    "            self.__init_deep_weight__()                                       # 初始化权重。(可以按情况调用。现在用kaiming)\n",
    "            \n",
    "    def __init_wide_weight__(self):              # 初始化权重.默认是N(0,1)\n",
    "        inn=n_features-1\n",
    "        # kaiming_normal_\n",
    "        nn.init.kaiming_uniform_(self.feature_embed.weight[1:], mode='fan_in', nonlinearity='relu')  # sqrt(6/inn)\n",
    "        nn.init.normal_(self.W.weight[1:],0, np.sqrt(2.0 /inn))\n",
    "\n",
    "    def __init_deep_weight__(self):              # 初始化权重\n",
    "        for layer in self.mlp:\n",
    "            if (layer.__class__.__name__=='Linear'):  # 每层初始化\n",
    "                self.init_linear(layer)\n",
    "        self.init_linear(self.finallinear)\n",
    "        \n",
    "    def init_linear(self,layer):\n",
    "        nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')  #sqrt(2/inn) 或者 sqrt(2/out)\n",
    "        nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "    def build_mlp(self,input_size,hiddens):\n",
    "        \"\"\"\n",
    "        hiddens:[256,56,32]\n",
    "        输出最后一层的hidden节点 （dropout+激活后的），可直接linear+sigmoid到deepscore. 也可以拼其他特征后再linear\n",
    "        \"\"\"        \n",
    "        layers=nn.ModuleList()\n",
    "        \n",
    "        hiddens.insert(0,input_size)     #  [inputsize,256,56,32]\n",
    "        num_layer=len(hiddens)-1         #  3层\n",
    "        \n",
    "        for i in range(0,len(hiddens)-1):\n",
    "            \n",
    "            # 线性层\n",
    "            in_dim=hiddens[i]\n",
    "            out_dim=hiddens[i+1]\n",
    "            layer=nn.Linear(in_dim,out_dim,bias=True)\n",
    "            layers.append(layer)\n",
    "            \n",
    "            # BN\n",
    "            if self.batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(out_dim)) \n",
    "            \n",
    "            # active + dropout\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(self.dropout))\n",
    "                \n",
    "        return layers  # 拼成一个前后连接的网络。可以在forward里作为一个模块被整体调用\n",
    "    \n",
    "    \n",
    "    def forward(self,f_p,f_x): # B,n.  n是每个样本的原始特征数目\n",
    "        \"\"\"\n",
    "        f_p: (B,N)  每个样本的原始特征，根据特征名（连续特征）/特征取值（离散特征）被映射到embedding上的位置。 N:原始特征数目\n",
    "        f_x: (B,N)  每个样本的原始特征，对应的取值。 离散特征对应的是one-hot后的，所以在对应的f_p上取值为1\n",
    "        output:  FM和deep部分 score相加\n",
    "        \"\"\"\n",
    "        batch_size=f_p.shape[0]\n",
    "        \n",
    "        # FM-part    每个filed 向量22交互\n",
    "        w=self.W(f_p.long()).reshape(batch_size,-1)       # B,n   每个样本根据原始特征，找到对应位置处的w\n",
    "        y_score1=self.w0 + torch.sum(torch.mul(w,f_x),1)  # B,1   wixi+b  B,n -->   B,1.  要是不sum，也可以作为n个特征。\n",
    "        \n",
    "        embed=self.feature_embed(f_p.long())              # B,n,d 每个样本根据原始特征，找到对应位置处的embedding \n",
    "        embed=torch.mul(embed,f_x.unsqueeze(2))           # B,n,d 样本的每个向量乘上对应的xi： xi* embedding\n",
    "        e_sum= torch.sum(embed,1)                         # B,d   每个样本。所有embedding对应维度元素相加，得到e_sum\n",
    "        e_sum_square=torch.square(e_sum)                  # B,d   (e_sum)^2\n",
    "        e_square=torch.square(embed)                      # B,n,d  平方后的\n",
    "        e_square_sum=torch.sum(e_square,1)                # B,d    每个维度相加\n",
    "        f =0.5*(e_sum_square-e_square_sum)                # B,d    n个embedding，每个维度元素22交互的结果（可作为新特征，拼接到后边）\n",
    "        y_score2= torch.sum(f,1)                          # (B,)\n",
    "        \n",
    "        # deep-part\n",
    "        x=torch.reshape(embed,[-1,self.n_field*self.k])           # 输入是所有原始特征对应embedding的拼接\n",
    "        for layer in self.mlp:\n",
    "            if(layer.__class__.__name__=='Linear'):\n",
    "                pass\n",
    "                #print(x.mean(),x.std())        # 可以画一下数据分布\n",
    "            x=layer(x)\n",
    "        \n",
    "        y_deep=self.finallinear(x).squeeze(-1)         # (B，)\n",
    "        \n",
    "        logits=y_score1+y_score2 +y_deep\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96836f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_field=len(dis_col+con_col)           # 原始特征数目\n",
    "n_features=len(f_trans.feature_id_map) # 连续+离散特征的总数目 (离散特征one-hot+unique化后的。且算上最终的一个padding)\n",
    "embed_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fb2ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "hiddens=[256,56,32]\n",
    "model=deepFM(n_field,n_features,embed_size,hiddens,dropout=0.5)\n",
    "#model=FM(n_field,n_features,embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d2f24ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepFM(\n",
       "  (W): Embedding(319, 1, padding_idx=0)\n",
       "  (feature_embed): Embedding(319, 8, padding_idx=0)\n",
       "  (droplayer): Dropout(p=0.5, inplace=False)\n",
       "  (mlp): ModuleList(\n",
       "    (0): Linear(in_features=312, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=56, bias=True)\n",
       "    (5): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=56, out_features=32, bias=True)\n",
       "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (finallinear): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba7855c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟一次forward\n",
    "logits=model(f_p,f_v)\n",
    "target=y\n",
    "loss_func= nn.BCEWithLogitsLoss()    #  mean [yn⋅logσ(xn)+(1−yn)⋅log(1−σ(xn))]\n",
    "loss=loss_func(logits,target.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dacb0652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e653abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-8.5255e+03, -7.4701e+04, -2.7454e+05,  2.3901e+06,  1.4238e+05,\n",
       "         9.5128e+06,  4.6718e+06,  1.8683e+07,  4.0666e+02,  6.4842e+04,\n",
       "        -4.9902e+03, -4.9139e+05,  4.0360e+04,  6.2662e+06, -1.3078e+06,\n",
       "         1.4915e+05,  4.1942e+02, -2.9158e+04,  4.8625e+02, -1.6564e+05,\n",
       "         3.7427e+06,  3.3336e+07, -1.9234e+04,  1.9785e+07, -1.7426e+06,\n",
       "         3.3527e+04,  1.0921e+07,  6.7598e+04,  2.0879e+06, -2.3352e+03,\n",
       "         5.4513e+05,  3.8053e+07], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4980064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3552915., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e3d1f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3552915.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d517c32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b4ebfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3552915., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy_with_logits(logits, target.float())  # 用函数结果相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29b27111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.5112,  0.2132,  0.1472,  ..., -0.2577,  0.4897,  0.5127],\n",
       "        [-1.0335, -0.9147,  1.0321,  ...,  1.6909, -0.8838,  0.6023],\n",
       "        ...,\n",
       "        [ 0.4567, -0.7279,  0.2588,  ...,  0.1279,  1.2441, -1.2084],\n",
       "        [ 2.0517, -0.4042,  1.7462,  ...,  0.6163,  1.1672, -0.5052],\n",
       "        [-0.7390,  0.1647,  0.1776,  ...,  0.5721,  1.7857, -1.0752]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_embed.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff6cb0",
   "metadata": {},
   "source": [
    "### train_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e3141",
   "metadata": {},
   "source": [
    "正常trainloop + reg + grad_clip  + CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf6000a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StandardScaler()\n",
    "ss.fit(raw_df[con_col])                           #归一化\n",
    "raw_df[con_col]=ss.transform(raw_df[con_col])     # 测试做相同处理\n",
    "\n",
    "f_trans=FeaturePosTrans(dis_col,con_col,0)           # 映射到对应id. 出现10次以下的作为UNK\n",
    "f_trans.fit(raw_df)\n",
    "feature_pos,feature_values=f_trans.transform(raw_df,label)  # 测试集做相同处理。用相同的原始con_col,dis_col。 label只是用来删除掉该列\n",
    "cols=dis_col+con_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff5727",
   "metadata": {},
   "source": [
    "处理过的数据，划分cv。 训练5个模型，用5个模型的平均作为最终结果（同时也保存这5个模型。作为衡量该模型最终表现的量度）\n",
    "也可以有放回的每次随机采样一份：df.sample(frac=0.7,random_state =i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "192a3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf=StratifiedKFold(n_splits=5,random_state=2020,shuffle=True)    # 分割器。按y值对给定的样本划分。返回分好的样本id 每轮4:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85cafbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 11:53:09,611 - 训练第0折对应的模型\n"
     ]
    }
   ],
   "source": [
    "for i,(train_index,dev_index) in enumerate(skf.split(raw_df,raw_df[label])): # 可用于df. 根据y，输出分割后的train/dev样本位置\n",
    "    logger.info(\"训练第%s折对应的模型\",i)                                    # 每个fold训一个模型\n",
    "    \n",
    "    train_fv=feature_values[cols].iloc[train_index].values                # 按样本位置，从转换好的df里取训练样本\n",
    "    train_fp=feature_pos[cols].iloc[train_index].values\n",
    "    train_label=raw_df[label].iloc[train_index].values\n",
    "    trainDataset=Mydata(train_fv,train_fp, train_label)                   # 对应的dataset\n",
    "    \n",
    "    dev_fv=feature_values[cols].iloc[dev_index].values                    # dev场景下，主要是计算指标。model不输出loss\n",
    "    dev_fp=feature_pos[cols].iloc[dev_index].values\n",
    "    dev_label=raw_df[label].iloc[dev_index].values                        # test用raw_df[label]\n",
    "    dev_dataset=Mydata(dev_fv,dev_fp, dev_label)                          \n",
    "    \n",
    "    #train(train_dataset,dev_dataset)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65834824",
   "metadata": {},
   "source": [
    "建立一个class,用来封装基本模型。预测，保存，重新加载等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cb915d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置随机种子。每次训练固定  \n",
    "def set_seed(args):\n",
    "    random.seed(args.random_seed)\n",
    "    np.random.seed(args.random_seed)\n",
    "    torch.manual_seed(args.random_seed)\n",
    "    \n",
    "# 用来算平均的\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "class WrapModel(object):\n",
    "    def __init__(self,args=None,state_dict=None):\n",
    "        # 初始化模型\n",
    "        n_field=len(args.dis_col+args.con_col)                # 原始特征数目\n",
    "        n_features=len(args.f_trans.feature_id_map)           # 连续+离散特征one-hot后的特征总数目 (算上一个NAN padding)\n",
    "        model=FM(n_field,n_features,args.embed_size,args.dropout,args.init_w)\n",
    "        #self.model=deepFM(n_field,n_features,args.embed_size,args.hiddens,args.dropout,args.batchnorm,args.init_w)\n",
    "        \n",
    "        if state_dict:                                        # 加载保存过的模型参数（如果有）\n",
    "            model.load_state_dict(state_dict)\n",
    "       \n",
    "        device = torch.device(\"cuda:0\" if args.cuda else \"cpu\") # 放gpu上 （相比.cuda(),优先使用这个。方便在不同设备上切换）\n",
    "        model.to(device) \n",
    "        \n",
    "        self.model=model\n",
    "        args.device=device\n",
    "        self.args=args\n",
    "        set_seed(args)\n",
    "\n",
    "        \n",
    "    def train(self,train_dataset,dev_dataset=None):        # 参考jupyter的loss画图\n",
    "        args=self.args\n",
    "        model=self.model\n",
    "        \n",
    "        # 设置train-loader. 每次都是随机取（无放回）\n",
    "        sampler = RandomSampler(train_dataset)\n",
    "        train_loader = DataLoader(train_dataset, sampler=sampler, batch_size=args.batch_size,num_workers=4) \n",
    "        \n",
    "        # 设置优化器\n",
    "        parameters = [p for p in self.model.parameters() if p.requires_grad]  # 可只优化模型的部分层/部分parameter\n",
    "        if args.optimizer == 'sgd':\n",
    "            optimizer = optim.SGD(parameters, lr=args.lr,momentum=0.9,weight_decay=0.08)\n",
    "        elif args.optimizer == 'adamax':\n",
    "            optimizer = optim.Adamax(parameters,weight_decay=0.08)\n",
    "        elif args.optimizer == 'adamaW':\n",
    "            optimizer = AdamW(parameters, lr=args.lr, eps=1e-8,weight_decay=0.08)\n",
    "        elif args.optimizer == 'adam':\n",
    "            optimizer = optim.Adam(parameters, lr=0.001)  # demo里的\n",
    "        \n",
    "        \n",
    "        # 定义lr本身的scheduler. \n",
    "        # 在多个epoch过程中，调节优化器中lr本身的大小。每个step通过schcduler.step()改变lr本身的值。optimizer里的lr被同步修改。\n",
    "        # 但只改变lr的值。其他算法仍同optimizer\n",
    "        # 在限定step内，让lr从0线性增加到设定值。防止初始lr较大，模型不稳定。之后认为模型稳定.再线性减小，到最终训练完lr减小到0\n",
    "        num_training_steps=int(len(train_loader)*args.epochs)      # 完整训练过程中总的steps:每个step对应一个batch.\n",
    "        num_warmup_steps=int(num_training_steps*0.2)               # 预热期steps的数目：占总step的20%。在这些step内，让lr从0线性增加到设定值。此时认为模型稳定了\n",
    "        if args.schedule_lr:\n",
    "            scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps,num_training_steps) # 先预热一些step.再逐渐减小。\n",
    "            logger.info(\"最初的lr:{}\".format(scheduler.get_lr()))  # lr此时是0  增到设定lr后，最终训练完仍减小到0\n",
    "                                                                                                                              \n",
    "        # train-loop\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  总的样本数量 = %d\", len(train_dataset))\n",
    "        logger.info(\"  epoch数目 = %d\", args.epochs) \n",
    "        logger.info(\"  train batch size = %d\",args.batch_size)\n",
    "        logger.info(\"  所有epoch总的steps = %d\", num_training_steps) \n",
    "        \n",
    "        global_step = 0                      # 记录总的step\n",
    "        best_metric=0.0\n",
    "\n",
    "        model.zero_grad()                    # 把模型所有参数的梯度都置为0 （optimizer.zero_grad是把优化器里参数的梯度置为0）\n",
    "        \n",
    "        steps=[]\n",
    "        losses=[]                           # 所有epoch.每个loss\n",
    "        avg_losses=[]                       # 该epoch.截止目前step的所有loss的平均\n",
    "        nstep_avg_losses=[]                 # 该epoch.每n个step,loss的平均\n",
    "        for epoch in enumerate(range(args.epochs)):                 # 每个epoch\n",
    "            \n",
    "            loss_sum=0.0                                            # 用来记录每个epoch到此时的平均loss\n",
    "            nstep_avg_loss = AverageMeter()                         # epoch内，每n个step loss的平均。 n==display_steps\n",
    "          \n",
    "            for step, batch in enumerate(train_loader):  # dataset按batch-size轮询一遍。每个batch一个step\n",
    "                \n",
    "                # 输入放到对应设备上。同模型\n",
    "                f_p,f_v,y= (x.to(args.device) for x in batch)   # trian、dev时才用y. test时没有y,dataset传入id列或任意列。但不用\n",
    "                del batch\n",
    "                \n",
    "                model.train()  # train mode\n",
    "                \n",
    "                logits=model(f_p,f_v)                                  # 输出logits,before sigmoid: (B,1)\n",
    "                \n",
    "                loss=self.compute_loss(logits,y)                       # 计算该batch的loss (TODO:可以添加L2)\n",
    "                \n",
    "                optimizer.zero_grad()                                  # 清空之前的参数梯度\n",
    "                loss.backward()                                        # 根据loss重新计算模型参数梯度\n",
    "                #print(batch_loss.item())\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)   # 对算好的梯度 grad_clip\n",
    "                \n",
    "                optimizer.step()                                      # 根据梯度更新参数\n",
    "                if args.schedule_lr:\n",
    "                    scheduler.step()                                  # 更新lr值\n",
    "                global_step += 1\n",
    "                \n",
    "                \n",
    "                # 打印每段时间的平均loss.和此时的train_metric\n",
    "                loss_sum+=loss.item()                                 # 该epoch截止到目前所有step内的平均。 item():转为float\n",
    "                nstep_avg_loss.update(loss.item(),f_p.shape[0])       # 每n个step内的平均\n",
    "                if args.display_steps % (step+1)==0:\n",
    "                    print('Epoch = {} | step = {}/{} | loss = {:.2f}'.format(epoch,step+1,len(train_loader),loss_sum/(step+1)))\n",
    "                    avg_losses.append(loss_sum/(step+1))  #每个epoch内的平均loss\n",
    "                    losses.append(loss.item())            #每个step的单个loss\n",
    "                    steps.append(global_step)\n",
    "                    nstep_avg_losses.append(nstep_avg_loss.avg) # epoch内.每n个step的单个loss。n==display_steps\n",
    "                    nstep_avg_loss.reset()               \n",
    "                          \n",
    "                # 评估。好的话保存\n",
    "                \n",
    "                \n",
    "            # myReader+demoFM都是每个epoch结束之后eval+保存\n",
    "            \n",
    "            # 打印每个epoch的日志\n",
    "#             print((\"\\nEPOCH=%d, loss=%.3f, \" + metric_name + \" = %.3f, val_loss=%.3f, \" + \"val_\" + metric_name + \" = %.3f\") %info)\n",
    "#             nowtime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#             print('\\n' + '=========='* 8 + '%s' %nowtime)\n",
    "\n",
    "            \n",
    "        self.steps=steps\n",
    "        self.losses=losses\n",
    "        self.avg_losses=avg_losses\n",
    "        self.nstep_avg_losses=nstep_avg_losses\n",
    "                          \n",
    "    def compute_loss(self,logits,labels):\n",
    "        '''\n",
    "        计算一个batch的loss\n",
    "        logits:(B,1) before sigmoid\n",
    "        labels:(B,1) 每个样本的取值0/1\n",
    "        '''\n",
    "        loss=F.binary_cross_entropy_with_logits(logits,labels.float()) #  mean [yn⋅logσ(xn)+(1−yn)⋅log(1−σ(xn))]\n",
    "        return loss\n",
    "        \n",
    "    def infer(self,test_dataset):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def eval_metric(self,labels,preds):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def save(self,filename):\n",
    "        '保存超参数和内部模型的模型参数'\n",
    "        params = {\n",
    "            'state_dict': self.model.state_dict(),   # 只按参数名称保存模型所有参数。是一个dict.不保存模型结构\n",
    "            'args': self.args,\n",
    "        }\n",
    "        torch.save(params, filename)           # 保存static等到指定文件中。 这里可以保存字典，之后通过load加载进来（底层pickle）\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filename):   \n",
    "        '直接根据文件名，返回加载好内部模型参数的WraPModel（init时通过state_dict）.可以在外边直接调用：WrapModel.load(f)'\n",
    "        saved_params = torch.load(\n",
    "            filename, map_location=lambda storage, loc: storage  # load默认直接加载到GPU.  这样指定，先加载到cpu上。再load_state\n",
    "        )\n",
    "        state_dict = saved_params['state_dict']\n",
    "        args = saved_params['args']\n",
    "        \n",
    "        return WrapModel(args,state_dict)     \n",
    "    \n",
    "    def export_onnx(self,onnx_filename):\n",
    "        '需要用到nn.Module等'\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "209d57e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()                             # 超参数\n",
    "parser.add_argument('--embed_size', type=int, default=8)\n",
    "parser.add_argument('--dropout', type=float, default=0,help='默认没有dropout')\n",
    "parser.add_argument('--batchnorm', type=bool, default=False,help='默认没有batchnorm')\n",
    "parser.add_argument('--epochs', type=int, default=20)\n",
    "parser.add_argument('--max_grad_norm', type=float, default=1.0)  #1\n",
    "parser.add_argument('--optimizer', type=str, default='adamaW')\n",
    "parser.add_argument('--lr', type=float, default=0.001,help='优化器步长') # 8e-5\n",
    "parser.add_argument('--schedule_lr', type=bool, default=False,help='是否优化lr,先warm再降低')\n",
    "parser.add_argument('--init_w', type=bool, default=False,help='是否用xvaier/kaiming等随机初始化')\n",
    "parser.add_argument('--hiddens', type=str, default='256,56,32',help='deepfm的mlp层数')\n",
    "parser.add_argument('--batch_size', type=int, default=32)\n",
    "parser.add_argument('--display_steps', type=int, default=100,help='打印日志的step间隔')\n",
    "parser.add_argument('--eval_steps', type=int, default=500)\n",
    "parser.add_argument('--eval_batch_size', type=int, default=4096)\n",
    "parser.add_argument('--test_batch_size', type=int, default=32)\n",
    "parser.add_argument('--no-cuda', type=bool, default=False,help='是否用GPU')\n",
    "parser.add_argument('--gpu', type=int, default=0,help='GPU设备id')\n",
    "parser.add_argument('--random_seed', type=int, default=2020)\n",
    "args = parser.parse_args(args=[])                              # jupyter里需要加args=[]\n",
    "args.dis_col=dis_col\n",
    "args.con_col=con_col\n",
    "args.f_trans=f_trans\n",
    "args.hiddens=args.hiddens.split(',')\n",
    "# 设置设备为某固定gpu\n",
    "args.cuda = (not args.no_cuda)  and  (torch.cuda.is_available())\n",
    "if args.cuda:\n",
    "    torch.cuda.set_device(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e5486bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CTRmodel=WrapModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "467be10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FM(\n",
       "  (W): Embedding(10995, 1, padding_idx=0)\n",
       "  (feature_embed): Embedding(10995, 8, padding_idx=0)\n",
       "  (droplayer): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTRmodel.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "532430de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Embedding-1                [-1, 39, 1]          10,995\n",
      "         Embedding-2                [-1, 39, 8]          87,960\n",
      "================================================================\n",
      "Total params: 98,955\n",
      "Trainable params: 98,955\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.005802\n",
      "Forward/backward pass size (MB): 0.002678\n",
      "Params size (MB): 0.377483\n",
      "Estimated Total Size (MB): 0.385963\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(CTRmodel.model,input_shape=[(39,),(39,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "84eab393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 12:38:36,003 - ***** Running training *****\n",
      "2022-03-13 12:38:36,003 -   总的样本数量 = 1279\n",
      "2022-03-13 12:38:36,004 -   epoch数目 = 20\n",
      "2022-03-13 12:38:36,004 -   train batch size = 32\n",
      "2022-03-13 12:38:36,004 -   所有epoch总的steps = 800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = (0, 0) | step = 1/40 | loss = 26.98\n",
      "Epoch = (0, 0) | step = 2/40 | loss = 23.30\n",
      "Epoch = (0, 0) | step = 4/40 | loss = 19.24\n",
      "Epoch = (0, 0) | step = 5/40 | loss = 19.67\n",
      "Epoch = (0, 0) | step = 10/40 | loss = 19.64\n",
      "Epoch = (0, 0) | step = 20/40 | loss = 22.03\n",
      "Epoch = (0, 0) | step = 25/40 | loss = 22.26\n",
      "Epoch = (1, 1) | step = 1/40 | loss = 18.45\n",
      "Epoch = (1, 1) | step = 2/40 | loss = 16.57\n",
      "Epoch = (1, 1) | step = 4/40 | loss = 20.27\n",
      "Epoch = (1, 1) | step = 5/40 | loss = 18.70\n",
      "Epoch = (1, 1) | step = 10/40 | loss = 19.69\n",
      "Epoch = (1, 1) | step = 20/40 | loss = 20.52\n",
      "Epoch = (1, 1) | step = 25/40 | loss = 20.20\n",
      "Epoch = (2, 2) | step = 1/40 | loss = 16.52\n",
      "Epoch = (2, 2) | step = 2/40 | loss = 13.79\n",
      "Epoch = (2, 2) | step = 4/40 | loss = 18.85\n",
      "Epoch = (2, 2) | step = 5/40 | loss = 18.01\n",
      "Epoch = (2, 2) | step = 10/40 | loss = 20.47\n",
      "Epoch = (2, 2) | step = 20/40 | loss = 18.95\n",
      "Epoch = (2, 2) | step = 25/40 | loss = 19.85\n",
      "Epoch = (3, 3) | step = 1/40 | loss = 13.49\n",
      "Epoch = (3, 3) | step = 2/40 | loss = 16.32\n",
      "Epoch = (3, 3) | step = 4/40 | loss = 24.12\n",
      "Epoch = (3, 3) | step = 5/40 | loss = 20.01\n",
      "Epoch = (3, 3) | step = 10/40 | loss = 18.40\n",
      "Epoch = (3, 3) | step = 20/40 | loss = 16.50\n",
      "Epoch = (3, 3) | step = 25/40 | loss = 17.07\n",
      "Epoch = (4, 4) | step = 1/40 | loss = 13.84\n",
      "Epoch = (4, 4) | step = 2/40 | loss = 13.50\n",
      "Epoch = (4, 4) | step = 4/40 | loss = 11.25\n",
      "Epoch = (4, 4) | step = 5/40 | loss = 11.09\n",
      "Epoch = (4, 4) | step = 10/40 | loss = 13.04\n",
      "Epoch = (4, 4) | step = 20/40 | loss = 14.66\n",
      "Epoch = (4, 4) | step = 25/40 | loss = 15.01\n",
      "Epoch = (5, 5) | step = 1/40 | loss = 19.47\n",
      "Epoch = (5, 5) | step = 2/40 | loss = 13.42\n",
      "Epoch = (5, 5) | step = 4/40 | loss = 11.34\n",
      "Epoch = (5, 5) | step = 5/40 | loss = 10.47\n",
      "Epoch = (5, 5) | step = 10/40 | loss = 11.29\n",
      "Epoch = (5, 5) | step = 20/40 | loss = 11.84\n",
      "Epoch = (5, 5) | step = 25/40 | loss = 12.52\n",
      "Epoch = (6, 6) | step = 1/40 | loss = 14.53\n",
      "Epoch = (6, 6) | step = 2/40 | loss = 12.23\n",
      "Epoch = (6, 6) | step = 4/40 | loss = 13.06\n",
      "Epoch = (6, 6) | step = 5/40 | loss = 12.00\n",
      "Epoch = (6, 6) | step = 10/40 | loss = 11.83\n",
      "Epoch = (6, 6) | step = 20/40 | loss = 11.66\n",
      "Epoch = (6, 6) | step = 25/40 | loss = 12.39\n",
      "Epoch = (7, 7) | step = 1/40 | loss = 11.60\n",
      "Epoch = (7, 7) | step = 2/40 | loss = 11.05\n",
      "Epoch = (7, 7) | step = 4/40 | loss = 9.91\n",
      "Epoch = (7, 7) | step = 5/40 | loss = 9.85\n",
      "Epoch = (7, 7) | step = 10/40 | loss = 13.35\n",
      "Epoch = (7, 7) | step = 20/40 | loss = 11.62\n",
      "Epoch = (7, 7) | step = 25/40 | loss = 10.99\n",
      "Epoch = (8, 8) | step = 1/40 | loss = 7.34\n",
      "Epoch = (8, 8) | step = 2/40 | loss = 5.73\n",
      "Epoch = (8, 8) | step = 4/40 | loss = 7.83\n",
      "Epoch = (8, 8) | step = 5/40 | loss = 9.10\n",
      "Epoch = (8, 8) | step = 10/40 | loss = 7.88\n",
      "Epoch = (8, 8) | step = 20/40 | loss = 8.92\n",
      "Epoch = (8, 8) | step = 25/40 | loss = 8.58\n",
      "Epoch = (9, 9) | step = 1/40 | loss = 16.73\n",
      "Epoch = (9, 9) | step = 2/40 | loss = 14.65\n",
      "Epoch = (9, 9) | step = 4/40 | loss = 10.94\n",
      "Epoch = (9, 9) | step = 5/40 | loss = 12.21\n",
      "Epoch = (9, 9) | step = 10/40 | loss = 9.96\n",
      "Epoch = (9, 9) | step = 20/40 | loss = 9.63\n",
      "Epoch = (9, 9) | step = 25/40 | loss = 9.07\n",
      "Epoch = (10, 10) | step = 1/40 | loss = 5.73\n",
      "Epoch = (10, 10) | step = 2/40 | loss = 4.39\n",
      "Epoch = (10, 10) | step = 4/40 | loss = 6.77\n",
      "Epoch = (10, 10) | step = 5/40 | loss = 6.10\n",
      "Epoch = (10, 10) | step = 10/40 | loss = 7.27\n",
      "Epoch = (10, 10) | step = 20/40 | loss = 7.48\n",
      "Epoch = (10, 10) | step = 25/40 | loss = 7.66\n",
      "Epoch = (11, 11) | step = 1/40 | loss = 4.53\n",
      "Epoch = (11, 11) | step = 2/40 | loss = 7.85\n",
      "Epoch = (11, 11) | step = 4/40 | loss = 6.84\n",
      "Epoch = (11, 11) | step = 5/40 | loss = 6.43\n",
      "Epoch = (11, 11) | step = 10/40 | loss = 5.09\n",
      "Epoch = (11, 11) | step = 20/40 | loss = 6.30\n",
      "Epoch = (11, 11) | step = 25/40 | loss = 6.52\n",
      "Epoch = (12, 12) | step = 1/40 | loss = 10.78\n",
      "Epoch = (12, 12) | step = 2/40 | loss = 7.63\n",
      "Epoch = (12, 12) | step = 4/40 | loss = 6.47\n",
      "Epoch = (12, 12) | step = 5/40 | loss = 5.90\n",
      "Epoch = (12, 12) | step = 10/40 | loss = 5.72\n",
      "Epoch = (12, 12) | step = 20/40 | loss = 6.34\n",
      "Epoch = (12, 12) | step = 25/40 | loss = 6.43\n",
      "Epoch = (13, 13) | step = 1/40 | loss = 0.86\n",
      "Epoch = (13, 13) | step = 2/40 | loss = 1.11\n",
      "Epoch = (13, 13) | step = 4/40 | loss = 2.98\n",
      "Epoch = (13, 13) | step = 5/40 | loss = 3.43\n",
      "Epoch = (13, 13) | step = 10/40 | loss = 5.05\n",
      "Epoch = (13, 13) | step = 20/40 | loss = 5.55\n",
      "Epoch = (13, 13) | step = 25/40 | loss = 5.62\n",
      "Epoch = (14, 14) | step = 1/40 | loss = 6.35\n",
      "Epoch = (14, 14) | step = 2/40 | loss = 3.36\n",
      "Epoch = (14, 14) | step = 4/40 | loss = 4.03\n",
      "Epoch = (14, 14) | step = 5/40 | loss = 4.17\n",
      "Epoch = (14, 14) | step = 10/40 | loss = 4.33\n",
      "Epoch = (14, 14) | step = 20/40 | loss = 4.14\n",
      "Epoch = (14, 14) | step = 25/40 | loss = 4.72\n",
      "Epoch = (15, 15) | step = 1/40 | loss = 0.97\n",
      "Epoch = (15, 15) | step = 2/40 | loss = 3.00\n",
      "Epoch = (15, 15) | step = 4/40 | loss = 7.20\n",
      "Epoch = (15, 15) | step = 5/40 | loss = 6.96\n",
      "Epoch = (15, 15) | step = 10/40 | loss = 5.25\n",
      "Epoch = (15, 15) | step = 20/40 | loss = 5.13\n",
      "Epoch = (15, 15) | step = 25/40 | loss = 5.09\n",
      "Epoch = (16, 16) | step = 1/40 | loss = 12.21\n",
      "Epoch = (16, 16) | step = 2/40 | loss = 6.88\n",
      "Epoch = (16, 16) | step = 4/40 | loss = 6.91\n",
      "Epoch = (16, 16) | step = 5/40 | loss = 6.04\n",
      "Epoch = (16, 16) | step = 10/40 | loss = 4.50\n",
      "Epoch = (16, 16) | step = 20/40 | loss = 4.23\n",
      "Epoch = (16, 16) | step = 25/40 | loss = 3.89\n",
      "Epoch = (17, 17) | step = 1/40 | loss = 2.51\n",
      "Epoch = (17, 17) | step = 2/40 | loss = 3.46\n",
      "Epoch = (17, 17) | step = 4/40 | loss = 4.09\n",
      "Epoch = (17, 17) | step = 5/40 | loss = 3.48\n",
      "Epoch = (17, 17) | step = 10/40 | loss = 4.12\n",
      "Epoch = (17, 17) | step = 20/40 | loss = 2.98\n",
      "Epoch = (17, 17) | step = 25/40 | loss = 3.23\n",
      "Epoch = (18, 18) | step = 1/40 | loss = 1.82\n",
      "Epoch = (18, 18) | step = 2/40 | loss = 1.10\n",
      "Epoch = (18, 18) | step = 4/40 | loss = 1.55\n",
      "Epoch = (18, 18) | step = 5/40 | loss = 1.45\n",
      "Epoch = (18, 18) | step = 10/40 | loss = 2.24\n",
      "Epoch = (18, 18) | step = 20/40 | loss = 2.40\n",
      "Epoch = (18, 18) | step = 25/40 | loss = 2.53\n",
      "Epoch = (19, 19) | step = 1/40 | loss = 1.02\n",
      "Epoch = (19, 19) | step = 2/40 | loss = 1.91\n",
      "Epoch = (19, 19) | step = 4/40 | loss = 1.60\n",
      "Epoch = (19, 19) | step = 5/40 | loss = 2.14\n",
      "Epoch = (19, 19) | step = 10/40 | loss = 1.92\n",
      "Epoch = (19, 19) | step = 20/40 | loss = 2.37\n",
      "Epoch = (19, 19) | step = 25/40 | loss = 2.22\n"
     ]
    }
   ],
   "source": [
    "CTRmodel.train(trainDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c9f37b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4db818e580>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABWp0lEQVR4nO2dd3gU5fbHv29IKKEnhE4C2FGKilhQVBAVKyDeq66ABVAUO9dyc+1iwS4qioIFFnu96FVBsKJIR6qA0juhBaQkOb8/zr6/mZ2dvrONvJ/nyTO7szsz785uvnPmvKcIIoJCoVAoMo+sVA9AoVAoFP5QAq5QKBQZihJwhUKhyFCUgCsUCkWGogRcoVAoMpTsZB6sQYMG1LJly2QeUqFQKDKemTNnbiGiAuP6pAp4y5YtMWPGjGQeUqFQKDIeIcRKs/XKhaJQKBQZihJwhUKhyFCUgCsUCkWGogRcoVAoMhQl4AqFQpGhKAFPMOEw0LIlkJXFy3A41SNSKBQHC0rA48BJnMNhYNAgYOVKgIiXgwYpEVcoFMGgBNwnbsS5uBjYsyd6uz17eL1CoVDEixJwn7gR51WrzLe1Wq9QKBReUALugJWbxI04Fxaav8dqvUKhUHhBCbgNdm4SN+I8bBiQmxv9em4ur1coFIp4UQJug52bZNgwoEaN6NeM4hwKAaNGac+Livh5KJS4MSsUisqDSGZPzI4dO1ImFbPKymLL24gQQEUFcNNNwIsv8rqiIhZvM3EWgpeq/ahCofCDEGImEXU0rlcWuA1ObpIGDXhZXAysWKEsa4VCkVyUgNvg5MPevp2X/fsndVgKhUIBIMn1wDMNaVEPGsS+70aNgKef1tZv2QK0agUcdpj9fhYtAqpVS+xYFQpF5UNZ4A6EQsDJJ/PjsWOj3SRbtgB//QXMmmW/jyOPZKFXKBSKIFEC7oIzzuBlXl70euleGTHCfnshtH0oFApFUCgBd4F0kRjDBj/6iF/bu9d5H99/H/y4FApF5UYJuAs2bODl/v2xr9WoAfz9d3LHo1AoFIAScFf8/DMv9Zb23r1A167AvHnuLHCFQqEIGiXgLjj9dF4ecoi2bssWYMoUfqwscIVCkQpUGKELKip4KTMqARZwALj/fuCSS5I/JoVCoVAC7oKvv+bl0qVa9qUU8G7dgLZt7bdftQrIVmdaoVAEjKMLRQhRXQjxmxBirhBigRDiwcj6VkKIaUKIZUKI94QQVRM/3NSwaxcv9ZOYUsD/+IOjUexo0QJo0iQxY1MoFJUXNz7wfQC6ElF7AB0AnCuEOAnAEwCeJaJDAWwDcG3CRpliLryQl/q0+mrV2PL+7DPgttvstxcCOO20xI1PoVBUThwFnJjSyNOcyB8B6Argw8j6twD0TMQA04FDD+Wl3g3SqxdHoDRvbj+JKSsQ/vRT4sanUCgqJ66iUIQQVYQQcwBsAjARwHIA24moLPKWNQCaWWw7SAgxQwgxY/PmzQEMOfmsWMHLsrLY16pXtw8jlBOgCoVCETSuBJyIyomoA4DmADoBONLtAYhoFBF1JKKOBQUF/kaZYn78kZdVdV7+224DrrjCOZGnvDyxY1MoFJUXT3HgRLQdwBQAJwOoJ4SQToXmANYGO7T0oVMnXh5+uLZu7lyOLqlenUXazDoHlAWuUCgSh5solAIhRL3I4xoAugNYBBbyPpG39QfwWYLGmHKs4sAbNAAGDmRfeJbFmdRvo1AoFEHixgJvAmCKEGIegOkAJhLRBAB3AbhdCLEMQD6A0YkbZmqZNImX8+Zp66SAN27M0ShWAl6tGrB1K7BtW+LHqVAoKheO6SVENA/AsSbr/wT7ww96pI9bukmIWMALCoAlS4CJE4F+/YA6dcy3N5ahVSgUiiBQtVBccOWVvJRW9r59XMjq6KOBGTO4ubGsWGhk+3YVB65QKBKDSvB2gbGbTvXqwFdf8WOZhWkVSiijUFQcuEKhCBplgbtg4UJeyqQcPbLJg1UooYpCUSgUiUIJuAt++IGX+fm8nDiRrfL589kaB5wtcIVCoQgaJeAukFEmMg583TrOzszNVRa4QqFIHcoH7gKi6DBBWYmwQQOgaVNg+XLraoPSQrcKM1QoFAq/KFlxweTJHEI4dSo/37IFyMkBatdmgW7dOrbhsSQvj63zPXuSN16FQlE5UALuAhn/LZcyiUcIrhX++OPA7NnW21evzgk9CoVCESQZJ+DhMNCyJbskWrbk54ne15AhvJRRKO3ba23U9uwB7rkH+PVX822XL6/cceBBfl8KhSKatPeBh8NAcTEXjsrLY4tXdsZZuRIYNIgfh0Le9ztokObasNtXYSEvpYBLQQc0H7fVJGZljgP3co4VCoV30toClwKwciWL59at0W3NABaH4mLv+y4ujvVLW+1r+nReSgHXx4NL37dVGGFljkLxco4VCoV30lrAzQTAjFWrvO/bahuz9TIOXEaaNGsG3HUXP87JYReJkwVeGfFyjhUKhXfSWsDd/qNLF4cXrLYxW3/ooVyo6sgjWZA3bNAmJYWw78pTmS1wL+dYoVB4J60F3M0/em4uMGyY930PGxbdpNhuX/o48G3b+Lm+udDKlcBDD5kfp359Xtat632MmY6Xc6xQKLyT1gJuJgA5OUCVKvy4qAgYNcrfhFgoxNtK7Pb1ww9cVXDSJEC29WzQQHu9oMA6Drx5cxb87du9jzHTkee4aVN+3ry5/+9LoVDEktYCLgWgdm1+XlQE3HoruzH69+d09njEQL+t3b70k5f6LEzJc88B48dbb2tWBKuyEAoBa9fyOVi9Wom3QhEkaS3gAP/DDxwI1KrFItumDa+///5g9l+zJnD77fbvufdeXhJxQavrrwcOOUR7ffRorayskd9+Y/fL6acHM14/pDoW++mnea5g69bkHlehONhJewEHWHjkZODOnbysVSt+y7aiAti9m4tT2e1LRp8Q8QVk5EhOn5e4mcSUkSzJxhiKKWOxkyniMslp4sTkHVOhqAxkhIA/9hiwYwc/lsuGDTV/tF927+blu+9ylx0rJk/mJRGHCxpDA2vUSN8wwnSIxc7J4aXVOVIoFP7ICAHPzuY/QLPAAes2Zm7RJwXZCfiPP/KyqAj4z3+0yBJJOocRpkMsthJwhSIxZISAT5gA3HgjPz7sMKBFC368fn18+83PB0aM4Md2At6iBUdSHHUUW/3GJsV2FniqBTwdYrGVgCsUicFRwIUQLYQQU4QQC4UQC4QQt0TWPyCEWCuEmBP5Oy9Rg5w+HXj5ZX48aBAwZQo/jtcCB7RaJnYCXlbGboeyMq0SoZ733+fmxmY0b87LQw+Nf6x+SIdY7BNO4KUqqatQBIubYlZlAO4gollCiNoAZgoh5HTUs0T0VOKGx8gkGiKOZmjcmJ/Ha4HPmMERLoC9gM+YwXHcX39tLuB2pWIPPTS1YYQybG/wYC4E1rQpMHx4csP5rruOY/ePPz55x1QoKgOOFjgRrSeiWZHHuwAsAtAs0QPTIwW8ogLo0QMYMAC45Rbg2GPj2+/GjbwcMCBWlPVIAZ4yBZg1i4VcH473wQfAv/5lvu2BA+y3T+VkZiik3Qn873+picUeMCD+70uhUETjyQcuhGgJ4FgA0yKrhggh5gkhxggh6ltsM0gIMUMIMWOzz7ARvYCvXcvW8nPPAeec42t3/8+uXby8/XagXj3r9z37LC9ffFETYn043s8/R2d16pk0idPo4x1rvFxwAbuL2rVL/rFvvJHvUpYuTf6xFYqDGdcCLoSoBeAjALcS0U4AIwEcAqADgPUAnjbbjohGEVFHIupYoC8g4oGcHBaf8nIOI6xTh/3RJSW+dvf/lJby8o8/NDE3Q3ajN7pZZDhejRrOUSjffRfXUOOmvFyL5Ek2JSUc8WNVL0ahUPjDlYALIXLA4h0moo8BgIg2ElE5EVUAeA1Ap0QN8s47OYKhenV2R9Spw26Ak0+Ob79SwHv2ZNeIFZ99Zv3aqlU8rv37zSNOpMWe6qbGf/zBn3fevOQfW7aiU1EoCkWwuIlCEQBGA1hERM/o1uv7sPcCMD/44UVDxAJety5PZMYbhaK/IbCbxLTLoiwstG/qIEU91QIuvVcrViT/2AcO8FJFoSgUweJGVjoD6AugqyFkcLgQ4nchxDwAZwK4LVGD/PproF8/Fu9+/TiaoUkTfh6PKIRCWrcdOwFv1IgvGMaKgzIcLzeXXzPbhxRwIfyPMwiejji4rFw9iUQKuLLAFYpgcROF8hMRCSJqR0QdIn9fElFfImobWX8REcUZ1GfN4sXA2LEshm+8wS4PGUoYrxUuQwDtBHz/fhY+mX4uRHT52SFD+EJizNAEOPkHANq2jW+cRrwWqJLny+5zJoozz+SlEnCFIljSvqkxoLkfysvNY8H1haW8MHQo8Omn/NhO2BYu5Dhwab1+9BHQq5e7Yxx1VPBx4H6aBf/vf7xMhQU+dCjQqZPmC1coFMGQEan0UsB//ZUt5m++AY4+mt0XzZr5L5e6fDlb9eEw0Lmz8/ulBWl0pcycCVx5pXl9kT17OPQxSPHyU6BKTsSmypXTpQvQtWtqjq1QHKxklIBv28b+1Nxcrk/y739zDLbfcqmlpexLv+IKFn4r3n6bl82bA089xb0x9bzzjnYRMV5APv6Yt7voIg8f2AE/Barq1uWL3oABwY3DLV26AEccoVV1VCgUwZARAp6by5mSshJhnTq8XL2au8P7LZe6axdb0999x8JvRa1avGzaFLjjjmixD4c5wQcwv4DIScxp0xAYfgpUHTiQujjwPXs4jLFPn9QcX6E4WMkIAe/fn8PgpOtCNgju1IndE2a4KZdaWgpUrcqTbO++a/0+aYHv2MFCpC9DW1xsneADJCYOfNiw2PorTgWqysqAuXOBceOCG4dbpPtIhREqFMGSEQIuMVrgTZpYNxN2Uy715JOB007jx27qga9Zw66AP//UXnNyZyQijDAU0srrGiNirJAiOmdOcONwiwwj3Lcv9eV1FYqDiYwQ8ClTOOqjUSPghhu0JseNG/M6v+VSX3sNuOcerpRnJ+D16wMdO2quE/1Fw8mdkahEnptv5uU117hr7vzxx1ySIJVx4EBqjq9QHKxkhICvXs3hfieeCLz0kubLbdyY3RmjRnFzYoCbLThZo0aqVbMX8H37gGXLgE2b+LmsIQ4419s+8URedujgfjxuKCriAlzGY1tRsya3oUuFgF5xBXDccfxYuVEUiuDICAGX1mtpaXQ4XpMmXBL28suB7t15XUkJRz04sX8/XwBeeslZwP/8k+PAP/iAn+sFPBTiC0ZRkbk7o107ntz86ivXH9cVf/0VHZvuxIsv8nxBKgT8gQf4DuCbb7S7J4VCET8ZkchTpQov+/VjAVq8mJ/37s0+6fJy4JNPgJ9+Yp/2b79pbdes2LWLxb+sjMMAZb1sM2QijhQ/vYADLNZLl3KzBxmRIikpYcv9sMO0zxEEskOR28xKORErJ4CTyf79/H0UFSX/2ArFwUxGWeDbt0cL0PHHs6jLnosnnMCPf/stenuzRB9ZibB2ba7VffTR1seX1vO557JwVq0a+54lS8yt7LFjORvzkktcfFAP7NjBS7cW9YEDwIUX8h1HsmnSBPjnP4EPPwS2bk3+8RWKg5WMEPDatYFWrVh0ZQQKwJmRv/zC7oQrrgCmTmVfs17AZdq5MdFHhg3WqsVx4EbR1yMt5/btuTWZWURJs2bsojCmzcswwrlzvX5qe7Zv5+Xdd7t7f1mZdqFLNmVlwIIFwKWX8oVOoVAEQ0YI+HnnsR+6ceNoAV+7FjjlFOD119kNsm4dx4bPmqVFf1ilnT/3HD+uXZsjOh57zPr4L7zAy7/+sq6n3awZW8PbtkWvT1QUyo4dPEHqtk3ZgQPsh7711mDH4fbY8s5JFbRSKIIjIwQcYEt68WIWIekGkQWtZEnYZs2A++7jeG0pmFZx2nLys7DQeRLz5595OXmydWu0ZpEuocbEokSVk92+HVi0CPj+e3fvl5O/U6cGOw43HDigXXhVFIpCERwZIeAPPMC+bmM/ys8+YxfIjBm8vnlzDpXTRzrYxWmPH8++bycBr1ULOOMM3sY4gSlp1YojToz7SVRHnieeYFF260L54w+ux5LsKBQiHqcUcGWBKxTBkREC/vLLsRl8Ml29SRPNbSGt4OHDtck6pzhtwFnA9+4FZs9m69pKwE84gf3cHTtGr+/RgxOBZBx0UJxxBnDWWe4FOSuLY8FTIeB33w2cfTY/VwKuUARHRgj4li3m61et0tworVtrGZLffMONHwAtTlsi47R37WLLetMmZwFft459zpMnWwu4FR06cCihXa0VP0yY4C2u+1//4mQo/fv9luH1QlYWzy/068fum/PPD/4YCkVlJSME3KqZfWEh8OijHImyfLm2vlMntoalWOmzMmXa+c6dwO7dbJU+8US0yBvRF46yE/CLLuISt3rWrtVcPEGxbx+HBM6c6T4OfMwYtn4POYSfW0XnBC3iFRVa6ODJJ3NVSYVCEQwZIeBXXx27TrpBTj0VOOmk6NdOOIH9rsbCTXpXyq5dPLGYm8vtzuyiOaZM4WUoBDz4oPX71qyJDRd89VUeT5Bx4DIGHPAWB37rrdpn8dMUwg/btrFov/IK3xXNnBns/hWKykxGCHivXtH9JvXp6i+8wEIshOYG6NSJ36eP7T788OimCqWl7EIRgmt1f/SR9fFlBMnpp2u+XDNkLLgeOYkZZPyzjAG/7z6tJZwTxjhwP00h/CCjX3JygIEDOYpIoVAEQ0YI+IknagI4YoTmBgmH2bcrkW6A777jrjky25KIb+WlmAKaDxwARo8GbrrJ+vjS6p46lftjWmEm4HLyNci+mNICP+EE7WLlRFkZ1wLv1InH5KcphB9kJcKcHL7bUWGECkVwONZCEUK0APA2gEYACMAoInpeCJEH4D0ALQGsAPAPItpmtZ94keKrrydSXBzdXAHQ3AB//aVZzn//zdUE8/O193XpwqVoAedJTBk7/eab/L7x483f16wZT7ju26f5zRMh4NICX7WKx3TVVc7bVK3K261fz+MbNiy6MTLgvgyvF4wCrqJQFIrgcGOBlwG4g4jaADgJwI1CiDYA7gbwLREdBuDbyPOEMHcuh8z16cMTYRI7N4A+cUaKyD/+oa3r108TKycBr14duOACjjO3m8Rs356jLKTlD0Rb/UHRsSPw7bd8kbr6ancNk0tLtWzTvXu16Bw5QdyggfcyvG6QY8vO5ighJeAKRXA4CjgRrSeiWZHHuwAsAtAMwMUA3oq87S0APRM0RuzezbU0Bg6Mrqtt5wZYsoRjrydP1kSkpER7z759mlVctapzHPgPP/AkpVUHIIB97BMmRFv6oRBPksq64EFQvz53eJd3EG4nMuXFRx+ds2kTu5tOOy148Qa4Pvsjj/D3plwoCkWwePKBCyFaAjgWwDQAjYhofeSlDWAXS0KYOJGX55zD4ixD3eySdBo35uSbX37RLHC9e+Dkk7VJzWrVWOSt2n2VlGjt3LzGgR97LNdPkXHpQTBvHvD++1pjCycB//tv4Morta7w+vcvX84XpUWLghufnvx8dmkdcwxPuMoaNAqFIn5cC7gQohaAjwDcSkQ79a8REYH942bbDRJCzBBCzNi8ebPnAYbDwOOPa89Xr9bile2aKdSty7XCp083dzHIKBSA92fXK1IfAWMn4Lt3c93r55/X1i1ZwnXKg+SDD4DLLtPuBswEXJ+kc/jh/HzXLqBz5+h5hKuu4gvdsmXRrc+CYt8+nnT++2+uiS6zZRUKRfy4EnAhRA5YvMNEJAPBNgohmkRebwJgk9m2RDSKiDoSUccCq4wcG4qLYwVKH68cCrFAVFTE9obs1IlDBGW7tYYNtdf0At6kCfuvreqVyIJR558P9O1rPdbcXLbWV67U1o0Ywe4J2TEoCHbs4AuUvPswnh9jks6aNby+YUO+mOhdT1K0y8pYxINm9myuE/Pdd8Dnn3MkTGUkGVmvisqHo4ALIQSA0QAWEdEzupc+B9A/8rg/gM+CH1588cqdOgEbNrBl3LFjdJ2SXbu0oleLFnHtlN277fd37rnsL7ZCiOhQwnAYeCsyS/Ddd8H908rGFuefzxO8xu5DZkk6APDf/8auk63lsrODjwEHouPAx4wBnnwy+GOkO8nKelVUPtxY4J0B9AXQVQgxJ/J3HoDHAXQXQiwFcFbkeeDEE6982mncCaa0lK1WOVFZUcFiLS3wqVOBIUOsu8XIDvAff8xWvh1SwOU/rYxIKSsL7p9WWuB5eVwBUZ/qD1gLcUkJ0KYN35VIDhzgePI9e6xL5caDtPCzsytvGGGysl4VlQ83USg/EZEgonZE1CHy9yURbSWibkR0GBGdRUQlTvvyg5tqgla0b89FpPbt456V0v9aUQHccw9nVgKaAFpFokjBmzJFm1C1Qgp4Iv9pt2/njvRr1/KdgzF5yOriVrs2323IOHKABbZGjcR169HHgdeoUTmjUJKV9aqofKR9JmYoxJOC0j/dtKn3eOVNEe+8rEeSnc0XgG7d+LmTgGdns5UKOEehdO/O0S2J/KcdM4ZrrCxbxncOxjT9YcNi+3bm5gJ33cWP9T7zRx8Frr8eGDkSuPHG+MdmRCXyJC/rVVH5SHsBB7hzTkUFVw1cu9abeF94oVa/5Kqr2IVx4ABnTEr/rJOA79+vdf1xEvD+/fmCk8h/2kMOYV+8Ma5bEgpFT5rK6JzevWPf37s3cOaZ3O3orbesQyn90qYNhw4WFVXeRJ547iIVCjsyQsClUP38sxaP7YZwmGuDS7ZtYz/08OGcgThhAq93EnB9ZqWbOPDycuDhhxP3TztyJLt15FjMxi3vWAYPZtfP++9rlRL1Aj59Omd0HnUUzwsY3THx0qoVcMstnHR0zz2JiXRJd2S4q3RTNWyYmKxXReUjIwRcxi1//jnw66/ut7OqlTJiBD+Wk5innsrCYtU1Rx/l4STgM2fyBSEvj/9JGzeOjVGPh4oKdnVMmGBtgQPAbbdp7y8p4XO3dy/fjTTSpVz16AE89ZQWXeMmocdLSNy2bcD8+XyRqV+fXWCVkVCIL5KAEm9FcGSEgOvRJ6E4YeVvlj5xGUZYsya7JazEWcaB9+wZ2zLNSKNGbIGvWcP/pKedxqFjBQXB/NOWlvL+6tbV7hzMBPzMM/niQaT5oRs3Br7+msMhJQcOsGUoxcVJwL2GxE2YwKUEVq/mi9sDDziHax6snHEGLyvjRK4iMWSMgMscIC8CbuVvlrVKpAW+aRP7151qdp96anRWphmNG7NlKl0RspiVVYiiV2Qp2Xr1OOJl+XLg0kuj37N5M7uOzj+fSwboC0oZkQLesCGnuztVTfQaXaOfxJw1i0vzyh6mlQ1Z+riyXsAUwZMxAi5LuHoRcKvJo549+bG0wDdv5sa7xm46kiuu4OXbb0d3wzEjO5utcKOAB4UMAaxbl0WxdWvtQiT5/nuO6b7xRp64lSJapQpf1J7RpWNJARcC+P137tpjh9foGn0ij/wuKqsFWlAAfPFF9B2QQhEPGSPgMjrCi4DLySPZh7FePX5+441cIU9a4k6TmLKn5bx5LPZO6LMxpYAHVQ9cb4GXl3OdGGOtFekGOeIIXlatyi6i2rU5M1U2iSaK7dTjhNVdTVaWuRvFGEYIVM5IFIDdaePGcVlihSIIMkbA776bxfuww7xtFwoBQ4fy46lT+XmHDnzLL2ukOAm4vkaKmyiUAQO0mPOgLfATTgD+/JOLUgnBkR3ffhv9nsWLedK0bVseS+fOPEnbsSOPX+8z//BDrU76Z5+xL7zEJiVr2DDzc1Bebu4LNybyAIkX8HStO1JSwuUMrO70FAqvZIyAV6/ONbB91MPC3ZFWE9Iy3bgx+pbfScD1VfrcCPh113HtcoBDFgcN0tw28VKtGofm5eayQOXkxE5iLlrEQlxWFluJsVo17f1C8IXm6KP5eXY2i7/dRKYxsUqPmS+8e3dOPKpZMzkulHSuO1Jayn9vvpnqkSgOFjJGwEtLOY1dH5Ptleuu4+VDD0WHDLpJ5JHYNXSQlJVxFEpZGU8Mvvoq8Oyz/sZs5Jdf2G0irdjq1aPHXVHBk7FHHskCTcTNKLp2Zctd//4DBzgqRV7MZCTK4sX2Yxg0yNolZPSFH300dw3KyeEJ1R07tBIGiSCd647I366axFQERcYI+O+/83L5cv/7kP5zfSlZQPMNDx5svp20UIHYwlFmhMMcO75iBUeDONVP8cLkyew2kS3j9Ba15Kef2M+flcVCu2EDJ/Ps3ctp/vLitWMHT6h9FqkjWVTEAu8USrh+fXRpXj1GH/mqVRy7T8QiXqeOt3kMr+hL+RrHkUpkATWg8k7iKoInYwRcEs8/f506vNSXkgVY6Bo1sraup0zhZZ8+5qF4RmTRrLVr2Wd89tncVCEIduxg0ZauHKNPOyuLuwAdeiiLfEVFdBjhSy9pNU/0/mmAz+3hhzsL+FdfsRvKeL7MMk1few045RQey7ZtPB+hr4YYJOFwdC9UPamuO1JWpp13ZYErgiJjBPykk3jpR8CloErBMVrgAMcnf/VV9Do5GebGbWJ2vLVrtUlMt30rndixgyNQJHPmaJmlAFvfb7zBx+3Xjy8eRqGWmK2/+GKe/LRDljN47jktLr55c/MMQxmmCPA5ePppbvKQCIqLzV07QqS+7kjVqsCLL3JvVGWBK4IiYwR8yBBe+hFwGdssxdRogQOcTq53dRgnwwDgo4/cTYaZCXhQyGYOkvx8LZoG4DC1oUPZEr//fhZxvQV+/vnABRfwczMBf+ih6BZ2ZkgBv+Ya4L33+PFbb5lnmuoFPNFhhFZuEqLUp65XVPC5ePVV1RdUERwZI+B22YRut330UV7+619akwZJtWrRk4Fmk2FE7ibD6tThC8SaNYmJA9db4K+8AowerT2XEShC8OTrgQNsJbdvr01gymQgK8tcxodbsXMni3F2Nlvr1aoB69aZv1cfZy7vZBJlgVq5SYqKEnM8L8ydy1b4ihXaZLFCES8ZI+CyHknjxt63XbiQl+edx8vevTUrVGIU8HjreQ8fDvTqFbwF/umn0a6eceO0LFWAI0hkYar27dny7N2bXS0FBdE+8+bNOQpF1ugAuPFFnTocH27Fzp3afEKjRuySuvJK8/ceOKBddHNy+A4qURa4WeZtTk7q3SeAFoEyZw5XhlQogsCHPZt8wmFuZwaw9fLoo95uiceO5eWvv3I9k5kzuSpekybae6pWjRbwwkLziAa3k2HXX6+N/d13Y6si+qV69ehYdP2Fp6SE67pIC0+GERq3lwJeq5ZWK13SogVPstlNZA4ZoiUqCWF/VzRwIFc8lO+tUcM6XDNeQiGeKL3pJm3dxRen3n0CaAL+wQd8FyWTpxSKeEh7C1z6omUK+apV/hMzrrmGl6ecEuuH1Avhiy8Cd94Za80B7q25LVu4eNORR3IFPum+iZd77+XSsBK9IMtiXNIClwL+9tvc4Pnvv6Pfv2ULW9obN0bvr1UrtuStMhrbto0W/g8+4IQds2YQxx7LTTUk27cntrHxqadGP0+X8rVSwBs1UlEoiuBIewEPMjGjooIt4f37oycxw2He5wcfsL/4ppvYkh01Krbju1tr7plnOOJg/Hh2UwTlSnn6aeDHH7Xn+sSck07icXftys9lHPjatdy4ISuLy8z26cOvL1rElQxljL3kqKO47IBVRuOUKVqHIoBFedIk8zuWuXO5EYckkTHgQGyi12WXJfZ4btm1i5dKwBVBkvYCHkRvSXmLT6T9g8swQmnhr17Nr2/fziJzyCEs1qtWaW4IacG7oVkznsC74QZOljFeCPzU69i/n61ofRSKMTW+oECbLJRx4PrO8Ndeq0WZWE1iHnUUT8BaXThvuy36TkSGHRovBADfeVx7rfb8oYeAl192/qx+OfVU4KyztOcyIijVHHMMT563aMHfo90ksULhlrQX8CB6S55yCi8rKjQBlxa4mYVfXs6uCoCtx//8hx97EQP5Xun60fui/dbr0FcilLz5ppb6/tRTwOuva6/JolplZSzm0vqVY7EScOmzNmPVKh6HnMQEtExVMwEvK4v2kX/2GfC//1nvPwj0x5s0KbHHckunTjyxLTNYVSy4IggcBVwIMUYIsUkIMV+37gEhxFohxJzI33mJGmAQDWHlhBGRdisrLXAnC3/aNO1Yet+zE3Zi79ctJAVcb4FXraoJ8yuvRMey33wzR4foRfS++7SO9VYC3rWrdehdYWF0FArAF8OWLc0FXB8HDvDdQSLF6/XX+XzIOQd9iGUq2bmTv79+/TgqSh+7r1D4xY0F/iYAsxL0zxJRh8jfl8EOS0PW9C4q8t9bctYsXr71Fk9qjR/PhZUAZwtf77PVR604YRRwvQXu1y20axefA70F/umn7NLYu1drTizZvp2Fo7AQ6NKF1+XksKCXl1sLOMAXEyn0EnnhNAo4wJOasu66HqOA5+YmtpzsL79wpqe8w0pUxItXiot5criggL+jRM8FKCoHjgJORD8AsKkQnXhCIU6AqKjgpRfxDoc5VhoA+vcHvvwSuPxyTaCdLHz9P9pXX7n3VzdqxBcMM/y6hY49lsX3PN39zrRp7FNeupTPj4xAAYBu3bib0PXXa64EfSf7009nF5FZjfV77wXateNbfv2Fs3dvHoNRwF99laN3jBhdKIm2wDdv5qSidevYynVTfCwZyPINf/3FlSn1kT8KhV/i8YEPEULMi7hYLDtFCiEGCSFmCCFmbHbTziZApK9ZxmCvXMlxyf/5jyYiTha+7MYjceuvrlKFb5f//JMFVhYyAuJzC2VlRV9Uqlfnz7dgAT/XW+BmceD6Rsh5eTw/YLydD4fZep8xgy31UaO0C2dODkeoyDZzTjz+eHQp3Xr1Yi37IJENqz/8kO86goq/jxcp4EuWALffzr8LhSJuiMjxD0BLAPN1zxsBqAK+AAwDMMbNfo4//nhKJkVFRCxhsX9//OFuH3l55tsXFTlvO28e0Xffxa5fv55o7FiiggLeV9OmROPGOe9v8mSigQOJtm3T1j32GO/jmWeIcnOJ9uzRXjvhBKIePYjuvZfo1FN53auv8vvXriVasoTojTeIdu3Sthk3jvej/6zVqjmPb9UqotaticJh58+RSFq1ih774YendjySc88l6tSJ6PvveVyTJqV6RIpMAsAMMtFUXxY4EW0konIiqgDwGoBOAVxLAsfOp2wsZmWFVQd1N2GMDzzAaeoTJkRHo5x/Psecb9qkxWm7cQvNns3lWfUlU6VL5Oqr2Ueur5wowwjXruVbd4DT62+/nbf7/nveTtZGAcwnWPft0yZYN21i19D69dHvadyYQzHnzYteP2lSdBy4W/y2RTPWKf/iC+/HTgTSApd3OyoWXBEEvgRcCKGfzusFYL7Ve1OJnU+5Uyd3ohBPGKOcyLzwQo7/bdmS3R+zZlk3RNBjFLGffmJR1l98atTQknmMbc5kIo/eD33iiZwMlJenuRf0k4xOE6wLF3Kne5n1KcnJYf/7fMMv4c47o6sbvvuus/slnrZov/7K4ZOSVNcBlwwaxOOSAq7CCBVB4CaM8B0AvwA4QgixRghxLYDhQojfhRDzAJwJ4LYEj9MXZr5myerV7kRhwIDYWh9u/dX6SJRdu6JL044fzynuXbtyz0gjN9wA9O0bLWL//S+LtV6or7uOrblQiK16PYMHs4WtrwhYXs5jKSszj0JxumDJUrLGSUyAE3qMoYTGrvcLFwLvvGNfnTHe7Fv99xVUK7t46duXJ8/l71FZ4IogcBOFcjkRNSGiHCJqTkSjiagvEbUlonZEdBERrXfaTyrQT1Ca4UYUZEZl7drewxjtYsH37OGY7N9+i7Vaw2GO6TaKXFmZ+aTcypXcmV7vCgF4EvWyy6It8EmTWHynT9cEXD+paHbRq1pVu2DZCfgxx7ClLt8DRFcjBLR924X3+Q2znD8f6NyZY9/vuovX/fvf3kv5JqKr/fLl7I5r2pQnhC+/PP59KhRpn4kZLzIE0arVlpMoyO169/YexujUmmzVKvYdb9gQvd6qswwQW1Nl1izghBP4sbHO9Pr1/Nehg1YyVvrM9+41t8DlRa95c23dgAHaZ7YT8C5d+K5GH+dtlsgD2LsQ/LqtVq/mCJkqVbSLhr6UgBsS1dW+fXu+CGZnsxFgdWeoUHjhoBdwiV9RkAJuVmnPjnDY+fa9sJDjxY0CbndRMd5NbNgAbN3Kj/Ux4ADwz3+yv/mee4CRI3mdXsAHDuRJR2NYXyikVQwcOxZ4+GHtNTsB79yZ48EbNdLWmSXyAPbJPH7DLGUI4a+/spjLkr5e/M2J6GovGxrL7N9HHw220bWi8lJpBPzaa2MzDt2IgvQ3e70NLy62Fyl57MaNY5M67C4qK1dG39bra4MbMyHlJKYevYAXFLDf2uzuRMaaT5vGE56SgQM5GsYqQaa8XLugAMAnn0SLX14eT+jaFXMKhTjpSo6hShV+7nTnIwV8+XKeLO3QgZ97EfAgiqcZkcfXC3ii68EoKgeVRsB37tRupb34sv0KuJMVLY993HHAEUdEv37//fb71t/Wy05FQKy/VoYRXnYZ0LMnr9Mn8vz4o2aZG5EuiBdfBP74Q1ufn8/CaOWSOussdjdJjjsuOtPzkkv43Ni1OQuHOVRRuovKy/m5kxtj82a+QNWty3MFsg6KFwEPoniaEWP9nZo1VRSKIhgqjYBLIZaNG9z6snv14prZXutKW/3DZ2dHH7u4WOs2JJH/8Hbs2QPccgtXuJMY/bUyE3PjRu7WA3D44n33AW3asHV8553W45RMnao9njDBXkgPP5wnE+UFb9w4nqj1gl83RsOGXO9c3mnNns1NK1q1cn/sYcNi7y68Fk8zYixhXLOmikJRBEOlE/AOHcyLN1mRm8s9DI09NJ0w8+NWqeIu/rtbN3fH2LpVqwUu0QuddKHo/dB5ecCDD/KkmtE/bRyrRO//f/316IuGkbZt+WIhE32uv17rXA+wuJ97LourFX7dGEOH8oVRzj2Ul3P9Gi+Fo0Kh6IbXfoqnGcnP53IKJ57Iz3NzlYArgqFSCHg4rDURWLDAW0TBokXsP9e7EdxgDGEUgsXN2JT5p5/Yap0zR1t39NHxdVKXQjdkCHDrrdFhhEQsrtKlZCXg0n8MRAu4WSVCPcbmDsZj7NnDHYqMmZx6/LoxjO33iDjp6Omn7bczcvrpvOzRw3vxNDPy8jgmX7qSlAtFERQHvYDLf2oZPVFa6i0sbP58TrR56CHvx5YhjLfcwqLXoEH0pCPA4rZ0Kae779vHFuuSJfZJSAC/lp9v/poUup49uX2aXkT37eNY5JEj7QW8aVMt9NCLgB9zDC+lgBsTedyEEfp1Y1x7bex+y8qAJ56w386IrLdu19jCCyUlfMch75YmTuQywApFvBz0Ah5vWJicrDO6KrxCxPswCri0yDdu5Em3V1/lEDhjlcTatdklop+Aff55+3C7FSuAZcu44bC0KvWTmHYCvmOH1jvTi4Dn57OL5YwzeLuKCvNEHrsInVCI249JmjZ1dmMQWScHbdlivZ0Z8pwccoi37ayYNIknc5cv5+d16sT+DioziUicqixkO78ls4k3LEz6zr3GgeuRF4EvvogNn5Mx06tWsYCfcormAw+FNNEiso78KC7m7QsLWbzlNoMHs59cP4koBMd9793LvmIrIZ0/n10wI0ZET+A6CTigia8UVK8WOMDRKlOnsvtD786xwtjMWI8+DNINtWqxFR5U30rjJOY773A52Xhiyw8W5B2y/D3IiXggftdVZeCgt8DjDQvzG0aop2dP4LHHWPiMYvLRRyyqDz7IjYRPOy1aqFev5jGY1UsB7JtdmMWBA2z97d3L1rI+41KPtJp//jm6A9CcOcAjj9h+XOzYweGNWVl8IdAXl6pZkxOOpJhZ0aEDlwdwI94AhxAC5rXG27Rxtw9J48b8GVau9LadFcY+rN98w3daisQkTlUmDnoBj7enphSyeFpgnX46F6caPpwbDUik9aEX2REjom8hs7P59QEDuHWaF2QceNu2XPRKIgX8vfesLwzy8777LjBzpra+cWNOALLjzjvZhVKtGpfO1Wcd1q3LE8NurKtly9j14CZrUSbxdO8ee6fy66/ebsv9Zt9aocIIrUlE4lRl4qAX8Hh7anbuDFxzDXDTTf7HsHEjd44fMSI6A8+N9aF3P6xb5+240gLfsSO6HsiDD3KyzVtvOSfyAJzwA7Do3H+/1mPUjHCYqywCWi2RAQO8+zW//ZajNmbPji01YEb16ly2d9as2LuOAwe8WXQ//MBLP3XMzdi1i7/HqlX5PIwdyxObB5O/168fOxGJU5WJg17Agfh6atavz75pOQnoh+HDueCUcRLTjfWhF1KvoYXSAjf2pbz+erZUvcaBb9nC0Thz51ofs7g4dsJ3795oAT3nHOC55+zHrk9msvNvSzp0AD7/3FrsvVh00vcdlAX+z39qmaT6iKigCmWlmngKgMkCX3riTZyqTFQKAY+HF17gW954Z8jNolDcWB96gfUq4DffzIJrLOm6ahX/2Qm4/lhSyOwKWen37bR+1iznuHr9BKKbzFRJEBad/LxWk8ZWWFmhHTpw+diD1d8bz+cKhTipTBJE4lRlQgm4DeEw+3P37ImvtKg+FFEv4G7889WqaRl8XgW8WzfgootiY7H79GEr3E7A69QBWrfmx0YBt2tH50ZAc3PtwwiB6LK5bizwO+/kmjJWGbBeLDo5EeqlfIKdFTpnDruCDlZ/b1Cfa+TIYBKnKhNKwG0oLo6NLfZrMZWV8Z9ewN3457OzOd67Sxfg0EO9HXPJEhaOvn05PFEiJzHtBFz/Ob1Y4E4NIQAOJXQKI5QWeOvWXL3QibVreRvjOc3O5gugH1GQFzA32Fmh99zDk8hWFzchODs1U+Oh473rkRPQTZsGM55KhVmn40T9JbsrfbwIYd6RXghv+xk6lKhGDaL9+4n27fM+jt27ifbu9b7dJZcQtWkTu757d6KTTybauZNo+3bzbVes4M/68MNa1/p33+V1CxbYH3fcOKKiIu383XRT9OvHHkt04YX2+5gyhejii4nWr7d/n6R7d6ITT4xd37YtUa9e7vYhmT6dqG5dom++cb+N3W+lc2eiM8/k85KbG/169epEzZvz4+zs6Ndyc3mbdMfsc3kZ+3nnEd17b2LHmOkgyK70lYWgZsgvvZRvD2UkghfCYfbBV6/u3SpbvZp9zUaLTlrgtWtraeNGpM986lQt/K1PH27bdvjhzseWrd+aNYuN5T7uOOe7iTPO4HRzY+0YKzZtMi8Ulpvrve5I27YcuTNjhvtt7H4rpaV8rs3uuF5/nb+jWrViE4cyxT8uP5d0rRUWevNjf/GFv1IVCigL3I54LQs9JSVEN9xA9MsvyTn+uHFEVaqYb9unD9FRRxENH85WtRnr12vbTZmSnDGb0asX0VVXOb+vSROia6+NXd+tG1vnXti3j8f9yCPut7H73IccQnTFFfbbB3W3l0rOPJPHXFLibbtt24hatyZ6441EjOrgABYWuBJwB/TugKIif0K0ciXRO+/w2X77bffbFRWZ/1MXFcW37cSJRO+/T9SqFVHfvubbb96sbXPffbzu88+J7rwzcWPWM2YMUUEB0ZFHsjA4MWRIcO6GMWN4zP37e9tu3DiimjV52/x8bTyNGhENGmS/bVDnLZW88AKPefNm99tMmULUogVv9+yziRpZ5mMl4I4uFCHEGCHEJiHEfN26PCHERCHE0siyfiLvElJJPDHkkpde0rqQeyliFM/svt22Z53Fbp39+60nMT/5RHv8/PPsfpk82Trxx8uY774bOO88+/2UlnJ6fJ067sIIR4wILnqBIolAXsMIQyGgXz9+/OCD2njCYeDGG+23jTdjOB2QE/7Gxtt2LFvGrj4guLj7yoQbH/ibAM41rLsbwLdEdBiAbyPPFS7wIuDx+ODttl2zhv27VlEo4TDXEZfs2MEhcbNnOxeycjPmjRu5Rood0h9ct65zGGF5ubVojBkT3aDBDVLAs3zMEEkR1vvdu3UD2rWz3y4UAh54gMNG/WQMpwOyiJkXAddf2OV5V7jH8SdKRD8AKDGsvhjAW5HHbwHoGeywDi70lpwXAY/HKrPb9vnneZLQSsCtQuKmT3cWcKs65nLSMhzmejCrV9tPykoBr1fPWcCnTuXPMWVK7GvTp3M9Fy9IAZJV8bzQuTMv5UTv/v3cMm/FCudtu3VjK/bTTzM7HtqLgK9erRVLUxa4d/xGoTQiItlTZQOARlZvFEIMEkLMEELM2CxLxlVSqla17uZuRjx1XEIh4N57teeNGmnbVqtmHwdu5QbZs8dZwEMh4OSTY9d/+y27bgYN0gTZLjFKikDnzpz2b8fmzWy91Tdx5PmJQpHH9tMVqVcvHsvFF/PzrVu5NO5XXzlvKy1+LwKYTsi7LKdKk3pWreKepRdf7D3PQRFAPXAiIiGE5c0PEY0CMAoAOnbsWClvkmQNbquGA3boa4J7ZdEiXvbvD7z5pra+enUWic2bzassFhaal1KtVs1ZwAHgu+/M13/7bew6GSpn/Ixt2gBXXsm+Y2OtDCMyEcQujJDIvU+7XTu+GCxe7D6M0QpjJUI75HeRqQLevj2XSza7kFrRoQOHyaowQn/4tcA3CiGaAEBkuSm4IR18XH55arLqpGAZmxNIN44xxV5i5X4ZPTq6mqIVXgXIzOK/6CKu2uck3oAm4A0axL6Wm2vfrceMzp1ZeL/5xv02kscf5/Muy/f6EfBMdSXs3s0Tzl4aYTz9tBLvePAr4J8D6B953B/AZ8EM5+CkXTu25K66iifwkoUUrRdeiPYDSwG/+mrzW3tjQ+aCAs394qYuutfa6XaTsmPGsI9061br92zaxFafMUkqHAaeeoofH3YY12R3k6q+bx+7l/xYwlK8ZOSMsZmDHbm5nPbvxYJNJ2rW5LZxS5e6e7+ctDxwgO+enCpUKmJxE0b4DoBfABwhhFgjhLgWwOMAugshlgI4K/JcYcHy5Rx+99Zb/twoftEXjNJbsuecwzW7P/zQura3DJ+sX5+LOoVCbFV+9JHzca0m/7p1cz8pe++9fOcgBEfB2IUSdu0a2+xCFpcqiUy/r1nD34GbkqcvvMBLN0W0jEjrWfrdvVjgLVty8wknn3+60rcvL91e+GbN4t/Xt9+yO8/P+a7suIlCuZyImhBRDhE1J6LRRLSViLoR0WFEdBYRGaNUFDreeAMYP54fJ7OZrZWAH3YYt3kDrOPAJVlZLEpEwGuv2dcCl7z8MvfjlJZ4lSr8fNIktuSlr7pJE+tJWWkFS+Gz++fu3Tt6whYwj6QxYpWqLgVo6VLvxaXktvLYJ53EDSK8tnXLRGTzaLcCvno1l2aQbQYz1XWUSlQtlCSTTAG//nrtsV6ot2zRfNlOtVmkgO/ezSLuZhITYBEvK+Ntysr4OcBiLd0548dbT9DKJhRuBHzjxtg7G7elTM3eJwVoyhTvTQrmzePlxIks+l9+yX1O3bhQ1q3jicBPP3U39nTjhht46UXAAc1Vp+LAvaMEPAn4jQOPl169gOOP58d6C/yXX7hLDODeAndTStYtUszs3CJlZWy5uxHwtm2BW26JXue24JjZ+6QAeS0uFQ5HT/LKdnKDB0e3tLOivJwvAHb+/kzArYCvWsWRTfKOTFng3lECnkTy8pwFM0hmz9YsQn0FQf1FxCkuPSuL/yETIeByn2ZIC7x5c578tWqkXF7OdxTGEEKrhCI9Vv53uygKO8verH783r3AK6+4sy4zPQ5c/rabNXP3/tWruda7EBwy6pStakWm1lEPgrjjwBXOCMF/ybasbriBLb8nnmC/t0QK+KRJPLFox9q1PPY5c/gCJLPm4sGNBd6lC7+vVSueQ7Bi61YWR6OAS9dMcTGLbmEh11/58kt+3qIF8Oij5i6cM89kYTezCO0seztxd1NGONPjwIuKuPer28YMXboARx/Nj8eO9XdMOVkt5xykqwvI3ExWT5hVuErUXyZWIwyCJUuIvvwy+cdt2JCrvH3zTXQjiWnTeP2ECfbbB1GJ0Yzdu7nZhJdzUlFhvv733/mzvPeeu/2sX8+NE0aOtH9fzZreGyxYVRTMynI3tk2b+P0jRrh7f7rRuDHR6acT7dmTvGMeDFUc3QDV0CF1HH44hxL6qa0RDzIK5eyzo5sTSAv8H//gWiFmxNNp3IncXA5h7NHD+j1lZWyJ7t7N1quM5zbeLr/zDq+3crEYqV+f9213N7RjBx/39NO1dXXrOpcxMOuwXqWK+7uWatW43EDz5rGvZYKboHt34PvvORTSiYqK6HmN+vVjI4nccLD2GXWNmaon6q+yWuCLFhHVrs31t5OJ3oLUN5LYuZPo0Ud5/ccfm29rZdk0b56UoVMoxEX+x47Vjp2fT1S1avR4atQg+uc/idatc7/vmjWJbrvN+vXbbuN9X365dpxu3dzt++yzo63ATp3M29p5IegmGYnihx94bBMnOr9XtuwbM4afV6vmXGveDGWBKxLOu++yvzeZESjhcPRk3Ndfa49r12ZLD7CeVLWyYNauDWZ8xxwTHeYokZZmOAz89Rdw7bXaa1u3aq3aJH//zRZfkybuj52fb2+B62O5ZRbt1KmxxzZDFmTKyeFEqI8+cpf8ZIddw2Q9qbbSZQamGx++DCGU/vKsLH9hhAdDHfV4UAKeRLxUIowH6f7Q8/jj2j/0/v3swgCsBdxqss5Nh3g3lJdrWZISvdsG4H9oN6Lp9XY5Ly/22MaxATwxOncu8OKLfKGYOdN533LiU148mzcHjjzS3bj+/ptdQfn50SLsxk2QSJeXW+TF1ouAy9+TEP7CCGXZBxmq26xZ5tVRjwcl4ElA/riSJeBmFtvevVqs9N69wPDh/NhKwK3C8B59NJgx1q4dG4XiJnvSDK+dc66+Wiv3aoYUoMcjBSK6dOHl998777tHD07tv/NOFtK3346++7Hjvfc4JLKkJFqEZaaiEf1F1q2VngzcCLi8+EgB92uBA9E1en79tfKIN6AEPKl47WbvFyuLbetWtsj0F5IaNczfKy0bWU41O1vrrB4EZgLuZ+KpShVv7hOAO/QMGGD9enk5f+7ZszkVfudO4Kef3HX2uegiru0hqxI+/DCLuBvuvz92nRRl48Xf6CZI9WSeFN969bTQQDtkIwcZUjpggHkdebfIO55MDcH0ixLwJCAtRK+dYfxid6EoLtZiku+7z/6fJhTi9O6KCm6x1r59cGOsXTs2kcfNBS4nRxOzoiLgkEOiY9zdUFbGxZOs6NOHrd6XXgKmTWPrsHNn58QggCNY1q1jK7qigi9SbtLoAc2tYKSkhCOGJGaNPeJpvxcEUkBvvx1o3dr5/eeeC/znP9rzZ5/l8+4X+TsOIk8hk1ACngSuugr48Ufvt/p+sZvAWbWKx1G9OrtSnJBJSE8+yZ8hKHr04FR/PWZum5wc9gnLjkRvvMFFtfr25UlOIcwbOdjx0EPcocjKWjv7bA4jlI2d69UDNmxgwVm40H7fN9/Mftj8fBbv0lL3HWqs5hcKCzVhOvFE83ZrbibzEjnJKUsFLFnCBaqcuOAC4I47tOd2fU3dMHUq3wXUret/HxmJWWhKov4qaxghEYfFPfZY8o6Xn28fXiWfr1jhvK/rryfKyQk+oceMceOICgv5WC1aOB+rfn2iIUO8HeO55/izb9li/vratdHnrKxMW/fUU/b7DoW07WRizv33uxvXuHH8uc3CBc89l+jYY523b9GC91FYGH3unEIR403a2r+f6F//4v2OH+/8/iVLOKFLkpdHdOON3o6pZ+dOosWLifbu9b+PdAYWYYRKwJPAvHl8pvv1S94xnf5hb76Z1y1c6LwfY+x1UDHI+/fHrvv4Y6IffyTq0oWz+uyoqOBx6GPc3SBjy5csMX/9ssu0z1qnjrb+0EOJLrzQft/62PGlS3n55JPux/bCC3x+jUJ66KFE//iH+/0YsYuXfuWVYOLM//iDtx071v59u3fz+x59VFvXoAHRDTd4/VQarVvzPhct8r+PdMZKwJULJQl8/jkvk1nIyqkhcseO7sZUXBwbyhdEdMPjj7Mv3rjvoUO5hssPPwB//mm+7aJF7Ff++GP+PCed5O3Y+fm8tIoF19/Kn3GG9rhZM2DCBHsXhH7bnBxuJGE3YWrkppvYtfXvf2uuEiIOLywt5Vojixdbb3/KKeZ1d+wmOe+4I/4Iln37tI46ffvau2iMIYQAj9lvFAqg/VbUJKYiYSQzkQfQuupUVMT6TaV/10nAExXdIP21+kiUP//kv7Zt+bnVpF6DBixmCxeyX96uqqEZbgX8ssuAzyLNAsNhLsMrbVSrOGt9LPMpp7BIdejg3t9crx7vQz8/IQT7eIcO5ZIIGzZYb//LL7yUzRUkdpOcVqGbXr7jV17Rar4D9nHocr/6McmyxfFS2UrSKgFPAnLyMtkCbodbAU9UdIMsS6sX30mTeGlXIwVgAc/J4cYHXbpoJXPd0qoV8MgjsdErcpLv4485PFHf2sztnUgoxC3rcnI4GsVrUs2OHbxcsyb2NRkPbpeEJDFOUNtNcgbxHcu8Aj1WVryZBR5PHLgeJeCKwJE/TLMiRanGKbkoUanKZiVlJ07kc3TMMfbbCsEp2HPm8HOvUSgFBSwsRxyhrTNmgZaXAwMHshgD7u9EevZkF4exgYNXl4T+Yj96NEefyIutHwEPhThUr2bNWJfasGGxxoXX73j9evP1K1fGXrhkJJS+bvgNN3D0T7xUNheKqgeeBGSh/sGDUzsOPV268LikO8EKs7raw4bFn9BjFHAiTlXv3l0Tqksusd6+aVNNbN1WItSzZg0nJ8lEJbNMxooK4Oef+XFhoXY8PUYrdd26YNxO+gvr3Lns95fH2rbNeXuzENFBg8wrYoZC7MO+5x6Oj/fzHTdubC3ixvrcF13E35++Rro+JtwPeXn8ew6q1EPGYDazmai/yhqFsmED0ezZROXlqR6JxtlnE510UuqOv3w5h50tXaqtO3CAaOtWjg4B7KMgXniBKxFmZ1vXCrejQQMOj5QYw/f0f0TuKwKed571ftxUyJPvnTpVWydDCCsqiE47jeiNN6y3P+oo3t4sHHDTpsT9Bh9+2Ppz6z+/1Xe6fTtRaWlixnYwgESEEQJYAeB3AHOsDqD/q6wCvmkT0fHHE336aapHoiH/qQ4cSPVIYqmoIFq92jpOW3LttURNm/o7xhFHEF16qfa8fn1z0albV3uPXsStxOicc8z34zYsT3/RkLgNIbS6yAwerIUR1qhhPo7du7kpxvLlzscxO27z5s4CLsdz3338/eopLCTq39/7sSU7dhBNn060a5f/faQziRTwBm7fX1kF/MMP+UyPHp3qkWj068dj8mO9BkFFBVtdMplj4MDoJJlWrYj69rXf/ocfiL74wt/xTzmFqGtXfvzqq3wuqlSJFZxQKHq7IUOI6tWz3m/37rH7yM93H1P9/fcco794MT/fv5/HVVzsvK1VrLdVcpCeVav4tddeczdOidlFw+lPCKLbb4/eT8uW/vMk9u7V9v3zz/72ke5YCbiaxEwC//0vL7PS5GyHwxzBAXBERiq6u2zfziFzo0ax7/mtt9h/DHCI4F9/Ad99Z739+PHsx5f1t70QDnOhqsmTOaLluuu4X+bo0ZpPXGL0AxcU8Nitusyb1UuXnZHc0KUL8NVXWmGrXbvYZ9ypEz/v14/DG82w8rGTIbrDbEJVVvO76y5vqfZ+KkgSxfqq/ZaTBaKPX9kmMeOVFALwjRBiphDCtGGYEGKQEGKGEGLGZrsKQgcxckIpWeVk7ZDRFjJ8LxV1o4HoScyffuIQPRm2JwsjWcWBA8CCBbw84ghvdT3k55eiunUrC9allwL9+0eXfj3//NiQRjlhaoyzlvs2q5XiNgIlHGYh++MPTv4Kh3ly7uOPWcQBnsBcssR8ey9hf0axlxd0Yylb/Xk1q6XiNx/AONZ4wgj1F8h0CiNMSoMNM7Pc7R+AZpFlQwBzAXSxe39ldaFcfDHf3lm1L0sm6dSCqnp1oqFD+a9qVW0Sq7TU3BcsGTeOt/XjY3b6/IsWaevKymK3/+ILnlD888/YMdm5EoSwH5eV/9qYlt6vn/V3ZVZLxWpy1rgPKx+2fJ/V+Oxq7phtU60aL3/7Lfr4hx3GZQj88Mwz2v4bNkx+qzmzOjJBt8FDomuhAHgAwFC791RWAZf1MX74IdUjsf6HdhKYRNCwIdF11xF16EB0xhna+jffjBUCPfFchJw+f3k597CUYjB/vrvPYjUmt2Oz2r52baIjj9Ted8stvM6KOnW0bZs25QlMN0LidF6sxpef765IFsAXaTn3sn599PFfeonoo4+cznIs8VzMg8DPhc0PgQs4gJoAauseTwVwrt02lVXAhw/nM50OYVLpZIEfcgg3JL7iCqIXX+R1biyXeC5Cbj7/V19p691GZdiFIboRFLvtjztOe9+DD/I6s0JgRCwcJ57I7/ngA17nptKgleDk59uPTwjeX4MG/LxJE/P933orn4cVK1iogwpnTPXv2enCHZShlAgBbx1xm8wFsABAsdM2lVXAS0qIli1LjzjwdOpwPnJkrFvJzT9kPP+0Tp+/tFSr1AhwXLqeHTuITjiB6O233Y27SpX4XDvZ2dEhhJ98QtSnj3W43PXXE73+OpeVHTOG6IkniO66yznayEnAnc75e+/x8wULzPf/+uv8+rJl5q+vX0+0ebP9GM1wczGPt1Sun+Nb/aWNBe7nr7IK+GefcdzxX3+leiRMIn/QXjEKpNt/yHguQnaff/v26P0a4+TLyng7Y43vt992F65nNybjZ5L7cxNCaLa/Fi14e6vYbz12QiR9unZlhdet4/kBqwvLr7/yNgMGcLy2kTZtiC65xPvndLqwJNpgsXMtxfN7MKIEPEWMG0dUqxaf6aZNUyuW6YQ++aNWLe28uLWuE3UR2rMn9rjGfefnx9au/uQTfn9Bgf8xDR5sLqSDBnnbjx/RKiy0FnC5bdeu2vi8itHOndr+zOL7jzmGqHdvb59TflY5MWr2WRPtYhk3ji+QxuOPHh39Xcb7G1UCngLSyV2RTtidl1Sfs7ffthYwiTGLk4hLEzRvHl9mq5XYNGmivWf2bO5e8+WXsduXlXHnpHr1vIuW2ec2bnvssURnncUTkXl50VE6f/7JF7E9e6yP8cgjZHlH0a4dUc+etqfHkiFDtHEWFAQ3X+KWMWM4Y1d/4V62jKhjRz7WmWfGfwwl4Ckg1RMs6Yqb295UuXjcfGennhodNVNayhOyDz4Y37Gd3BhEWp0Ys643f/9tL8J2olVR4bytzAiV/u6fftK2f+UVXrdunfn+x40jataM35OXF/udtm9PdNFF5ts5/Rb0UUvGSJZk/Q9WVLAf33gB79mT7y7ixUrA0yQ38OAkUc0QMh2n82LXiCLRmFUcBKLH3LkzcPTR2vOaNTn55l//iu/Ydok4Mqlm8mR+btb1RtYrt+rMbrd/p4bbWVmc5fj661yzvFYt/swSmXyVbVLfVCZPySzVkpLYJCGZyKNPfmnQALjmGv5OiKyTzuwSeczKIWdlxV8OWc+BA9yNqEkTLcmKiJcNGwKbNgV3rBjMVD1Rf8oCVxY4UfqeF7NEGKex7d/Plm9Qx7dLBnKKud6yhdf17evPDSXfa4yrNnMpvflm9LayUXRJSex+3Xzf4TDXR3FTV8X4XegTed59N/b4cmyA5l6aNs3hy3DJuHHs4pL7HzqUrfHCQu75WVzMk7/xRqBBuVCST6r9uelKup4Xu2JQVmOTMdBW4XFeGTfOWcCsBG3dOn4+cqQ/N9SCBUQbN0Zva1bgS39MGZ741FO8fufO2P269UO7jak2bjduHNHRR3PRuLVrY48vXT4zZvD48vKIzj8/ens/Ljuz33HVqtq5ePVVLrQVRPiwEvAUkU4he+lEOp4Xp5rgknHjOKJo61b2hx96aLAx/n6TQ0pKiG68Mdo37YXSUp6M3LdPW2cnvh07Eo0axe97/HFebzaJ6cYCf/ZZ7xcsIne/o927ucqjTH6Sk6kzZsRnTNiFEAJEv//uvA+3KAFXKBzwEsIIaGWCn3wy2HEkKz3bSI8evD99nLbVOSks5BKwF17I71u9mktFmF3InERy3DiirCx34m3czrhfY8y7mcBv307Uti3HrSeiLAPAJQ3Ky/nObODA+MVcCbhC4YBba+zrr/m19u05Btmp8YTfsbgpkKQXrPJytp791niX+9TXf7E7JzfeyI/dzAHYWcp2dxw5OdqFKyfH3XZuknjkOYonzNDqgpqVxXXhiYjmzOF1sqyBX5SAKxQucHNLLm/BAaKaNZPr/tGPD4juYiPFwk9RKCLtMxnrv1idky++4Pf/739Es2b5Pw9uwid799aEtaiIXTdW2zgV4JICv28fFyzza4FbCbgxQxUgevllf+dGogRcoQgAq8y7ZPvwKyq4q1DLllrs8fTpPJ7//tffPuXnMZsINGPPHj4XQ4YQ3X03T+D5wakOi1m2pd2fFF8n6/qJJ5wFWB7f7ALmxnrfv5/XxZsjYCXgKg5cofBAcXFshx23DRuCRAjunrNiBfD++7xOxoHn5MS37xo13L/vnnuAU0/lOHCzGPAgKC4G9u2LXV+3bmyMd5Uq3NHJrkGEjIe3ipeX32c4rMWwm8WiW8XVE2kx+jk5fJyExYKbqXqi/pQFrsh00qmeuqxd3rYtW+TffcdjmTzZ3/7kZ7EqVWvHrbfyxF08x7U6p06lbPUuJauwRzPr2inax0/DCrNjtWvHVSLjAcoCVyjix8rq8tLOLCiysoA77wTq1AFefRX4xz94/eWX+2vftWYNZ0l6teDXr+ceo34scNlGzgx5Tu3Oucza3bsXaNTIvCdmlSp8jKIi7sEqM3udMqL37OGWe2asWsX7eeQRzhi12r64GJg7Fxg50v5YflECrlB4wCw1Ozc32NRsL/TrBwweDNxxh3abvnGjvz6nFRVaY2kvnHMO8P33/lw3xcXmrg4htHPq5pxXrWrtpqioMC/LEM9Ft2lTXlavzv1RrS5CCS+bYWaWJ+pPuVAUBwPploQUVGkCGYvtlQsu0FwaXs+Hl+Qpu3P+5pvWseRW58HJBWL3d9ppvH39+vaum6IiHtsVV7g/J2ZARaEoFAcnQfnlzYTTCad63E4EcfExiwxyO5bBg72L95NPchijk/jLYxcXs8DHk62rBFyhOEhxCsNzix8Bj1eAg6iLE087O69lC+Tnsjum8S7hyiu1C6rfOzYrAU9Q4I9CoagMxFsyWfqki4t5m8JC9m17KSFsdayKCuf92I0zN5cnIvXPpd/d7pj6krbhsBbmSaSFIQLBlElWk5gKRYZTUuJtvRn6CU9jnXE7gojKibf+ezxjyMszXy8jVoqKzCNY3B6zuFiLz5cEmTegBFyhyHDiFVGZrCKxapxgRjpE5fgdQzgM7NwZu75qVe0uwOrC4vaYCW/qYuZXcfsH4FwASwAsA3C30/uVD1yhCJ54/chB+LFTHZXjZwx25WCDOmZQEUKw8IELfs07QogqAP4A0B3AGgDTAVxORAuttunYsSPNmDHD1/EUCoU14bB/P7JV2rkQsS3KDiaS8bnl3Y3Rl653x7hBCDGTiDoa18fjQukEYBkR/UlE+wG8C+DiOPanUCh8Eo8fOZ2yS5NJMj53KGTvS4+XeAS8GYDVuudrIuuiEEIMEkLMEELM2Lx5cxyHUygUiSAd/NipIFmfO5FNuhM+iUlEo4ioIxF1LCgoSPThFAqFRxJtJaYrB8PnjicOfC2AFrrnzSPrFApFhhEKZZZwBUWmf+54LPDpAA4TQrQSQlQFcBmAz4MZlkKhUCic8G2BE1GZEGIIgK8BVAEwhogWBDYyhUKhUNgSVyo9EX0J4MuAxqJQKBQKD6hMTIVCochQlIArFApFhuI7E9PXwYTYDGClz80bANgS4HCCJF3Hlq7jAtTY/KLG5o90HZvbcRURUUwcdlIFPB6EEDPMUknTgXQdW7qOC1Bj84samz/SdWzxjku5UBQKhSJDUQKuUCgUGUomCfioVA/AhnQdW7qOC1Bj84samz/SdWxxjStjfOAKhUKhiCaTLHCFQqFQ6FACrlAoFBlK2gu4EOJcIcQSIcQyIcTdKTj+GCHEJiHEfN26PCHERCHE0siyfmS9EEK8EBnrPCHEcQkeWwshxBQhxEIhxAIhxC3pMj4hRHUhxG9CiLmRsT0YWd9KCDEtMob3IoXQIISoFnm+LPJ6y0SNLXK8KkKI2UKICWk2rhVCiN+FEHOEEDMi61L+fUaOV08I8aEQYrEQYpEQ4uR0GJsQ4ojI+ZJ/O4UQt6bD2CLHuy3yPzBfCPFO5H8jmN+bWZ+1dPkDF8laDqA1gKoA5gJok+QxdAFwHID5unXDEekBCuBuAE9EHp8H4H8ABICTAExL8NiaADgu8rg2uMVdm3QYX+QYtSKPcwBMixzzfQCXRda/AmBw5PENAF6JPL4MwHsJPne3AxgPYELkebqMawWABoZ1Kf8+I8d7C8CAyOOqAOqly9h0Y6wCYAOAonQYG7jJzV8Aauh+Z1cF9XtL+AmN88OfDOBr3fN7ANyTgnG0RLSALwHQJPK4CYAlkcevgvuCxrwvSeP8DNyjNK3GByAXwCwAJ4KzzrKN3y+4quXJkcfZkfeJBI2nOYBvAXQFMCHyj5zycUWOsQKxAp7y7xNA3YgQiXQbm2E8ZwP4OV3GBq1zWV7k9zMBwDlB/d7S3YXiqm1bCmhEROsjjzcAaBR5nLLxRm61jgVbumkxvoibYg6ATQAmgu+mthNRmcnx/39skdd3AMhP0NCeA3AnANm6Nj9NxgUABOAbIcRMIcSgyLp0+D5bAdgM4I2I6+l1IUTNNBmbnssAvBN5nPKxEdFaAE8BWAVgPfj3MxMB/d7SXcDTHuJLZUpjMYUQtQB8BOBWItqpfy2V4yOiciLqALZ4OwE4MhXj0COEuADAJiKameqxWHAqER0HoAeAG4UQXfQvpvD7zAa7EkcS0bEAdoPdEukwNgBAxI98EYAPjK+lamwRv/vF4AtgUwA1AZwb1P7TXcDTtW3bRiFEEwCILDdF1id9vEKIHLB4h4no43QbHwAQ0XYAU8C3ivWEELIOvf74/z+2yOt1AWxNwHA6A7hICLECwLtgN8rzaTAuAP9vsYGINgH4BHzhS4fvcw2ANUQ0LfL8Q7Cgp8PYJD0AzCKijZHn6TC2swD8RUSbiegAgI/Bv8FAfm/pLuDp2rbtcwD9I4/7g33Pcn2/yCz3SQB26G7hAkcIIQCMBrCIiJ5Jp/EJIQqEEPUij2uAffOLwELex2Jscsx9AEyOWE2BQkT3EFFzImoJ/j1NJqJQqscFAEKImkKI2vIx2J87H2nwfRLRBgCrhRBHRFZ1A7AwHcam43Jo7hM5hlSPbRWAk4QQuZH/V3negvm9JXpSIYBJgPPA0RXLARSn4PjvgH1XB8BWyLVgn9S3AJYCmAQgL/JeAeClyFh/B9AxwWM7FXxbOA/AnMjfeekwPgDtAMyOjG0+gPsi61sD+A3AMvCtbrXI+uqR58sir7dOwnd7BrQolJSPKzKGuZG/BfL3ng7fZ+R4HQDMiHynnwKon0Zjqwm2VOvq1qXL2B4EsDjyfzAWQLWgfm8qlV6hUCgylHR3oSgUCoXCAiXgCoVCkaEoAVcoFIoMRQm4QqFQZChKwBUKhSJDUQKuUCgUGYoScIVCochQ/g9yLxDGpYk0PgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(CTRmodel.steps, CTRmodel.losses, 'bo--')  # 每个step的单个loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fa437a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4db8127cd0>]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(CTRmodel.steps, CTRmodel.avg_losses, 'bo--') # 每个step,对应的epoch截止到该step时的平均loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "65cc66ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4db8099bb0>]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(CTRmodel.steps, CTRmodel.nstep_avg_losses, 'bo--') # 每个step,对应的epoch截止到该step时的平均loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc643e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
