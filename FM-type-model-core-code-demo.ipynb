{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5dd31b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from importlib import reload\n",
    "from torch.utils.data import DataLoader,Dataset,RandomSampler\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import argparse\n",
    "import random\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "from transformers import (AdamW, get_linear_schedule_with_warmup)\n",
    "from torchkeras import summary\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08987513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup file handler\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "           #logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fhandler  = logging.FileHandler('my.log')\n",
    "fhandler.setLevel(logging.DEBUG)\n",
    "fhandler.setFormatter(formatter)\n",
    " \n",
    "# Configure stream handler for the cells\n",
    "chandler = logging.StreamHandler()\n",
    "chandler.setLevel(logging.DEBUG)\n",
    "chandler.setFormatter(formatter)\n",
    " \n",
    "# Add both handlers\n",
    "logger.addHandler(fhandler)\n",
    "logger.addHandler(chandler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e2da3",
   "metadata": {},
   "source": [
    "数据处理\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee50b9",
   "metadata": {},
   "source": [
    "1 得到原始数据和离散，连续列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c58c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/media/xuweijia/DATA/代码/python_test/data/Criteo/demo_data/'\n",
    "file_name='train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f64db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>e88ffc9d</td>\n",
       "      <td>c393dc22</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>57c90cd9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>4d19a3eb</td>\n",
       "      <td>cb079c2d</td>\n",
       "      <td>456c12a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>92555263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242bb710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>72c78f11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>25c88e42</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>a0136dd2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>f37f3967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>c3abeb21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>642f2610</td>\n",
       "      <td>1d1eb838</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>1640d50b</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>45ab94c8</td>\n",
       "      <td>2bf691b1</td>\n",
       "      <td>c84c4aec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>fc35e8fe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a02708ad</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c3dc6cef</td>\n",
       "      <td>502f2493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>eea796be</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>2b0a9d11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7453e535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dbb486d7</td>\n",
       "      <td>906e72ec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>817481a8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e4244d7f</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c7dc6720</td>\n",
       "      <td>60efe6e6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2005abd1</td>\n",
       "      <td>1cdbd1c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>288eaded</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label   I1   I2    I3    I4      I5     I6     I7    I8     I9  ...  \\\n",
       "0         1  1.0    0   1.0   NaN   227.0    1.0  173.0  18.0   50.0  ...   \n",
       "1         1  4.0    1   1.0   2.0    27.0    2.0    4.0   2.0    2.0  ...   \n",
       "2         1  0.0  806   NaN   NaN  1752.0  142.0    2.0   0.0   50.0  ...   \n",
       "3         0  2.0   -1  42.0  14.0   302.0   38.0   25.0  38.0   90.0  ...   \n",
       "4         1  0.0   57   2.0   1.0  2891.0    2.0   35.0   1.0  137.0  ...   \n",
       "...     ...  ...  ...   ...   ...     ...    ...    ...   ...    ...  ...   \n",
       "1594      0  NaN    8   1.0   1.0    43.0    NaN    0.0   1.0    1.0  ...   \n",
       "1595      0  8.0    2  20.0   8.0    36.0    9.0    8.0  10.0    8.0  ...   \n",
       "1596      0  0.0    1   2.0  12.0  4877.0  140.0   13.0  34.0  136.0  ...   \n",
       "1597      0  NaN    2   NaN   1.0  1972.0    NaN    0.0   1.0   14.0  ...   \n",
       "1598      1  NaN   34   3.0   4.0     NaN    NaN    0.0   4.0   14.0  ...   \n",
       "\n",
       "           C17       C18       C19       C20       C21       C22       C23  \\\n",
       "0     3486227d  e88ffc9d  c393dc22  b1252a9d  57c90cd9       NaN  bcdee96c   \n",
       "1     07c540c4  92555263       NaN       NaN  242bb710       NaN  3a171ecb   \n",
       "2     07c540c4  25c88e42  21ddcdc9  b1252a9d  a0136dd2       NaN  32c7478e   \n",
       "3     e5ba7672  5aed7436  21ddcdc9  b1252a9d  c3abeb21       NaN  423fab69   \n",
       "4     e5ba7672  642f2610  1d1eb838  b1252a9d  1640d50b  ad3062eb  423fab69   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1594  1e88c74f  fc35e8fe       NaN       NaN  a02708ad  c9d4222a  c3dc6cef   \n",
       "1595  e5ba7672  5aed7436  21ddcdc9  b1252a9d  eea796be       NaN  3a171ecb   \n",
       "1596  e5ba7672  2b0a9d11       NaN       NaN  7453e535       NaN  dbb486d7   \n",
       "1597  e5ba7672  817481a8       NaN       NaN  e4244d7f  c9d4222a  c7dc6720   \n",
       "1598  2005abd1  1cdbd1c5       NaN       NaN  288eaded  c9d4222a  bcdee96c   \n",
       "\n",
       "           C24       C25       C26  \n",
       "0     4d19a3eb  cb079c2d  456c12a0  \n",
       "1     72c78f11       NaN       NaN  \n",
       "2     8fc66e78  001f3601  f37f3967  \n",
       "3     1793a828  e8b83407  5cef228f  \n",
       "4     45ab94c8  2bf691b1  c84c4aec  \n",
       "...        ...       ...       ...  \n",
       "1594  502f2493       NaN       NaN  \n",
       "1595  1793a828  e8b83407  5cef228f  \n",
       "1596  906e72ec       NaN       NaN  \n",
       "1597  60efe6e6       NaN       NaN  \n",
       "1598  8fc66e78       NaN       NaN  \n",
       "\n",
       "[1599 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get raw data\n",
    "raw_df=pd.read_csv(os.path.join(data_path+file_name))\n",
    "raw_df=raw_df.drop([\"Id\"],axis=1)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b5d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别找出连续列/离散列\n",
    "def col_type(df):\n",
    "    dis_col=[]\n",
    "    con_col=[]\n",
    "    columns=df.columns.tolist()\n",
    "    for c in columns:\n",
    "        if df[c].dtype=='int64' or df[c].dtype=='float':\n",
    "            con_col.append(c)\n",
    "        else:\n",
    "            dis_col.append(c)\n",
    "    return dis_col,con_col\n",
    "dis_col,con_col=col_type(raw_df)\n",
    "con_col.remove(\"Label\")\n",
    "label=\"Label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59912c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[con_col].values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68807a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认是float64(double). 降低到float32. 与torch默认的兼容\n",
    "raw_df[con_col]=raw_df[con_col].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f207e533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[con_col].values.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d7b1e",
   "metadata": {},
   "source": [
    "2 填充缺失值：数值型填0； 类别填空字符串，到时候也编码进去 （测试数据的缺失值用同样字符填充。相同编码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737e366a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3486227d</td>\n",
       "      <td>e88ffc9d</td>\n",
       "      <td>c393dc22</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>57c90cd9</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>4d19a3eb</td>\n",
       "      <td>cb079c2d</td>\n",
       "      <td>456c12a0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>92555263</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>242bb710</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>72c78f11</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>25c88e42</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>a0136dd2</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>001f3601</td>\n",
       "      <td>f37f3967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>c3abeb21</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>642f2610</td>\n",
       "      <td>1d1eb838</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>1640d50b</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>45ab94c8</td>\n",
       "      <td>2bf691b1</td>\n",
       "      <td>c84c4aec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>fc35e8fe</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>a02708ad</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c3dc6cef</td>\n",
       "      <td>502f2493</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>5aed7436</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>eea796be</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>5cef228f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>2b0a9d11</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>7453e535</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>dbb486d7</td>\n",
       "      <td>906e72ec</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>817481a8</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>e4244d7f</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>c7dc6720</td>\n",
       "      <td>60efe6e6</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2005abd1</td>\n",
       "      <td>1cdbd1c5</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>288eaded</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>8fc66e78</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "      <td>&lt;NULL&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label   I1     I2    I3    I4      I5     I6     I7    I8     I9  ...  \\\n",
       "0         1  1.0    0.0   1.0   0.0   227.0    1.0  173.0  18.0   50.0  ...   \n",
       "1         1  4.0    1.0   1.0   2.0    27.0    2.0    4.0   2.0    2.0  ...   \n",
       "2         1  0.0  806.0   0.0   0.0  1752.0  142.0    2.0   0.0   50.0  ...   \n",
       "3         0  2.0   -1.0  42.0  14.0   302.0   38.0   25.0  38.0   90.0  ...   \n",
       "4         1  0.0   57.0   2.0   1.0  2891.0    2.0   35.0   1.0  137.0  ...   \n",
       "...     ...  ...    ...   ...   ...     ...    ...    ...   ...    ...  ...   \n",
       "1594      0  0.0    8.0   1.0   1.0    43.0    0.0    0.0   1.0    1.0  ...   \n",
       "1595      0  8.0    2.0  20.0   8.0    36.0    9.0    8.0  10.0    8.0  ...   \n",
       "1596      0  0.0    1.0   2.0  12.0  4877.0  140.0   13.0  34.0  136.0  ...   \n",
       "1597      0  0.0    2.0   0.0   1.0  1972.0    0.0    0.0   1.0   14.0  ...   \n",
       "1598      1  0.0   34.0   3.0   4.0     0.0    0.0    0.0   4.0   14.0  ...   \n",
       "\n",
       "           C17       C18       C19       C20       C21       C22       C23  \\\n",
       "0     3486227d  e88ffc9d  c393dc22  b1252a9d  57c90cd9    <NULL>  bcdee96c   \n",
       "1     07c540c4  92555263    <NULL>    <NULL>  242bb710    <NULL>  3a171ecb   \n",
       "2     07c540c4  25c88e42  21ddcdc9  b1252a9d  a0136dd2    <NULL>  32c7478e   \n",
       "3     e5ba7672  5aed7436  21ddcdc9  b1252a9d  c3abeb21    <NULL>  423fab69   \n",
       "4     e5ba7672  642f2610  1d1eb838  b1252a9d  1640d50b  ad3062eb  423fab69   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1594  1e88c74f  fc35e8fe    <NULL>    <NULL>  a02708ad  c9d4222a  c3dc6cef   \n",
       "1595  e5ba7672  5aed7436  21ddcdc9  b1252a9d  eea796be    <NULL>  3a171ecb   \n",
       "1596  e5ba7672  2b0a9d11    <NULL>    <NULL>  7453e535    <NULL>  dbb486d7   \n",
       "1597  e5ba7672  817481a8    <NULL>    <NULL>  e4244d7f  c9d4222a  c7dc6720   \n",
       "1598  2005abd1  1cdbd1c5    <NULL>    <NULL>  288eaded  c9d4222a  bcdee96c   \n",
       "\n",
       "           C24       C25       C26  \n",
       "0     4d19a3eb  cb079c2d  456c12a0  \n",
       "1     72c78f11    <NULL>    <NULL>  \n",
       "2     8fc66e78  001f3601  f37f3967  \n",
       "3     1793a828  e8b83407  5cef228f  \n",
       "4     45ab94c8  2bf691b1  c84c4aec  \n",
       "...        ...       ...       ...  \n",
       "1594  502f2493    <NULL>    <NULL>  \n",
       "1595  1793a828  e8b83407  5cef228f  \n",
       "1596  906e72ec    <NULL>    <NULL>  \n",
       "1597  60efe6e6    <NULL>    <NULL>  \n",
       "1598  8fc66e78    <NULL>    <NULL>  \n",
       "\n",
       "[1599 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_token = '<NULL>'\n",
    "raw_df[dis_col]=raw_df[dis_col].fillna(null_token)\n",
    "raw_df[con_col]=raw_df[con_col].fillna(0)\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1131d",
   "metadata": {},
   "source": [
    "3 可以做一些特征处理上的优化。比如数值型归一化。离散特征出现次数小于某阈值的，值都编码成\\<UNK\\>。这里忽略，假设已经做过了.也做过了特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f1832",
   "metadata": {},
   "source": [
    "4 离散特征label-encode. 保存原始值到label的映射。之后根据映射后的id找对应embedding （取值10个以内的one-hot,作为新特征）\n",
    "  如果想同一列加工出不同特征。可以用FeatureUnion和自定义transformer来选择列。 （如对文本列同时加工长度和tfidf两个特征）\n",
    "  ColumnTransformer对同一列只能做一个操作。如果不对同一列做不同操作，就用这个就可以。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b53bf00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load FM_helper/LabelEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b2430f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>C10</th>\n",
       "      <th>...</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>I11</th>\n",
       "      <th>I12</th>\n",
       "      <th>I13</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>...</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>30.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>727.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        C1     C2      C3     C4    C5   C6     C7    C8   C9    C10  ...  \\\n",
       "0     33.0   27.0   486.0  572.0   1.0  1.0  459.0   1.0  1.0  465.0  ...   \n",
       "1      0.0   98.0   170.0  287.0   1.0  3.0  550.0  21.0  1.0  683.0  ...   \n",
       "2      0.0   28.0   114.0  696.0  11.0  3.0  704.0   1.0  1.0  133.0  ...   \n",
       "3      0.0   12.0   650.0  243.0   1.0  3.0  329.0   1.0  1.0   27.0  ...   \n",
       "4      0.0   36.0   517.0   70.0   1.0  3.0   20.0   2.0  1.0  166.0  ...   \n",
       "...    ...    ...     ...    ...   ...  ...    ...   ...  ...    ...  ...   \n",
       "1594   0.0   93.0   617.0  801.0   1.0  1.0   25.0  12.0  1.0   28.0  ...   \n",
       "1595  30.0   12.0  1034.0  243.0   1.0  6.0  935.0   1.0  1.0  454.0  ...   \n",
       "1596  30.0  113.0   676.0    7.0   1.0  6.0  185.0  14.0  1.0  485.0  ...   \n",
       "1597   0.0   48.0   565.0  727.0   1.0  6.0  377.0   0.0  1.0  202.0  ...   \n",
       "1598   0.0  155.0   286.0  768.0   1.0  6.0  590.0   1.0  0.0  166.0  ...   \n",
       "\n",
       "          I5     I6     I7    I8     I9  I10   I11  I12   I13  Label  \n",
       "0      227.0    1.0  173.0  18.0   50.0  1.0   7.0  1.0   0.0    1.0  \n",
       "1       27.0    2.0    4.0   2.0    2.0  1.0   1.0  0.0   2.0    1.0  \n",
       "2     1752.0  142.0    2.0   0.0   50.0  0.0   1.0  0.0   0.0    1.0  \n",
       "3      302.0   38.0   25.0  38.0   90.0  1.0   3.0  0.0  38.0    0.0  \n",
       "4     2891.0    2.0   35.0   1.0  137.0  0.0  17.0  0.0   1.0    1.0  \n",
       "...      ...    ...    ...   ...    ...  ...   ...  ...   ...    ...  \n",
       "1594    43.0    0.0    0.0   1.0    1.0  0.0   0.0  0.0   1.0    0.0  \n",
       "1595    36.0    9.0    8.0  10.0    8.0  1.0   1.0  0.0   8.0    0.0  \n",
       "1596  4877.0  140.0   13.0  34.0  136.0  0.0   2.0  0.0  12.0    0.0  \n",
       "1597  1972.0    0.0    0.0   1.0   14.0  0.0   0.0  0.0   1.0    0.0  \n",
       "1598     0.0    0.0    0.0   4.0   14.0  0.0   0.0  0.0   4.0    1.0  \n",
       "\n",
       "[1599 rows x 40 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接当做包，引用py中函数\n",
    "# labelencoding。\n",
    "from FM_helper import LabelEncoder\n",
    "reload(LabelEncoder)\n",
    "trans,new_con_col,new_dis_col,df,raw_df2,cate_counts,cate_feature_map=LabelEncoder.labelencode_trans(raw_df,dis_col,con_col,label)\n",
    "# 测试.只需要保存大transformer和最终的dis_col,con_col。 用来做转化，以及识别转换后的两类特征。 \n",
    "LabelEncoder.test(raw_df,trans,new_con_col,new_dis_col,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a1e46",
   "metadata": {},
   "source": [
    "标准FM\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd23e3",
   "metadata": {},
   "source": [
    "公式："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395db68",
   "metadata": {},
   "source": [
    "$$y= b+ \\sum_{i}w_ix_i  + \\sum_{i}^{n}\\sum_{j!=i}^{n}x_ix_j<\\vec{v_i},\\vec{v_j}>$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899f7a5",
   "metadata": {},
   "source": [
    "一阶同LR. 每个连续特征对应一个$w_i$,每个离散特征one-hot之后的特征作为新特征，对应一个$w_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0fd6b1",
   "metadata": {},
   "source": [
    "二阶交互，每个连续特征对应一个embedding。每个离散特征的每个每个特征的每个取值对应一个embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997451f0",
   "metadata": {},
   "source": [
    "因此每个连续特征$x_i$,对应一个$w_i$,一个embedding，用来和其他特征交互。\n",
    "   每个离散特征域，对应one-hot之后的C个特征$x_i$，对应C个$w_i$,C个embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818520f1",
   "metadata": {},
   "source": [
    "但对每个样本来说，该离散特征one-hot之后，只会根据取值取到一个embedding，一个$w_i$<br/>(该离散特征对一阶的贡献，只有根据样本该离散特征取值映射到的$w_i$，对应取值$x_i$是1,其他C-1位置由于one-hot,该样本下取值$x_i$都是0,贡献是0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a62e344",
   "metadata": {},
   "source": [
    "因此总共需要维护（所有连续特征+所有离散特征的所有取值)个特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82c11d",
   "metadata": {},
   "source": [
    "假设所有连续特征和one-hot后的所有离散特征共F个,总共需要维护F个特征。可以根据特征名称，把每个特征映射到一个固定id上（位置）:<br/>\n",
    "每个连续特征对应一个id                            <br/>\n",
    "每个离散特征的每个取值对应一个id                    <br/>\n",
    "每个id都维护一个$w_i$,一个embedding，对应该特征在W（F,1）,embedding(F,d)中的位置。<br/>\n",
    "之后每个样本，都可以根据特征位置去找对应的$w_i$,embedding：       <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca8dd50",
   "metadata": {},
   "source": [
    "因此在对每个样本进行映射时，需要分别得到样本每个特征的位置（id）和取值$x_i$："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d5c8dd",
   "metadata": {},
   "source": [
    "位置映射：样本的所有特征都被映射到对应位置,用来找对应的$w_i$,embedding。每个连续特征对应的就是位置id。每个离散域，根据样本在该域的取值映射到对应id。n个离散域，对应n个embedding,n个$w_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012662c",
   "metadata": {},
   "source": [
    "样本取值：连续特征的取值不变（或者归一化），离散特征取值1，作为样本的$x_i$输入。n个离散域，对应的n个取值，$x_i$都是1。在one-hot后的对应位置上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2400cb9",
   "metadata": {},
   "source": [
    "### 对原始特征进行映射。得到one-hot之后的所有特征（含连续特征）到位置id的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde59bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "class FeaturePosTrans(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, dis_col=None, con_col= None, limit_freq = 0):\n",
    "        self.dis_col=dis_col\n",
    "        self.con_col=con_col\n",
    "        self.limit_freq=limit_freq\n",
    "        \n",
    "        self.NULL = '<NULL>'\n",
    "        self.UNK = '<UNK>'                                                # nlp里。低频是1，NAN是0. NAN作为padding,不参与训练且是0\n",
    "                                                                          # NAN对应embedding： padding_index=0.只占位，不训练）\n",
    "                                                                          # nn.Embedding(V,d,padding_idx=0\n",
    "    \n",
    "        self.dis_col_map=dict()                                            # 按特征，记录取值到位置id的映射  只用来存着\n",
    "        self.feature_id_map=dict()                                         # 特征名到位置id的映射大表 {特征名_取值：位置id}\n",
    "        self.pos=0                                                         # 位置id\n",
    "        self.dis_col_count=dict()                                          # 每个离散特征的取值数目\n",
    "        \n",
    "        \n",
    "        # 所有离散的缺失值，统一用NAN编码，之后在w，E中padding成0\n",
    "        self.feature_id_map[self.NULL]=0\n",
    "        self.pos+=1\n",
    "        \n",
    "        if (con_col!=None):\n",
    "            self.feature_id_map.update(dict(zip(con_col,range(self.pos,self.pos+len(con_col))))) # 连续特征到对应位置的映射\n",
    "            self.pos+=len(self.con_col)\n",
    "\n",
    "    def fit(self, X , y = None):\n",
    "        \n",
    "        if (self.dis_col!=None):\n",
    "            # 每个离散特征取值,映射到对应id\n",
    "            for col in self.dis_col:\n",
    "                valueCount=dict(X[col].value_counts())                       # 该离散特征。每个取值的出现数目\n",
    "                # 是否特殊处理低频取值\n",
    "                if self.limit_freq>0:\n",
    "                    values=[k for k,v in valueCount.items() if k!=self.NULL and v>self.limit_freq]  # 该特征留下的取值\n",
    "                    self.dis_col_map[col]=dict(zip(values,range(self.pos+1,self.pos+1+len(values))))\n",
    "                    self.dis_col_map[col][self.UNK]=self.pos\n",
    "                    # 组织大表。类似\n",
    "                    new_values=[col+\"_\"+v for v in values]                    # { C1_v1：id}  \n",
    "                    self.feature_id_map.update(dict(zip(new_values,range(self.pos+1,self.pos+1+len(new_values)))))\n",
    "                    self.feature_id_map[col+\"_\"+self.UNK]=self.pos\n",
    "                    self.pos+=len(new_values)+1                              # 每个特征留下：所有高频取值+UNK                                   \n",
    "                else:\n",
    "                    # 每个特征。分别记录映射\n",
    "                    values=[k for k in valueCount.keys() if k!=self.NULL]    # 该离散特征所有取值（除缺失值） \n",
    "                    self.dis_col_map[col]=dict(zip(values,range(self.pos,self.pos+len(values))))\n",
    "                    # 类似，但根据取值记在大map里\n",
    "                    new_values=[col+\"_\"+v for v in values]                   # { C1_v1：id}  \n",
    "                    self.feature_id_map.update(dict(zip(new_values,range(self.pos,self.pos+len(new_values)))))\n",
    "                    self.pos+=len(new_values)\n",
    "                    \n",
    "                 # 每个离散特征的有效取值数目(不含NAN，含每个特征的unk)\n",
    "                self.dis_col_count[col]=len(self.dis_col_map[col])                            \n",
    "                                                                               \n",
    "    def transform(self, X, label=None):        \n",
    "        # 映射：\n",
    "        feature_pos=X.copy()                        # 样本每个特征对应的位置\n",
    "        feature_values=X.copy()                     # 样本每个特征的取值。离散特征取值是1.  \n",
    "        cols=self.dis_col+self.con_col    \n",
    "        \n",
    "        # 如果有target列，删掉target列\n",
    "        if label in feature_pos.columns:\n",
    "            feature_pos=feature_pos.drop([label], axis=1)\n",
    "            feature_values=feature_values.drop([label], axis=1)    # 特征列去掉label\n",
    "        \n",
    "        for col in cols:\n",
    "            if col in self.dis_col:\n",
    "                #values=X[col].apply(self.gen,args=(col,)).values\n",
    "                values=X[col].apply(self.gen2,args=(col,)).values    # 组织形式不同。映射效果相同。用这个好些\n",
    "                feature_pos[col]=values\n",
    "                feature_values[col]=1.0\n",
    "            else:\n",
    "                feature_pos[col]=self.feature_id_map[col]            # 连续特征取值不变  。 位置是映射后的id \n",
    "        \n",
    "        # 映射完的取值（包括离散特征取值1.0），也都变成float32\n",
    "        feature_values=feature_values.astype(np.float32)\n",
    "        \n",
    "        return feature_pos,feature_values\n",
    "        \n",
    "    # 如果是多列。传入的x是该列对应的series. 输出的是这些列拼起来的df\n",
    "    # 如果是单列，传入的x是该列的每个元素    输出的是该列对应的Series\n",
    "    # 根据离散特征取值，返回对应的位置id\n",
    "    def gen(self,x,col):\n",
    "        if x==self.NULL:                                        # NAN统一映射到0\n",
    "            return 0\n",
    "        else:\n",
    "            if x in self.dis_col_map[col]:\n",
    "                return self.dis_col_map[col][x]                 # 按取值，映射到对应位置id\n",
    "            else:\n",
    "                if self.limit_freq>0:\n",
    "                    return self.dis_col_map[col][self.UNK]       # 低频取值/没见过的值。映射到unqkey对应的编码 \n",
    "                else:\n",
    "                    return 0                                     # 没见过的值。映射到NAN==0。没有贡献\n",
    "\n",
    "    # 用大表做映射。类似\n",
    "    def gen2(self,x,col):    \n",
    "        if x==self.NULL:                                         # NAN统一映射到0\n",
    "            return 0\n",
    "        else:\n",
    "            x=col+\"_\"+x\n",
    "            if x in self.feature_id_map:                         # 其他按取值，映射到对应位置id\n",
    "                return self.feature_id_map[x]                 \n",
    "            else:\n",
    "                if self.limit_freq>0:                \n",
    "                    return self.feature_id_map[col+\"_\"+self.UNK] # 低频取值/没见过的值。映射到该特征unqkey对应的编码 \n",
    "                else:\n",
    "                    return 0                                     # 没见过的值。映射到NAN。没有贡献\n",
    "                \n",
    "    def id2name(self):\n",
    "        return dict(zip(self.feature_id_map.values(),self.feature_id_map.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e496e9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10',\n",
       "       'I11', 'I12', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8',\n",
       "       'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18',\n",
       "       'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80f89ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from FM_helper import Fmdata\n",
    "#reload(Fmdata)\n",
    "#f_trans=Fmdata.FeaturePosTrans(dis_col,con_col,10)\n",
    "f_trans=FeaturePosTrans(dis_col,con_col,10)             # 出现10次以下的作为UNK\n",
    "f_trans.fit(raw_df)\n",
    "feature_pos,feature_values=f_trans.transform(raw_df,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4622628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_trans.feature_id_map)  # 离散特征one-hot后，总的特征数目. NAN+con_col+all_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9310c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<NULL>': 0,\n",
       " 'I1': 1,\n",
       " 'I2': 2,\n",
       " 'I3': 3,\n",
       " 'I4': 4,\n",
       " 'I5': 5,\n",
       " 'I6': 6,\n",
       " 'I7': 7,\n",
       " 'I8': 8,\n",
       " 'I9': 9,\n",
       " 'I10': 10,\n",
       " 'I11': 11,\n",
       " 'I12': 12,\n",
       " 'I13': 13,\n",
       " 'C1_05db9164': 15,\n",
       " 'C1_68fd1e64': 16,\n",
       " 'C1_5a9ed9b0': 17,\n",
       " 'C1_8cf07265': 18,\n",
       " 'C1_be589b51': 19,\n",
       " 'C1_5bfa8ab5': 20,\n",
       " 'C1_f473b8dc': 21,\n",
       " 'C1_87552397': 22,\n",
       " 'C1_ae82ea21': 23,\n",
       " 'C1_39af2607': 24,\n",
       " 'C1_9a89b36c': 25,\n",
       " 'C1_<UNK>': 14,\n",
       " 'C2_38a947a1': 27,\n",
       " 'C2_09e68b86': 28,\n",
       " 'C2_80e26c9b': 29,\n",
       " 'C2_d833535f': 30,\n",
       " 'C2_4f25e98b': 31,\n",
       " 'C2_287130e0': 32,\n",
       " 'C2_0a519c5c': 33,\n",
       " 'C2_08d6d899': 34,\n",
       " 'C2_4c2bc594': 35,\n",
       " 'C2_38d50e09': 36,\n",
       " 'C2_207b2d81': 37,\n",
       " 'C2_58e67aaf': 38,\n",
       " 'C2_2c16a946': 39,\n",
       " 'C2_942f9a8d': 40,\n",
       " 'C2_8947f767': 41,\n",
       " 'C2_421b43cd': 42,\n",
       " 'C2_0468d672': 43,\n",
       " 'C2_8084ee93': 44,\n",
       " 'C2_78ccd99e': 45,\n",
       " 'C2_1cfdf714': 46,\n",
       " 'C2_68b3edbf': 47,\n",
       " 'C2_e112a9de': 48,\n",
       " 'C2_95e2d337': 49,\n",
       " 'C2_e5fb1af3': 50,\n",
       " 'C2_39dfaa0d': 51,\n",
       " 'C2_e77e5e6e': 52,\n",
       " 'C2_9819deea': 53,\n",
       " 'C2_8cc9c66e': 54,\n",
       " 'C2_f0cf0024': 55,\n",
       " 'C2_3df44d94': 56,\n",
       " 'C2_ae46a29d': 57,\n",
       " 'C2_26a88120': 58,\n",
       " 'C2_<UNK>': 26,\n",
       " 'C3_d032c263': 60,\n",
       " 'C3_b00d1501': 61,\n",
       " 'C3_77f2f2e5': 62,\n",
       " 'C3_aa8c1539': 63,\n",
       " 'C3_02cf9876': 64,\n",
       " 'C3_ad4b77ff': 65,\n",
       " 'C3_9143c832': 66,\n",
       " 'C3_e346a5fd': 67,\n",
       " 'C3_<UNK>': 59,\n",
       " 'C4_d16679b9': 69,\n",
       " 'C4_c18be181': 70,\n",
       " 'C4_85dd697c': 71,\n",
       " 'C4_f922efad': 72,\n",
       " 'C4_13508380': 73,\n",
       " 'C4_29998ed1': 74,\n",
       " 'C4_f56b7dd5': 75,\n",
       " 'C4_<UNK>': 68,\n",
       " 'C5_25c83c98': 77,\n",
       " 'C5_4cf72387': 78,\n",
       " 'C5_43b19349': 79,\n",
       " 'C5_384874ce': 80,\n",
       " 'C5_30903e74': 81,\n",
       " 'C5_0942e0a7': 82,\n",
       " 'C5_f281d2a7': 83,\n",
       " 'C5_b0530c50': 84,\n",
       " 'C5_<UNK>': 76,\n",
       " 'C6_7e0ccccf': 86,\n",
       " 'C6_fbad5c96': 87,\n",
       " 'C6_fe6b92e5': 88,\n",
       " 'C6_13718bbd': 89,\n",
       " 'C6_6f6d9be8': 90,\n",
       " 'C6_3bf701e7': 91,\n",
       " 'C6_<UNK>': 85,\n",
       " 'C7_38eb9cf4': 93,\n",
       " 'C7_3f4ec687': 94,\n",
       " 'C7_970f01b2': 95,\n",
       " 'C7_9b98e9fc': 96,\n",
       " 'C7_49b74ebc': 97,\n",
       " 'C7_d0bdaa98': 98,\n",
       " 'C7_468a0854': 99,\n",
       " 'C7_dc7659bd': 100,\n",
       " 'C7_26a81064': 101,\n",
       " 'C7_88002ee1': 102,\n",
       " 'C7_<UNK>': 92,\n",
       " 'C8_0b153874': 104,\n",
       " 'C8_5b392875': 105,\n",
       " 'C8_1f89b562': 106,\n",
       " 'C8_37e4aa92': 107,\n",
       " 'C8_062b5529': 108,\n",
       " 'C8_51d76abe': 109,\n",
       " 'C8_c8ddd494': 110,\n",
       " 'C8_64523cfa': 111,\n",
       " 'C8_6c41e35e': 112,\n",
       " 'C8_66f29b89': 113,\n",
       " 'C8_<UNK>': 103,\n",
       " 'C9_a73ee510': 115,\n",
       " 'C9_7cc72ec2': 116,\n",
       " 'C9_<UNK>': 114,\n",
       " 'C10_3b08e48b': 118,\n",
       " 'C10_fbbf2c95': 119,\n",
       " 'C10_fa7d0797': 120,\n",
       " 'C10_0e9ead52': 121,\n",
       " 'C10_efea433b': 122,\n",
       " 'C10_6c47047a': 123,\n",
       " 'C10_5ba575e7': 124,\n",
       " 'C10_dcbc7c2b': 125,\n",
       " 'C10_451bd4e4': 126,\n",
       " 'C10_<UNK>': 117,\n",
       " 'C11_7f8ffe57': 128,\n",
       " 'C11_c4adf918': 129,\n",
       " 'C11_e51ddf94': 130,\n",
       " 'C11_5874c9c9': 131,\n",
       " 'C11_9e511730': 132,\n",
       " 'C11_a7b606c4': 133,\n",
       " 'C11_f25fe7e9': 134,\n",
       " 'C11_4ba74619': 135,\n",
       " 'C11_36bccca0': 136,\n",
       " 'C11_dd6fc8cb': 137,\n",
       " 'C11_b7094596': 138,\n",
       " 'C11_<UNK>': 127,\n",
       " 'C12_dfbb09fb': 140,\n",
       " 'C12_e0d76380': 141,\n",
       " 'C12_9f32b866': 142,\n",
       " 'C12_d8c29807': 143,\n",
       " 'C12_8fe001f4': 144,\n",
       " 'C12_a2f4e8b5': 145,\n",
       " 'C12_6aaba33c': 146,\n",
       " 'C12_ae1bb660': 147,\n",
       " 'C12_b99ddbc8': 148,\n",
       " 'C12_539c5644': 149,\n",
       " 'C12_<UNK>': 139,\n",
       " 'C13_46f42a63': 151,\n",
       " 'C13_85dbe138': 152,\n",
       " 'C13_80467802': 153,\n",
       " 'C13_ebd756bd': 154,\n",
       " 'C13_3516f6e6': 155,\n",
       " 'C13_740c210d': 156,\n",
       " 'C13_6e5da64f': 157,\n",
       " 'C13_04e4a7e0': 158,\n",
       " 'C13_eae197fd': 159,\n",
       " 'C13_dd183b4c': 160,\n",
       " 'C13_879fa878': 161,\n",
       " 'C13_1f9d2c38': 162,\n",
       " 'C13_605bbc24': 163,\n",
       " 'C13_949ea585': 164,\n",
       " 'C13_b55434a9': 165,\n",
       " 'C13_<UNK>': 150,\n",
       " 'C14_07d13a8f': 167,\n",
       " 'C14_b28479f6': 168,\n",
       " 'C14_1adce6ef': 169,\n",
       " 'C14_8ceecbc8': 170,\n",
       " 'C14_64c94865': 171,\n",
       " 'C14_cfef1c29': 172,\n",
       " 'C14_051219e6': 173,\n",
       " 'C14_f862f261': 174,\n",
       " 'C14_<UNK>': 166,\n",
       " 'C15_36721ddc': 176,\n",
       " 'C15_7ac43a46': 177,\n",
       " 'C15_52baadf5': 178,\n",
       " 'C15_a733d362': 179,\n",
       " 'C15_0f942372': 180,\n",
       " 'C15_10040656': 181,\n",
       " 'C15_d2f03b75': 182,\n",
       " 'C15_dfab705f': 183,\n",
       " 'C15_dbc5e126': 184,\n",
       " 'C15_8ab5b746': 185,\n",
       " 'C15_41f10449': 186,\n",
       " 'C15_1150f5ed': 187,\n",
       " 'C15_2ee9f086': 188,\n",
       " 'C15_2d0bb053': 189,\n",
       " 'C15_9efd8b77': 190,\n",
       " 'C15_4c1df281': 191,\n",
       " 'C15_3628a186': 192,\n",
       " 'C15_f3635baf': 193,\n",
       " 'C15_bfef54b3': 194,\n",
       " 'C15_ac182643': 195,\n",
       " 'C15_b760dcb7': 196,\n",
       " 'C15_<UNK>': 175,\n",
       " 'C16_84898b2a': 198,\n",
       " 'C16_1203a270': 199,\n",
       " 'C16_31ca40b6': 200,\n",
       " 'C16_c64d548f': 201,\n",
       " 'C16_36103458': 202,\n",
       " 'C16_89052618': 203,\n",
       " 'C16_b041b04a': 204,\n",
       " 'C16_bad5ee18': 205,\n",
       " 'C16_87acb535': 206,\n",
       " 'C16_aafa191e': 207,\n",
       " 'C16_da441c7e': 208,\n",
       " 'C16_<UNK>': 197,\n",
       " 'C17_e5ba7672': 210,\n",
       " 'C17_d4bb7bd8': 211,\n",
       " 'C17_07c540c4': 212,\n",
       " 'C17_3486227d': 213,\n",
       " 'C17_776ce399': 214,\n",
       " 'C17_1e88c74f': 215,\n",
       " 'C17_2005abd1': 216,\n",
       " 'C17_27c07bd6': 217,\n",
       " 'C17_8efede7f': 218,\n",
       " 'C17_<UNK>': 209,\n",
       " 'C18_5aed7436': 220,\n",
       " 'C18_891589e7': 221,\n",
       " 'C18_7ef5affa': 222,\n",
       " 'C18_281769c2': 223,\n",
       " 'C18_bc48b783': 224,\n",
       " 'C18_005c6740': 225,\n",
       " 'C18_f54016b9': 226,\n",
       " 'C18_c21c3e4c': 227,\n",
       " 'C18_7b49e3d2': 228,\n",
       " 'C18_1f868fdd': 229,\n",
       " 'C18_2efa89c6': 230,\n",
       " 'C18_63cdbb21': 231,\n",
       " 'C18_2804effd': 232,\n",
       " 'C18_bd17c3da': 233,\n",
       " 'C18_e7e991cb': 234,\n",
       " 'C18_698d1c68': 235,\n",
       " 'C18_eea3ab97': 236,\n",
       " 'C18_13145934': 237,\n",
       " 'C18_582152eb': 238,\n",
       " 'C18_7e32f7a4': 239,\n",
       " 'C18_e88ffc9d': 240,\n",
       " 'C18_a6f5dd38': 241,\n",
       " 'C18_9880032b': 242,\n",
       " 'C18_e4ca448c': 243,\n",
       " 'C18_87c6f83c': 244,\n",
       " 'C18_7b06fafe': 245,\n",
       " 'C18_df4fffb7': 246,\n",
       " 'C18_752d8b8a': 247,\n",
       " 'C18_52e44668': 248,\n",
       " 'C18_<UNK>': 219,\n",
       " 'C19_21ddcdc9': 250,\n",
       " 'C19_55dd3565': 251,\n",
       " 'C19_cf99e5de': 252,\n",
       " 'C19_9437f62f': 253,\n",
       " 'C19_<UNK>': 249,\n",
       " 'C20_5840adea': 255,\n",
       " 'C20_a458ea53': 256,\n",
       " 'C20_b1252a9d': 257,\n",
       " 'C20_<UNK>': 254,\n",
       " 'C21_0014c32a': 259,\n",
       " 'C21_73d06dde': 260,\n",
       " 'C21_dfcfc3fa': 261,\n",
       " 'C21_5f957280': 262,\n",
       " 'C21_e587c466': 263,\n",
       " 'C21_d4703ebd': 264,\n",
       " 'C21_723b4dfd': 265,\n",
       " 'C21_0429f84b': 266,\n",
       " 'C21_a4b7004c': 267,\n",
       " 'C21_7e5b7cc4': 268,\n",
       " 'C21_<UNK>': 258,\n",
       " 'C22_ad3062eb': 270,\n",
       " 'C22_c9d4222a': 271,\n",
       " 'C22_78e2e389': 272,\n",
       " 'C22_8ec974f4': 273,\n",
       " 'C22_<UNK>': 269,\n",
       " 'C23_32c7478e': 275,\n",
       " 'C23_3a171ecb': 276,\n",
       " 'C23_423fab69': 277,\n",
       " 'C23_be7c41b4': 278,\n",
       " 'C23_bcdee96c': 279,\n",
       " 'C23_c7dc6720': 280,\n",
       " 'C23_55dd3565': 281,\n",
       " 'C23_dbb486d7': 282,\n",
       " 'C23_93bad2c0': 283,\n",
       " 'C23_<UNK>': 274,\n",
       " 'C24_aee52b6f': 285,\n",
       " 'C24_3b183c5c': 286,\n",
       " 'C24_1793a828': 287,\n",
       " 'C24_3fdb382b': 288,\n",
       " 'C24_b34f3128': 289,\n",
       " 'C24_45ab94c8': 290,\n",
       " 'C24_9117a34a': 291,\n",
       " 'C24_c0d61a5c': 292,\n",
       " 'C24_b258af68': 293,\n",
       " 'C24_df487a73': 294,\n",
       " 'C24_f96a556f': 295,\n",
       " 'C24_08b0ce98': 296,\n",
       " 'C24_<UNK>': 284,\n",
       " 'C25_e8b83407': 298,\n",
       " 'C25_001f3601': 299,\n",
       " 'C25_ea9a246c': 300,\n",
       " 'C25_2bf691b1': 301,\n",
       " 'C25_010f6491': 302,\n",
       " 'C25_9b3e8820': 303,\n",
       " 'C25_445bbe3b': 304,\n",
       " 'C25_cb079c2d': 305,\n",
       " 'C25_f0f449dd': 306,\n",
       " 'C25_9d93af03': 307,\n",
       " 'C25_724b04da': 308,\n",
       " 'C25_<UNK>': 297,\n",
       " 'C26_49d68486': 310,\n",
       " 'C26_c84c4aec': 311,\n",
       " 'C26_b7d9c3bc': 312,\n",
       " 'C26_9904c656': 313,\n",
       " 'C26_c27f155b': 314,\n",
       " 'C26_2fede552': 315,\n",
       " 'C26_984e0db0': 316,\n",
       " 'C26_aa5f0a15': 317,\n",
       " 'C26_b9809574': 318,\n",
       " 'C26_<UNK>': 309}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_trans.feature_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "883319d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>240</td>\n",
       "      <td>249</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>284</td>\n",
       "      <td>305</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>212</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>212</td>\n",
       "      <td>219</td>\n",
       "      <td>250</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>284</td>\n",
       "      <td>299</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>220</td>\n",
       "      <td>250</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>287</td>\n",
       "      <td>298</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>219</td>\n",
       "      <td>249</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>270</td>\n",
       "      <td>277</td>\n",
       "      <td>290</td>\n",
       "      <td>301</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>215</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>271</td>\n",
       "      <td>274</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>220</td>\n",
       "      <td>250</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>287</td>\n",
       "      <td>298</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>271</td>\n",
       "      <td>280</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>216</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>271</td>\n",
       "      <td>279</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      I1  I2  I3  I4  I5  I6  I7  I8  I9  I10  ...  C17  C18  C19  C20  C21  \\\n",
       "0      1   2   3   4   5   6   7   8   9   10  ...  213  240  249  257  258   \n",
       "1      1   2   3   4   5   6   7   8   9   10  ...  212  219    0    0  258   \n",
       "2      1   2   3   4   5   6   7   8   9   10  ...  212  219  250  257  258   \n",
       "3      1   2   3   4   5   6   7   8   9   10  ...  210  220  250  257  258   \n",
       "4      1   2   3   4   5   6   7   8   9   10  ...  210  219  249  257  258   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "1594   1   2   3   4   5   6   7   8   9   10  ...  215  219    0    0  258   \n",
       "1595   1   2   3   4   5   6   7   8   9   10  ...  210  220  250  257  258   \n",
       "1596   1   2   3   4   5   6   7   8   9   10  ...  210  219    0    0  258   \n",
       "1597   1   2   3   4   5   6   7   8   9   10  ...  210  219    0    0  258   \n",
       "1598   1   2   3   4   5   6   7   8   9   10  ...  216  219    0    0  258   \n",
       "\n",
       "      C22  C23  C24  C25  C26  \n",
       "0       0  279  284  305  309  \n",
       "1       0  276  284    0    0  \n",
       "2       0  275  284  299  309  \n",
       "3       0  277  287  298  309  \n",
       "4     270  277  290  301  311  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "1594  271  274  284    0    0  \n",
       "1595    0  276  287  298  309  \n",
       "1596    0  282  284    0    0  \n",
       "1597  271  280  284    0    0  \n",
       "1598  271  279  284    0    0  \n",
       "\n",
       "[1599 rows x 39 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7235edeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2891.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4877.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       I1     I2    I3    I4      I5     I6     I7    I8     I9  I10  ...  \\\n",
       "0     1.0    0.0   1.0   0.0   227.0    1.0  173.0  18.0   50.0  1.0  ...   \n",
       "1     4.0    1.0   1.0   2.0    27.0    2.0    4.0   2.0    2.0  1.0  ...   \n",
       "2     0.0  806.0   0.0   0.0  1752.0  142.0    2.0   0.0   50.0  0.0  ...   \n",
       "3     2.0   -1.0  42.0  14.0   302.0   38.0   25.0  38.0   90.0  1.0  ...   \n",
       "4     0.0   57.0   2.0   1.0  2891.0    2.0   35.0   1.0  137.0  0.0  ...   \n",
       "...   ...    ...   ...   ...     ...    ...    ...   ...    ...  ...  ...   \n",
       "1594  0.0    8.0   1.0   1.0    43.0    0.0    0.0   1.0    1.0  0.0  ...   \n",
       "1595  8.0    2.0  20.0   8.0    36.0    9.0    8.0  10.0    8.0  1.0  ...   \n",
       "1596  0.0    1.0   2.0  12.0  4877.0  140.0   13.0  34.0  136.0  0.0  ...   \n",
       "1597  0.0    2.0   0.0   1.0  1972.0    0.0    0.0   1.0   14.0  0.0  ...   \n",
       "1598  0.0   34.0   3.0   4.0     0.0    0.0    0.0   4.0   14.0  0.0  ...   \n",
       "\n",
       "      C17  C18  C19  C20  C21  C22  C23  C24  C25  C26  \n",
       "0     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "2     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "3     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "1594  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1595  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1596  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1597  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "1598  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "\n",
       "[1599 rows x 39 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a0f5b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_values.values.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cbb3267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcols=dis_col+con_col\n",
    "feature_values[allcols].values.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920cd3e",
   "metadata": {},
   "source": [
    "### 建立自己的dataset和对应的dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33d9c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)           # torch模型参数的默认数据类型是flaot32.  np/pd是默认是flaot64(double).转成一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ed2ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建dataset: 都放np,防止loader开多进程内存泄露:https://github.com/pytorch/pytorch/issues/13246#issuecomment-893198671）\n",
    "class Mydata(Dataset):\n",
    "    def __init__(self,fv,fp,target,mode='train'):\n",
    "        super(Mydata, self).__init__()\n",
    "        self.fv=fv           # np: m,n.  每个样本的特征取值 \n",
    "        self.fp=fp           #           每个样本的特征位置.如果太大以后可以放np文件名.或切成多个文件,每次只打开一个(类似drml)\n",
    "        self.target=target   #           如果mode==train/valid.对应y. mode==test。可以传入样本id。infer时不用\n",
    "    def __len__(self):\n",
    "        return len(self.fv)\n",
    "    def __getitem__(self, index):\n",
    "        return self.fp[index,:],self.fv[index],self.target[index]  # 提前做好了映射。当然映射也可以在这里做。\n",
    "\n",
    "allcols=dis_col+con_col\n",
    "trainDataset=Mydata(feature_values[allcols].values,feature_pos[allcols].values, raw_df[label].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8006fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = RandomSampler(trainDataset)\n",
    "train_dataloader = DataLoader(trainDataset, sampler=train_sampler, batch_size=32,num_workers=4)\n",
    "epoch_num=3\n",
    "for epoch in range(epoch_num):\n",
    "    for batch_id,x in enumerate(train_dataloader):   # 把数据完整轮询一遍。对应一个epoch. 每一轮都是随机的\n",
    "        # 输入模型\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3df47b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[15, 57, 59,  ..., 11, 12, 13],\n",
       "         [15, 26,  0,  ..., 11, 12, 13],\n",
       "         [15, 41, 59,  ..., 11, 12, 13],\n",
       "         ...,\n",
       "         [16, 26, 59,  ..., 11, 12, 13],\n",
       "         [15, 33, 61,  ..., 11, 12, 13],\n",
       "         [17, 26, 59,  ..., 11, 12, 13]]),\n",
       " tensor([[ 1.,  1.,  1.,  ...,  2.,  0., 13.],\n",
       "         [ 1.,  1.,  1.,  ...,  1.,  0.,  4.],\n",
       "         [ 1.,  1.,  1.,  ...,  1.,  0.,  4.],\n",
       "         ...,\n",
       "         [ 1.,  1.,  1.,  ...,  2.,  0.,  0.],\n",
       "         [ 1.,  1.,  1.,  ...,  2.,  0.,  8.],\n",
       "         [ 1.,  1.,  1.,  ...,  1.,  0.,  2.]]),\n",
       " tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 0, 0, 1])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3e73d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader:   valid同\n",
    "trainloader = DataLoader(trainDataset,        \n",
    "                    shuffle=True,             # 每个epoch全部shuffle\n",
    "                    batch_size=32,\n",
    "                    collate_fn=None,          # 自定义如何拼batch。默认有，一般不需要。可以用来对batch padding（根据每个batch最长的text）\n",
    "                                              # 传入的是一个batch，B个tuple. 每个tuple对应Dataset传出来的n个元素。\n",
    "                                              # 自己重新拼成n个元素，每个元素B行，作为loader每次迭代的返回\n",
    "                    pin_memory=False,         # 页锁定内存：不可分页，占用物理内存。 可分页内存：占用虚拟内存，用时候从磁盘读入物理内存\n",
    "                                                # gpu需要通过页锁定内存中，把数据复制到gpu上\n",
    "                                                #  数据从cpu的可分页内存内存传到gpu时，需要先把数据复制到临时的页锁定内存，再赋值到gpu.速度更慢\n",
    "                                                #  如果指定pin_memory=True, batch的数据会直接被放在cpu的页锁定内存中，传到gpu时更快。少了一步复制\n",
    "                                                #  但页锁定内存会占用真实物理内存，分配过多会挤占别的程序的内存，把内存耗尽。因此内存小时不建议用\n",
    "                    sampler=None,             # 定义/自定义怎么从dataset里抽取每个batch的样本.还有一个batch_sampler参数\n",
    "                                              # 需要实现__iter__方法。返回针对所有样本id的迭代器，顺序按自定义的样本顺序排好\n",
    "                                              # 需要实现 __len__ ， 表示loader的一次抽取完成。一般同dataset样本数。\n",
    "                                              # 就不能定义shuffle了，因为策略自己实现了。shuffle只能在iter里自己做。加入随机性\n",
    "                                              # 每次loader会根据__iter__(和batch_size），迭代产生该epoch的每个batch。 \n",
    "                                              # 比如nlp会根据样本文本长度，将长度相近样本排一起：iter([25,3,60,0,...1])。使得每个batch长度接近\n",
    "                                              # 通过在__iter_里先切好batch,再shuffle,再整合。打乱每个epoch,batch间的执行顺序\n",
    "                                              # 可以设置RandomSampler每次随机采样。（可参考该实现等）                       \n",
    "                    num_workers=10            # 开多进程，每个进程计算一个batch。初始化时用之前提前处理好对应的n个batch。后续batch加入新的线程\n",
    "                   )                          # 初始化时会一次性建好n个进程。每个进程提前处理好要用的batch数据。（底层是 multiprocessing）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32d5890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num=3\n",
    "for epoch in range(epoch_num):\n",
    "    for batch_id,x in enumerate(trainloader):   # 把数据完整轮询一遍。对应一个epoch\n",
    "        # 输入模型\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2294dd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)                                # 每个epoch对应的batch的个数（step的数目）。一个epoch共50个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bf0764c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_df)//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5a26398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[14, 27, 59,  ..., 11, 12, 13],\n",
       "         [14, 37, 59,  ..., 11, 12, 13],\n",
       "         [17, 33, 64,  ..., 11, 12, 13],\n",
       "         ...,\n",
       "         [15, 41, 59,  ..., 11, 12, 13],\n",
       "         [15, 40, 59,  ..., 11, 12, 13],\n",
       "         [15, 32, 59,  ..., 11, 12, 13]]),\n",
       " tensor([[ 1.,  1.,  1.,  ...,  0.,  0.,  2.],\n",
       "         [ 1.,  1.,  1.,  ...,  0.,  0.,  1.],\n",
       "         [ 1.,  1.,  1.,  ...,  8.,  0.,  4.],\n",
       "         ...,\n",
       "         [ 1.,  1.,  1.,  ...,  0.,  0.,  0.],\n",
       "         [ 1.,  1.,  1.,  ...,  1.,  0., 15.],\n",
       "         [ 1.,  1.,  1.,  ...,  1.,  0.,  0.]]),\n",
       " tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "         1, 0, 0, 1, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "732b7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_p,f_v,y=x[0],x[1],x[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649aa906",
   "metadata": {},
   "source": [
    "### 原始FM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d13e0d",
   "metadata": {},
   "source": [
    "模型维持n个w,n个embedding，对应one-hot后的所有特征（这里还算上了缺失值对应的0参数）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e0034",
   "metadata": {},
   "source": [
    "二阶分数是$$\\sum_{i}^{n}\\sum_{j!=i}^{n}x_ix_j<\\vec{v_i},\\vec{v_j}>$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3827b2f",
   "metadata": {},
   "source": [
    "直接计算是$O(n^2*k)$。每对向量内积是$k$,共$O(n^2)$个pair。最后求和"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d74b52",
   "metadata": {},
   "source": [
    "等价于embedding们对应位置22相乘后，再求和。可以先求所有embedding每个维度元素22相乘的和，最后再对所有维度求和"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968764fe",
   "metadata": {},
   "source": [
    "$$\\sum_{i}^{n}\\sum_{j!=i}^{n}<\\vec{e_i},\\vec{e_j}>= \\sum_{f} \\sum_{i}^{n}\\sum_{j!=i}^{n}e_{if}*e_{jf} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d22070",
   "metadata": {},
   "source": [
    "embedding的每个维度元素22相乘的和： $ab+ac+bc= \\frac{1}{2}((a+b+c)^2-(a^2+b^2+c^2))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e537011",
   "metadata": {},
   "source": [
    "因此对固定维度，embedding的每个维度元素22相乘的和$\\sum_{i}^{n}\\sum_{j!=i}^{n}e_{if}*e_{jf}$ ，是$\\frac{1}{2}((e_{if}+e_{jf}...)^2-(e_{if}^2+e_{if}^2+...))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7a78d",
   "metadata": {},
   "source": [
    "可以通过每个embedding相加（对应位置相加）的平方，减去每个embedding平方的相加，得到（1，k）的向量，作为embedding的每个维度元素22交互的结果。最终的二阶分数是这k个维度的结果相加。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8ea15",
   "metadata": {},
   "source": [
    "也可以把这k维向量作为新的隐特征，输入后续网络。作为FM/deepFM的一个小变体"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6985922",
   "metadata": {},
   "source": [
    "转化后，$\\frac{1}{2}((e_{if}+e_{jf}...)^2-(e_{if}^2+e_{if}^2+...))$的复杂度只有$O(n)$(n个元素相加或平方后相加)。加上维度F，总的复杂度可以降低到$O(nk)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4527e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self,n_field,n_features,embed_size,dropout=0,init_w=False):\n",
    "        \"\"\"\n",
    "        标准FM\n",
    "        n_field: 原始离散特征数目\n",
    "        n_features: 离散特征one-hot之后,和dense的总特征个数. 这里包含了一个缺失值特征向量，paddding成0\n",
    "        \"\"\"\n",
    "        super(FM, self).__init__()\n",
    "        self.n_field=n_field             # 原始特征数目\n",
    "        self.n_features=n_features       # 连续+离散特征的总数目 (离散特征one-hot+unique化后的。且算上最终的一个padding)\n",
    "        self.k=embed_size\n",
    "        \n",
    "        self.W=nn.Embedding(n_features,1,padding_idx=0)                       # 每个特征对应的wi。位置0是0对梯度无贡献。embedding默认是N(0,1)\n",
    "        self.w0=nn.Parameter(torch.zeros([1,]))                               # b初始化为0\n",
    "        self.feature_embed=nn.Embedding(n_features,embed_size,padding_idx=0)  # 每个特征对应的embedding\n",
    "        self.droplayer=nn.Dropout(dropout)\n",
    "        \n",
    "        self.scoreweight=nn.Parameter(0.5*torch.ones([2,]))                   # 一阶，二阶score的权重 \n",
    "                                                                              \n",
    "        if init_w:\n",
    "            self.__init_weight__()                                                # 初始化权重(可以不调用，用默认的)\n",
    "            \n",
    "    def __init_weight__(self):              # 初始化权重.默认是N(0,1)\n",
    "        inn=n_features-1\n",
    "        # kaiming_normal_\n",
    "        nn.init.kaiming_uniform_(self.feature_embed.weight[1:], mode='fan_in', nonlinearity='relu')  # sqrt(6/inn)\n",
    "        nn.init.normal_(self.W.weight[1:],0, np.sqrt(2.0 /inn))\n",
    "        \n",
    "    def forward(self,f_p,f_x): # B,n.  n是每个样本的原始特征数目\n",
    "        \"\"\"\n",
    "        f_p: (B,N)  每个样本的原始特征，根据特征名（连续特征）/特征取值（离散特征）被映射到embedding上的位置。 N:原始特征数目\n",
    "        f_x: (B,N)  每个样本的原始特征，对应的取值。 离散特征对应的是one-hot后的，所以在对应的f_p上取值为1\n",
    "        \"\"\"\n",
    "        batch_size=f_p.shape[0]\n",
    "        \n",
    "        # 一阶score\n",
    "        w=self.W(f_p.long()).reshape(batch_size,-1)              # B,n   每个样本根据原始特征，找到对应位置处的w\n",
    "        y_score1=self.w0 + torch.sum(torch.mul(w,f_x),1)  # B,1   wixi+b  B,n -->   B,1.  要是不sum，也可以作为n个特征。之后作为deepFM的改造\n",
    "        \n",
    "        # 二阶score\n",
    "        embed=self.feature_embed(f_p.long())             # B,n,d 每个样本根据原始特征，找到对应位置处的embedding\n",
    "        \n",
    "        embed=torch.mul(embed,f_x.unsqueeze(2))           # B,n,d 样本的每个向量乘上对应的xi： xi* embedding\n",
    "                                                          #       tf.mul:按位置乘.广播 (B,n,d) * (B,n,1) ->(B,n,d) \n",
    "                                                          #       离散特征对应的xi是1.假设数值型已经归一化\n",
    "        \n",
    "        embed=self.droplayer(embed)\n",
    "        \n",
    "        # 每个filed 向量22交互\n",
    "        e_sum= torch.sum(embed,1)                         # B,d   每个样本。所有embedding对应维度元素相加，得到e_sum\n",
    "        e_sum_square=torch.square(e_sum)                  # B,d   (e_sum)^2\n",
    "        \n",
    "        e_square=torch.square(embed)                      # B,n,d  平方后的\n",
    "        e_square_sum=torch.sum(e_square,1)                # B,d    每个维度相加\n",
    "        \n",
    "        f =0.5*(e_sum_square-e_square_sum)                # B,d    n个embedding，每个维度元素22交互的结果（可作为新特征，拼接到后边）\n",
    "    \n",
    "        y_score2= torch.sum(f,1)                          # (B,)\n",
    "        \n",
    "        logits=y_score1+y_score2                          # (B,)   最终分数  y_score1*self.scoreweight[0] +..\n",
    "        \n",
    "        # TODO:loss加正则项（最后加）/ grad-clip等. 看下train-loop\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24089f",
   "metadata": {},
   "source": [
    "### 原始deepFM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ebe038",
   "metadata": {},
   "source": [
    "FM部分相同，但共享底层的embedding部分。把样本原始离散特征和连续特征映射得到的所有embedding，concat,作为后续mlp的输入。输出结果作为deep部分的score,和linear(FM)部分相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ddae6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepFM： 标准的。 或者上述k个元素作为特征统一拼到deep的\n",
    "class deepFM(nn.Module):\n",
    "    def __init__(self,n_field,n_features,embed_size,hiddens,dropout=0,batchnorm=True,init_w=False):\n",
    "        \"\"\"\n",
    "        标准DeepFM\n",
    "        n_field: 原始特征数目\n",
    "        n_features: 离散特征one-hot之后,和dense的总特征个数. 这里包含了一个缺失值特征向量，paddding成0\n",
    "        deep每层：linear + (bn) + relu + (dropout).  输出hidden层。  最后按需单独linear到1\n",
    "        \"\"\"\n",
    "        super(deepFM, self).__init__() \n",
    "        self.n_field=n_field             # 原始特征数目\n",
    "        self.n_features=n_features       # 连续+离散特征的总数目 (离散特征one-hot+unique化后的。且算上最终的一个padding)\n",
    "        self.k=embed_size\n",
    "        self.dropout=dropout\n",
    "        self.batchnorm=batchnorm\n",
    "        self.hiddens=hiddens             # hiddens:[256,64,32]\n",
    "    \n",
    "        # FM-part\n",
    "        self.W=nn.Embedding(n_features,1,padding_idx=0)                       # 每个特征对应的wi。位置0是0对梯度无贡献。embedding默认是N(0,1)\n",
    "        self.w0=nn.Parameter(torch.zeros([1,]))                               # b初始化为0\n",
    "        self.feature_embed=nn.Embedding(n_features,embed_size,padding_idx=0)  # 每个特征对应的embedding\n",
    "        self.droplayer=nn.Dropout(dropout)            \n",
    " \n",
    "        # deep-part.\n",
    "        input_size=n_field*embed_size                                         #输入是所有原始特征的embedding拼接   \n",
    "        self.mlp=self.build_mlp(input_size,hiddens)                           #多层mlp.输出hidden  是一个ModuleList\n",
    "        self.finallinear=nn.Linear(hiddens[-1],1,bias=True)                   #最后一层linear\n",
    "        \n",
    "        if init_w:\n",
    "            self.__init_deep_weight__()                                       # 初始化权重。(可以按情况调用。现在用kaiming)\n",
    "            self.__init_wide_weight__()\n",
    "            \n",
    "    def __init_wide_weight__(self):              # 初始化权重.默认是N(0,1)\n",
    "        inn=n_features-1\n",
    "        # kaiming_normal_\n",
    "        nn.init.kaiming_uniform_(self.feature_embed.weight[1:], mode='fan_in', nonlinearity='relu')  # sqrt(6/inn)\n",
    "        nn.init.normal_(self.W.weight[1:],0, np.sqrt(2.0 /inn))\n",
    "\n",
    "    def __init_deep_weight__(self):              # 初始化权重\n",
    "        for layer in self.mlp:\n",
    "            if (layer.__class__.__name__=='Linear'):  # 每层初始化\n",
    "                self.init_linear(layer)\n",
    "        self.init_linear(self.finallinear)\n",
    "        \n",
    "    def init_linear(self,layer):\n",
    "        nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')  #sqrt(2/inn) 或者 sqrt(2/out)\n",
    "        nn.init.constant_(layer.bias, 0)\n",
    "\n",
    "    def build_mlp(self,input_size,hiddens):\n",
    "        \"\"\"\n",
    "        hiddens:[256,56,32]\n",
    "        输出最后一层的hidden节点 （dropout+激活后的），可直接linear+sigmoid到deepscore. 也可以拼其他特征后再linear\n",
    "        \"\"\"        \n",
    "        layers=nn.ModuleList()\n",
    "        \n",
    "        hiddens.insert(0,input_size)     #  [inputsize,256,56,32]\n",
    "        num_layer=len(hiddens)-1         #  3层\n",
    "        \n",
    "        for i in range(0,len(hiddens)-1):\n",
    "            \n",
    "            # 线性层\n",
    "            in_dim=hiddens[i]\n",
    "            out_dim=hiddens[i+1]\n",
    "            print(in_dim,out_dim)\n",
    "            layer=nn.Linear(in_dim,out_dim,bias=True)\n",
    "            layers.append(layer)\n",
    "            \n",
    "            # BN\n",
    "            if self.batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(out_dim)) \n",
    "            \n",
    "            # active + dropout\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(self.dropout))\n",
    "                \n",
    "        return layers  # 拼成一个前后连接的网络。可以在forward里作为一个模块被整体调用\n",
    "    \n",
    "    \n",
    "    def forward(self,f_p,f_x): # B,n.  n是每个样本的原始特征数目\n",
    "        \"\"\"\n",
    "        f_p: (B,N)  每个样本的原始特征，根据特征名（连续特征）/特征取值（离散特征）被映射到embedding上的位置。 N:原始特征数目\n",
    "        f_x: (B,N)  每个样本的原始特征，对应的取值。 离散特征对应的是one-hot后的，所以在对应的f_p上取值为1\n",
    "        output:  FM和deep部分 score相加\n",
    "        \"\"\"\n",
    "        batch_size=f_p.shape[0]\n",
    "        \n",
    "        # FM-part    每个filed 向量22交互\n",
    "        w=self.W(f_p.long()).reshape(batch_size,-1)       # B,n   每个样本根据原始特征，找到对应位置处的w\n",
    "        y_score1=self.w0 + torch.sum(torch.mul(w,f_x),1)  # B,1   wixi+b  B,n -->   B,1.  要是不sum，也可以作为n个特征。\n",
    "        \n",
    "        embed=self.feature_embed(f_p.long())              # B,n,d 每个样本根据原始特征，找到对应位置处的embedding \n",
    "        embed=torch.mul(embed,f_x.unsqueeze(2))           # B,n,d 样本的每个向量乘上对应的xi： xi* embedding\n",
    "        e_sum= torch.sum(embed,1)                         # B,d   每个样本。所有embedding对应维度元素相加，得到e_sum\n",
    "        e_sum_square=torch.square(e_sum)                  # B,d   (e_sum)^2\n",
    "        e_square=torch.square(embed)                      # B,n,d  平方后的\n",
    "        e_square_sum=torch.sum(e_square,1)                # B,d    每个维度相加\n",
    "        f =0.5*(e_sum_square-e_square_sum)                # B,d    n个embedding，每个维度元素22交互的结果（可作为新特征，拼接到后边）\n",
    "        y_score2= torch.sum(f,1)                          # (B,)\n",
    "        \n",
    "        # deep-part\n",
    "        x=torch.reshape(embed,[-1,self.n_field*self.k])           # 输入是所有原始特征对应embedding的拼接\n",
    "        for layer in self.mlp:\n",
    "            if(layer.__class__.__name__=='Linear'):\n",
    "                pass\n",
    "                #print(x.mean(),x.std())        # 可以画一下数据分布\n",
    "            x=layer(x)\n",
    "        \n",
    "        y_deep=self.finallinear(x).squeeze(-1)         # (B，)\n",
    "        \n",
    "        logits=y_score1+y_score2 +y_deep\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96836f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_field=len(dis_col+con_col)           # 原始特征数目\n",
    "n_features=len(f_trans.feature_id_map) # 连续+离散特征的总数目 (离散特征one-hot+unique化后的。且算上最终的一个padding)\n",
    "embed_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fb2ffb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312 256\n",
      "256 56\n",
      "56 32\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "hiddens=[256,56,32]\n",
    "model=deepFM(n_field,n_features,embed_size,hiddens,dropout=0.5)\n",
    "#model=FM(n_field,n_features,embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d2f24ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepFM(\n",
       "  (W): Embedding(319, 1, padding_idx=0)\n",
       "  (feature_embed): Embedding(319, 8, padding_idx=0)\n",
       "  (droplayer): Dropout(p=0.5, inplace=False)\n",
       "  (mlp): ModuleList(\n",
       "    (0): Linear(in_features=312, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=56, bias=True)\n",
       "    (5): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=56, out_features=32, bias=True)\n",
       "    (9): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (finallinear): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba7855c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟一次forward\n",
    "logits=model(f_p,f_v)\n",
    "target=y\n",
    "loss_func= nn.BCEWithLogitsLoss()    #  mean [yn⋅logσ(xn)+(1−yn)⋅log(1−σ(xn))]\n",
    "loss=loss_func(logits,target.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dacb0652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e653abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.6035e+03,  1.7109e+07,  1.4638e+06, -3.0710e+04,  2.1162e+05,\n",
       "        -3.7813e+06, -7.0735e+05, -4.6011e+07, -7.0422e+04,  2.0176e+03,\n",
       "        -3.8771e+05, -2.5291e+04, -1.4853e+08, -1.6265e+06, -2.5600e+05,\n",
       "         7.1084e+03, -1.4330e+05, -1.6017e+05, -1.2043e+06,  1.2714e+03,\n",
       "        -1.4872e+05, -2.9318e+08, -6.3235e+07, -8.6016e+06, -5.4082e+05,\n",
       "        -4.4505e+05, -4.0083e+06,  5.7519e+03,  1.2027e+07, -3.0599e+05,\n",
       "        -6.9011e+04, -1.0556e+06], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4980064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(999979.6875, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4139bbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999979.6875"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f8c4d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16220a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(999979.6875, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy_with_logits(logits, target.float())  # 用函数结果相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29b27111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-1.9554, -0.0343,  1.3315,  ..., -1.7705,  0.5383,  0.1683],\n",
       "        [-2.1674, -1.2431, -0.4310,  ..., -0.1527, -0.4331, -1.7655],\n",
       "        ...,\n",
       "        [ 1.5762, -1.3008,  0.0370,  ..., -0.0271,  1.4381,  0.3837],\n",
       "        [ 0.1990,  0.5929, -1.4279,  ..., -1.2578,  0.7082, -0.1214],\n",
       "        [ 0.9754, -2.1611, -1.6071,  ...,  0.4555,  1.1335,  0.1223]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_embed.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff6cb0",
   "metadata": {},
   "source": [
    "### train_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e3141",
   "metadata": {},
   "source": [
    "正常trainloop + reg + grad_clip  + CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf6000a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=StandardScaler()\n",
    "ss.fit(raw_df[con_col])                           #归一化\n",
    "raw_df[con_col]=ss.transform(raw_df[con_col])     # 测试做相同处理\n",
    "\n",
    "f_trans=FeaturePosTrans(dis_col,con_col,0)           # 映射到对应id. 出现10次以下的作为UNK\n",
    "f_trans.fit(raw_df)\n",
    "feature_pos,feature_values=f_trans.transform(raw_df,label)  # 测试集做相同处理。用相同的原始con_col,dis_col。 label只是用来删除掉该列\n",
    "cols=dis_col+con_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff5727",
   "metadata": {},
   "source": [
    "处理过的数据，划分cv。 训练5个模型，用5个模型的平均作为最终结果（同时也保存这5个模型。作为衡量该模型最终表现的量度）\n",
    "也可以有放回的每次随机采样一份：df.sample(frac=0.7,random_state =i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "192a3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf=StratifiedKFold(n_splits=5,random_state=2020,shuffle=True)    # 分割器。按y值对给定的样本划分。返回分好的样本id 每轮4:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85cafbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 13:01:39,690 - 训练第0折对应的模型\n"
     ]
    }
   ],
   "source": [
    "for i,(train_index,dev_index) in enumerate(skf.split(raw_df,raw_df[label])): # 可用于df. 根据y，输出分割后的train/dev样本位置\n",
    "    logger.info(\"训练第%s折对应的模型\",i)                                    # 每个fold训一个模型\n",
    "    \n",
    "    train_fv=feature_values[cols].iloc[train_index].values                # 按样本位置，从转换好的df里取训练样本\n",
    "    train_fp=feature_pos[cols].iloc[train_index].values\n",
    "    train_label=raw_df[label].iloc[train_index].values\n",
    "    trainDataset=Mydata(train_fv,train_fp, train_label)                   # 对应的dataset\n",
    "    \n",
    "    dev_fv=feature_values[cols].iloc[dev_index].values                    # dev场景下，主要是计算指标。model不输出loss\n",
    "    dev_fp=feature_pos[cols].iloc[dev_index].values\n",
    "    dev_label=raw_df[label].iloc[dev_index].values                        # test用raw_df[label]\n",
    "    dev_dataset=Mydata(dev_fv,dev_fp, dev_label)                          \n",
    "    \n",
    "    #train(train_dataset,dev_dataset)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65834824",
   "metadata": {},
   "source": [
    "建立一个class,用来封装基本模型。预测，保存，重新加载等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb915d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置随机种子。每次训练固定  \n",
    "def set_seed(args):\n",
    "    random.seed(args.random_seed)\n",
    "    np.random.seed(args.random_seed)\n",
    "    torch.manual_seed(args.random_seed)\n",
    "    \n",
    "# 用来算平均的\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "class WrapModel(object):\n",
    "    def __init__(self,args=None,state_dict=None):\n",
    "        # 初始化模型\n",
    "        n_field=len(args.dis_col+args.con_col)                # 原始特征数目\n",
    "        n_features=len(args.f_trans.feature_id_map)           # 连续+离散特征one-hot后的特征总数目 (算上一个NAN padding)\n",
    "        #model=FM(n_field,n_features,args.embed_size,args.dropout,args.init_w)\n",
    "        model=deepFM(n_field,n_features,args.embed_size,args.hiddens,args.dropout,args.batchnorm,args.init_w)\n",
    "        \n",
    "        if state_dict:                                        # 加载保存过的模型参数（如果有）\n",
    "            model.load_state_dict(state_dict)\n",
    "       \n",
    "        device = torch.device(\"cuda:0\" if args.cuda else \"cpu\") # 放gpu上 （相比.cuda(),优先使用这个。方便在不同设备上切换）\n",
    "        model.to(device) \n",
    "        \n",
    "        self.model=model\n",
    "        args.device=device\n",
    "        self.args=args\n",
    "        set_seed(args)\n",
    "\n",
    "        \n",
    "    def train(self,train_dataset,dev_dataset=None):        # 参考jupyter的loss画图\n",
    "        args=self.args\n",
    "        model=self.model\n",
    "        \n",
    "        # 设置train-loader. 每次都是随机取（无放回）\n",
    "        sampler = RandomSampler(train_dataset)\n",
    "        train_loader = DataLoader(train_dataset, sampler=sampler, batch_size=args.batch_size,num_workers=4) \n",
    "        \n",
    "        # 设置优化器\n",
    "        parameters = [p for p in self.model.parameters() if p.requires_grad]  # 可只优化模型的部分层/部分parameter\n",
    "        if args.optimizer == 'sgd':\n",
    "            optimizer = optim.SGD(parameters, lr=args.lr,momentum=0.9,weight_decay=0.08)\n",
    "        elif args.optimizer == 'adamax':\n",
    "            optimizer = optim.Adamax(parameters,weight_decay=0.08)\n",
    "        elif args.optimizer == 'adamaW':\n",
    "            optimizer = AdamW(parameters, lr=args.lr, eps=1e-8,weight_decay=0.08)\n",
    "        elif args.optimizer == 'adam':\n",
    "            optimizer = optim.Adam(parameters, lr=0.001)  # demo里的\n",
    "        \n",
    "        \n",
    "        # 定义lr本身的scheduler. \n",
    "        # 在多个epoch过程中，调节优化器中lr本身的大小。每个step通过schcduler.step()改变lr本身的值。optimizer里的lr被同步修改。\n",
    "        # 但只改变lr的值。其他算法仍同optimizer\n",
    "        # 在限定step内，让lr从0线性增加到设定值。防止初始lr较大，模型不稳定。之后认为模型稳定.再线性减小，到最终训练完lr减小到0\n",
    "        num_training_steps=int(len(train_loader)*args.epochs)      # 完整训练过程中总的steps:每个step对应一个batch.\n",
    "        num_warmup_steps=int(num_training_steps*0.2)               # 预热期steps的数目：占总step的20%。在这些step内，让lr从0线性增加到设定值。此时认为模型稳定了\n",
    "        if args.schedule_lr:\n",
    "            scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps,num_training_steps) # 先预热一些step.再逐渐减小。\n",
    "            logger.info(\"最初的lr:{}\".format(scheduler.get_lr()))  # lr此时是0  增到设定lr后，最终训练完仍减小到0\n",
    "                                                                                                                              \n",
    "        # train-loop\n",
    "        logger.info(\"***** Running training *****\")\n",
    "        logger.info(\"  总的样本数量 = %d\", len(train_dataset))\n",
    "        logger.info(\"  epoch数目 = %d\", args.epochs) \n",
    "        logger.info(\"  train batch size = %d\",args.batch_size)\n",
    "        logger.info(\"  所有epoch总的steps = %d\", num_training_steps) \n",
    "        \n",
    "        global_step = 0                      # 记录总的step\n",
    "        best_metric=0.0\n",
    "\n",
    "        model.zero_grad()                    # 把模型所有参数的梯度都置为0 （optimizer.zero_grad是把优化器里参数的梯度置为0）\n",
    "        \n",
    "        steps=[]\n",
    "        losses=[]                           # 所有epoch.每个loss\n",
    "        avg_losses=[]                       # 该epoch.截止目前step的所有loss的平均\n",
    "        nstep_avg_losses=[]                 # 该epoch.每n个step,loss的平均\n",
    "        for epoch in enumerate(range(args.epochs)):                 # 每个epoch\n",
    "            \n",
    "            loss_sum=0.0                                            # 用来记录每个epoch到此时的平均loss\n",
    "            nstep_avg_loss = AverageMeter()                         # epoch内，每n个step loss的平均。 n==display_steps\n",
    "          \n",
    "            for step, batch in enumerate(train_loader):  # dataset按batch-size轮询一遍。每个batch一个step\n",
    "                \n",
    "                # 输入放到对应设备上。同模型\n",
    "                f_p,f_v,y= (x.to(args.device) for x in batch)   # trian、dev时才用y. test时没有y,dataset传入id列或任意列。但不用\n",
    "                del batch\n",
    "                \n",
    "                model.train()  # train mode\n",
    "                \n",
    "                logits=model(f_p,f_v)                                  # 输出logits,before sigmoid: (B,1)\n",
    "                \n",
    "                loss=self.compute_loss(logits,y)                       # 计算该batch的loss (TODO:可以添加L2)\n",
    "                \n",
    "                optimizer.zero_grad()                                  # 清空之前的参数梯度\n",
    "                loss.backward()                                        # 根据loss重新计算模型参数梯度\n",
    "                #print(batch_loss.item())\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)   # 对算好的梯度 grad_clip\n",
    "                \n",
    "                optimizer.step()                                      # 根据梯度更新参数\n",
    "                if args.schedule_lr:\n",
    "                    scheduler.step()                                  # 更新lr值\n",
    "                global_step += 1\n",
    "                \n",
    "                \n",
    "                # 打印每段时间的平均loss.和此时的train_metric\n",
    "                loss_sum+=loss.item()                                 # 该epoch截止到目前所有step内的平均。 item():转为float\n",
    "                nstep_avg_loss.update(loss.item(),f_p.shape[0])       # 每n个step内的平均\n",
    "                if args.display_steps % (step+1)==0:\n",
    "                    print('Epoch = {} | step = {}/{} | loss = {:.2f}'.format(epoch,step+1,len(train_loader),loss_sum/(step+1)))\n",
    "                    avg_losses.append(loss_sum/(step+1))  #每个epoch内的平均loss\n",
    "                    losses.append(loss.item())            #每个step的单个loss\n",
    "                    steps.append(global_step)\n",
    "                    nstep_avg_losses.append(nstep_avg_loss.avg) # epoch内.每n个step的单个loss。n==display_steps\n",
    "                    nstep_avg_loss.reset()               \n",
    "                          \n",
    "                # 评估。好的话保存\n",
    "                \n",
    "                \n",
    "            # myReader+demoFM都是每个epoch结束之后eval+保存\n",
    "            \n",
    "            # 打印每个epoch的日志\n",
    "#             print((\"\\nEPOCH=%d, loss=%.3f, \" + metric_name + \" = %.3f, val_loss=%.3f, \" + \"val_\" + metric_name + \" = %.3f\") %info)\n",
    "#             nowtime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#             print('\\n' + '=========='* 8 + '%s' %nowtime)\n",
    "\n",
    "            \n",
    "        self.steps=steps\n",
    "        self.losses=losses\n",
    "        self.avg_losses=avg_losses\n",
    "        self.nstep_avg_losses=nstep_avg_losses\n",
    "                          \n",
    "    def compute_loss(self,logits,labels):\n",
    "        '''\n",
    "        计算一个batch的loss\n",
    "        logits:(B,1) before sigmoid\n",
    "        labels:(B,1) 每个样本的取值0/1\n",
    "        '''\n",
    "        loss=F.binary_cross_entropy_with_logits(logits,labels.float()) #  mean [yn⋅logσ(xn)+(1−yn)⋅log(1−σ(xn))]\n",
    "        return loss\n",
    "        \n",
    "    def infer(self,test_dataset):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def eval_metric(self,labels,preds):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def save(self,filename):\n",
    "        '保存超参数和内部模型的模型参数'\n",
    "        params = {\n",
    "            'state_dict': self.model.state_dict(),   # 只按参数名称保存模型所有参数。是一个dict.不保存模型结构\n",
    "            'args': self.args,\n",
    "        }\n",
    "        torch.save(params, filename)           # 保存static等到指定文件中。 这里可以保存字典，之后通过load加载进来（底层pickle）\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filename):   \n",
    "        '直接根据文件名，返回加载好内部模型参数的WraPModel（init时通过state_dict）.可以在外边直接调用：WrapModel.load(f)'\n",
    "        saved_params = torch.load(\n",
    "            filename, map_location=lambda storage, loc: storage  # load默认直接加载到GPU.  这样指定，先加载到cpu上。再load_state\n",
    "        )\n",
    "        state_dict = saved_params['state_dict']\n",
    "        args = saved_params['args']\n",
    "        \n",
    "        return WrapModel(args,state_dict)     \n",
    "    \n",
    "    def export_onnx(self,onnx_filename):\n",
    "        '需要用到nn.Module等'\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "209d57e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuweijia/.conda/envs/pytorch1.9/lib/python3.9/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()                             # 超参数\n",
    "parser.add_argument('--embed_size', type=int, default=8)\n",
    "parser.add_argument('--dropout', type=float, default=0,help='默认没有dropout')\n",
    "parser.add_argument('--batchnorm', type=bool, default=False,help='默认没有batchnorm')\n",
    "parser.add_argument('--epochs', type=int, default=20)\n",
    "parser.add_argument('--max_grad_norm', type=float, default=1.0)  #1\n",
    "parser.add_argument('--optimizer', type=str, default='adamaW')\n",
    "parser.add_argument('--lr', type=float, default=0.001,help='优化器步长') # 8e-5\n",
    "parser.add_argument('--schedule_lr', type=bool, default=False,help='是否优化lr,先warm再降低')\n",
    "parser.add_argument('--init_w', type=bool, default=False,help='是否用xvaier/kaiming等随机初始化')\n",
    "parser.add_argument('--hiddens', type=str, default='256,56,32',help='deepfm的mlp层数')\n",
    "parser.add_argument('--batch_size', type=int, default=32)\n",
    "parser.add_argument('--display_steps', type=int, default=100,help='打印日志的step间隔')\n",
    "parser.add_argument('--eval_steps', type=int, default=500)\n",
    "parser.add_argument('--eval_batch_size', type=int, default=4096)\n",
    "parser.add_argument('--test_batch_size', type=int, default=32)\n",
    "parser.add_argument('--no-cuda', type=bool, default=False,help='是否用GPU')\n",
    "parser.add_argument('--gpu', type=int, default=0,help='GPU设备id')\n",
    "parser.add_argument('--random_seed', type=int, default=2020)\n",
    "args = parser.parse_args(args=[])                              # jupyter里需要加args=[]\n",
    "args.dis_col=dis_col\n",
    "args.con_col=con_col\n",
    "args.f_trans=f_trans\n",
    "args.hiddens=[int(h) for h in args.hiddens.split(',')]\n",
    "# 设置设备为某固定gpu\n",
    "args.cuda = (not args.no_cuda)  and  (torch.cuda.is_available())\n",
    "if args.cuda:\n",
    "    torch.cuda.set_device(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee0a098a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=312, out_features=256, bias=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(312,256,bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5486bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312 256\n",
      "256 56\n",
      "56 32\n"
     ]
    }
   ],
   "source": [
    "CTRmodel=WrapModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "340bbd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepFM(\n",
       "  (W): Embedding(10995, 1, padding_idx=0)\n",
       "  (feature_embed): Embedding(10995, 8, padding_idx=0)\n",
       "  (droplayer): Dropout(p=0, inplace=False)\n",
       "  (mlp): ModuleList(\n",
       "    (0): Linear(in_features=312, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=56, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0, inplace=False)\n",
       "    (6): Linear(in_features=56, out_features=32, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (finallinear): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTRmodel.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bab7d13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Embedding-1                [-1, 39, 1]          10,995\n",
      "         Embedding-2                [-1, 39, 8]          87,960\n",
      "            Linear-3                  [-1, 256]          80,128\n",
      "              ReLU-4                  [-1, 256]               0\n",
      "           Dropout-5                  [-1, 256]               0\n",
      "            Linear-6                   [-1, 56]          14,392\n",
      "              ReLU-7                   [-1, 56]               0\n",
      "           Dropout-8                   [-1, 56]               0\n",
      "            Linear-9                   [-1, 32]           1,824\n",
      "             ReLU-10                   [-1, 32]               0\n",
      "          Dropout-11                   [-1, 32]               0\n",
      "           Linear-12                    [-1, 1]              33\n",
      "================================================================\n",
      "Total params: 195,332\n",
      "Trainable params: 195,332\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.005802\n",
      "Forward/backward pass size (MB): 0.010559\n",
      "Params size (MB): 0.745132\n",
      "Estimated Total Size (MB): 0.761494\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(CTRmodel.model,input_shape=[(39,),(39,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b37b7dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 13:01:39,792 - ***** Running training *****\n",
      "2022-03-13 13:01:39,793 -   总的样本数量 = 1279\n",
      "2022-03-13 13:01:39,794 -   epoch数目 = 20\n",
      "2022-03-13 13:01:39,795 -   train batch size = 32\n",
      "2022-03-13 13:01:39,795 -   所有epoch总的steps = 800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = (0, 0) | step = 1/40 | loss = 23.20\n",
      "Epoch = (0, 0) | step = 2/40 | loss = 23.33\n",
      "Epoch = (0, 0) | step = 4/40 | loss = 25.92\n",
      "Epoch = (0, 0) | step = 5/40 | loss = 27.08\n",
      "Epoch = (0, 0) | step = 10/40 | loss = 26.20\n",
      "Epoch = (0, 0) | step = 20/40 | loss = 23.93\n",
      "Epoch = (0, 0) | step = 25/40 | loss = 22.22\n",
      "Epoch = (1, 1) | step = 1/40 | loss = 14.48\n",
      "Epoch = (1, 1) | step = 2/40 | loss = 19.37\n",
      "Epoch = (1, 1) | step = 4/40 | loss = 14.58\n",
      "Epoch = (1, 1) | step = 5/40 | loss = 13.47\n",
      "Epoch = (1, 1) | step = 10/40 | loss = 14.60\n",
      "Epoch = (1, 1) | step = 20/40 | loss = 14.46\n",
      "Epoch = (1, 1) | step = 25/40 | loss = 15.11\n",
      "Epoch = (2, 2) | step = 1/40 | loss = 21.27\n",
      "Epoch = (2, 2) | step = 2/40 | loss = 15.69\n",
      "Epoch = (2, 2) | step = 4/40 | loss = 22.27\n",
      "Epoch = (2, 2) | step = 5/40 | loss = 20.71\n",
      "Epoch = (2, 2) | step = 10/40 | loss = 18.39\n",
      "Epoch = (2, 2) | step = 20/40 | loss = 15.27\n",
      "Epoch = (2, 2) | step = 25/40 | loss = 14.53\n",
      "Epoch = (3, 3) | step = 1/40 | loss = 9.02\n",
      "Epoch = (3, 3) | step = 2/40 | loss = 11.76\n",
      "Epoch = (3, 3) | step = 4/40 | loss = 12.31\n",
      "Epoch = (3, 3) | step = 5/40 | loss = 12.69\n",
      "Epoch = (3, 3) | step = 10/40 | loss = 13.40\n",
      "Epoch = (3, 3) | step = 20/40 | loss = 12.15\n",
      "Epoch = (3, 3) | step = 25/40 | loss = 12.66\n",
      "Epoch = (4, 4) | step = 1/40 | loss = 13.66\n",
      "Epoch = (4, 4) | step = 2/40 | loss = 9.02\n",
      "Epoch = (4, 4) | step = 4/40 | loss = 11.17\n",
      "Epoch = (4, 4) | step = 5/40 | loss = 10.00\n",
      "Epoch = (4, 4) | step = 10/40 | loss = 10.23\n",
      "Epoch = (4, 4) | step = 20/40 | loss = 8.81\n",
      "Epoch = (4, 4) | step = 25/40 | loss = 8.85\n",
      "Epoch = (5, 5) | step = 1/40 | loss = 10.23\n",
      "Epoch = (5, 5) | step = 2/40 | loss = 8.40\n",
      "Epoch = (5, 5) | step = 4/40 | loss = 8.88\n",
      "Epoch = (5, 5) | step = 5/40 | loss = 8.24\n",
      "Epoch = (5, 5) | step = 10/40 | loss = 6.59\n",
      "Epoch = (5, 5) | step = 20/40 | loss = 6.86\n",
      "Epoch = (5, 5) | step = 25/40 | loss = 7.23\n",
      "Epoch = (6, 6) | step = 1/40 | loss = 5.01\n",
      "Epoch = (6, 6) | step = 2/40 | loss = 2.75\n",
      "Epoch = (6, 6) | step = 4/40 | loss = 4.42\n",
      "Epoch = (6, 6) | step = 5/40 | loss = 4.33\n",
      "Epoch = (6, 6) | step = 10/40 | loss = 5.22\n",
      "Epoch = (6, 6) | step = 20/40 | loss = 5.29\n",
      "Epoch = (6, 6) | step = 25/40 | loss = 5.18\n",
      "Epoch = (7, 7) | step = 1/40 | loss = 3.74\n",
      "Epoch = (7, 7) | step = 2/40 | loss = 4.63\n",
      "Epoch = (7, 7) | step = 4/40 | loss = 4.20\n",
      "Epoch = (7, 7) | step = 5/40 | loss = 4.97\n",
      "Epoch = (7, 7) | step = 10/40 | loss = 4.01\n",
      "Epoch = (7, 7) | step = 20/40 | loss = 3.89\n",
      "Epoch = (7, 7) | step = 25/40 | loss = 3.63\n",
      "Epoch = (8, 8) | step = 1/40 | loss = 1.59\n",
      "Epoch = (8, 8) | step = 2/40 | loss = 1.86\n",
      "Epoch = (8, 8) | step = 4/40 | loss = 1.63\n",
      "Epoch = (8, 8) | step = 5/40 | loss = 1.33\n",
      "Epoch = (8, 8) | step = 10/40 | loss = 2.44\n",
      "Epoch = (8, 8) | step = 20/40 | loss = 2.09\n",
      "Epoch = (8, 8) | step = 25/40 | loss = 2.12\n",
      "Epoch = (9, 9) | step = 1/40 | loss = 1.21\n",
      "Epoch = (9, 9) | step = 2/40 | loss = 1.10\n",
      "Epoch = (9, 9) | step = 4/40 | loss = 0.91\n",
      "Epoch = (9, 9) | step = 5/40 | loss = 0.76\n",
      "Epoch = (9, 9) | step = 10/40 | loss = 1.12\n",
      "Epoch = (9, 9) | step = 20/40 | loss = 1.56\n",
      "Epoch = (9, 9) | step = 25/40 | loss = 1.48\n",
      "Epoch = (10, 10) | step = 1/40 | loss = 0.41\n",
      "Epoch = (10, 10) | step = 2/40 | loss = 0.25\n",
      "Epoch = (10, 10) | step = 4/40 | loss = 0.72\n",
      "Epoch = (10, 10) | step = 5/40 | loss = 0.61\n",
      "Epoch = (10, 10) | step = 10/40 | loss = 0.95\n",
      "Epoch = (10, 10) | step = 20/40 | loss = 1.00\n",
      "Epoch = (10, 10) | step = 25/40 | loss = 0.97\n",
      "Epoch = (11, 11) | step = 1/40 | loss = 0.20\n",
      "Epoch = (11, 11) | step = 2/40 | loss = 0.45\n",
      "Epoch = (11, 11) | step = 4/40 | loss = 0.69\n",
      "Epoch = (11, 11) | step = 5/40 | loss = 0.58\n",
      "Epoch = (11, 11) | step = 10/40 | loss = 0.61\n",
      "Epoch = (11, 11) | step = 20/40 | loss = 0.62\n",
      "Epoch = (11, 11) | step = 25/40 | loss = 0.62\n",
      "Epoch = (12, 12) | step = 1/40 | loss = 0.00\n",
      "Epoch = (12, 12) | step = 2/40 | loss = 0.21\n",
      "Epoch = (12, 12) | step = 4/40 | loss = 0.63\n",
      "Epoch = (12, 12) | step = 5/40 | loss = 0.60\n",
      "Epoch = (12, 12) | step = 10/40 | loss = 0.43\n",
      "Epoch = (12, 12) | step = 20/40 | loss = 0.55\n",
      "Epoch = (12, 12) | step = 25/40 | loss = 0.46\n",
      "Epoch = (13, 13) | step = 1/40 | loss = 0.00\n",
      "Epoch = (13, 13) | step = 2/40 | loss = 0.00\n",
      "Epoch = (13, 13) | step = 4/40 | loss = 0.13\n",
      "Epoch = (13, 13) | step = 5/40 | loss = 0.10\n",
      "Epoch = (13, 13) | step = 10/40 | loss = 0.19\n",
      "Epoch = (13, 13) | step = 20/40 | loss = 0.13\n",
      "Epoch = (13, 13) | step = 25/40 | loss = 0.14\n",
      "Epoch = (14, 14) | step = 1/40 | loss = 0.00\n",
      "Epoch = (14, 14) | step = 2/40 | loss = 0.00\n",
      "Epoch = (14, 14) | step = 4/40 | loss = 0.02\n",
      "Epoch = (14, 14) | step = 5/40 | loss = 0.04\n",
      "Epoch = (14, 14) | step = 10/40 | loss = 0.03\n",
      "Epoch = (14, 14) | step = 20/40 | loss = 0.05\n",
      "Epoch = (14, 14) | step = 25/40 | loss = 0.10\n",
      "Epoch = (15, 15) | step = 1/40 | loss = 0.02\n",
      "Epoch = (15, 15) | step = 2/40 | loss = 0.03\n",
      "Epoch = (15, 15) | step = 4/40 | loss = 0.02\n",
      "Epoch = (15, 15) | step = 5/40 | loss = 0.09\n",
      "Epoch = (15, 15) | step = 10/40 | loss = 0.05\n",
      "Epoch = (15, 15) | step = 20/40 | loss = 0.04\n",
      "Epoch = (15, 15) | step = 25/40 | loss = 0.03\n",
      "Epoch = (16, 16) | step = 1/40 | loss = 0.00\n",
      "Epoch = (16, 16) | step = 2/40 | loss = 0.00\n",
      "Epoch = (16, 16) | step = 4/40 | loss = 0.02\n",
      "Epoch = (16, 16) | step = 5/40 | loss = 0.01\n",
      "Epoch = (16, 16) | step = 10/40 | loss = 0.01\n",
      "Epoch = (16, 16) | step = 20/40 | loss = 0.02\n",
      "Epoch = (16, 16) | step = 25/40 | loss = 0.02\n",
      "Epoch = (17, 17) | step = 1/40 | loss = 0.00\n",
      "Epoch = (17, 17) | step = 2/40 | loss = 0.02\n",
      "Epoch = (17, 17) | step = 4/40 | loss = 0.01\n",
      "Epoch = (17, 17) | step = 5/40 | loss = 0.01\n",
      "Epoch = (17, 17) | step = 10/40 | loss = 0.03\n",
      "Epoch = (17, 17) | step = 20/40 | loss = 0.02\n",
      "Epoch = (17, 17) | step = 25/40 | loss = 0.01\n",
      "Epoch = (18, 18) | step = 1/40 | loss = 0.00\n",
      "Epoch = (18, 18) | step = 2/40 | loss = 0.00\n",
      "Epoch = (18, 18) | step = 4/40 | loss = 0.00\n",
      "Epoch = (18, 18) | step = 5/40 | loss = 0.00\n",
      "Epoch = (18, 18) | step = 10/40 | loss = 0.00\n",
      "Epoch = (18, 18) | step = 20/40 | loss = 0.00\n",
      "Epoch = (18, 18) | step = 25/40 | loss = 0.01\n",
      "Epoch = (19, 19) | step = 1/40 | loss = 0.00\n",
      "Epoch = (19, 19) | step = 2/40 | loss = 0.00\n",
      "Epoch = (19, 19) | step = 4/40 | loss = 0.00\n",
      "Epoch = (19, 19) | step = 5/40 | loss = 0.00\n",
      "Epoch = (19, 19) | step = 10/40 | loss = 0.00\n",
      "Epoch = (19, 19) | step = 20/40 | loss = 0.00\n",
      "Epoch = (19, 19) | step = 25/40 | loss = 0.00\n"
     ]
    }
   ],
   "source": [
    "CTRmodel.train(trainDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7abfc914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd24c9d5220>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(CTRmodel.steps, CTRmodel.losses, 'bo--')  # 每个step的单个loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3354c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd24c8c76a0>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(CTRmodel.steps, CTRmodel.avg_losses, 'bo--') # 每个step,对应的epoch截止到该step时的平均loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bcfc87f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd24c8be1f0>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(CTRmodel.steps, CTRmodel.nstep_avg_losses, 'bo--') # 每个step,对应的epoch截止到该step时的平均loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9377c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
